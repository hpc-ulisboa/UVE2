diff --git a/disasm/disasm.cc b/disasm/disasm.cc
index 343fff72..5031a368 100644
--- a/disasm/disasm.cc
+++ b/disasm/disasm.cc
@@ -530,6 +530,143 @@ struct : public arg_t {
   }
 } rcon;

+/*=== UVE ===*/
+
+struct : public arg_t {
+  std::string to_string(insn_t insn) const {
+    return ur_name[insn.uve_rd()];
+  }
+} urd;
+
+struct : public arg_t {
+  std::string to_string(insn_t insn) const {
+    return xpr_name[insn.uve_rd()];
+  }
+} uxrd;
+
+struct : public arg_t {
+  std::string to_string(insn_t insn) const {
+    return ur_name[insn.uve_rs1()];
+  }
+} urs1;
+
+struct : public arg_t {
+  std::string to_string(insn_t insn) const {
+    return xpr_name[insn.uve_rs1()];
+  }
+} uxrs1;
+
+struct : public arg_t {
+  std::string to_string(insn_t insn) const {
+    return ur_name[insn.uve_rs2()];
+  }
+} urs2;
+
+struct : public arg_t {
+  std::string to_string(insn_t insn) const {
+    return xpr_name[insn.uve_rs2()];
+  }
+} uxrs2;
+
+struct : public arg_t {
+  std::string to_string(insn_t insn) const {
+    return ur_name[insn.uve_rs3()];
+  }
+} urs3;
+
+struct : public arg_t {
+  std::string to_string(insn_t insn) const {
+    return xpr_name[insn.uve_rs3()];
+  }
+} uxrs3;
+
+struct : public arg_t {
+  std::string to_string(insn_t insn) const {
+    return xpr_name[insn.uve_conf_base()];
+  }
+} uconf_rs1;
+
+struct : public arg_t {
+  std::string to_string(insn_t insn) const {
+    return xpr_name[insn.uve_conf_size()];
+  }
+} uconf_rs2;
+
+struct : public arg_t {
+  std::string to_string(insn_t insn) const {
+    return xpr_name[insn.uve_conf_stride()];
+  }
+} uconf_rs3;
+
+struct : public arg_t {
+  std::string to_string(insn_t insn) const {
+    return xpr_name[insn.uve_mod_size()];
+  }
+} umod_size;
+
+struct : public arg_t {
+  std::string to_string(insn_t insn) const {
+    return xpr_name[insn.uve_mod_disp()];
+  }
+} umod_disp;
+
+struct : public arg_t {
+  std::string to_string(insn_t insn) const {
+    return ur_name[insn.uve_branch_rs()];
+  }
+} ub_rs1;
+
+struct : public arg_t {
+  std::string to_string(insn_t insn) const {
+    int32_t target = insn.uve_branch_imm();
+    std::string s = target >= 0 ? "pc + " : "pc - ";
+    s += std::to_string(abs(target));
+    return s;
+  }
+} ub_imm;
+
+struct : public arg_t {
+  std::string to_string(insn_t insn) const {
+    return pr_name[insn.uve_pred_rd()];
+  }
+} up_rd;
+
+struct : public arg_t {
+  std::string to_string(insn_t insn) const {
+    return pr_name[insn.uve_pred_rs1()];
+  }
+} up_rs1;
+
+struct : public arg_t {
+  std::string to_string(insn_t insn) const {
+    return ur_name[insn.uve_pred_rs2()];
+  }
+} up_rs2;
+
+struct : public arg_t {
+  std::string to_string(insn_t insn) const {
+    return xpr_name[insn.uve_pred_rs2()];
+  }
+} up_xrs2;
+
+struct : public arg_t {
+  std::string to_string(insn_t insn) const {
+    return ur_name[insn.uve_pred_vs1()];
+  }
+} up_vs1;
+
+struct : public arg_t {
+  std::string to_string(insn_t insn) const {
+    return pr_name[insn.uve_pred()];
+  }
+} upred;
+
+struct : public arg_t {
+  std::string to_string(insn_t insn) const {
+    return pr_name[insn.uve_v_pred()];
+  }
+} uv_pred;
+
 typedef struct {
   reg_t match;
   reg_t mask;
@@ -724,6 +861,73 @@ static void NOINLINE add_vector_vim_insn(disassembler_t* d, const char* name, ui
   d->add_insn(new disasm_insn_t(name, match, mask, {&vd, &vs2, &v_simm5, &v0}));
 }

+/*=== UVE ===*/
+
+static void NOINLINE add_uve_conf_insn(disassembler_t* d, const char* name, uint32_t match, uint32_t mask)
+{
+  d->add_insn(new disasm_insn_t(name, match, mask, {&urd, &uconf_rs1, &uconf_rs2, &uconf_rs3}));
+}
+
+static void NOINLINE add_uve_mod_insn(disassembler_t* d, const char* name, uint32_t match, uint32_t mask)
+{
+  d->add_insn(new disasm_insn_t(name, match, mask, {&urd, &uconf_rs1, &uconf_rs3}));
+}
+
+static void NOINLINE add_uve_branch_insn(disassembler_t* d, const char* name, uint32_t match, uint32_t mask)
+{
+  d->add_insn(new disasm_insn_t(name, match, mask, {&ub_rs1, &ub_imm}));
+}
+
+static void NOINLINE add_uve_vmv_insn(disassembler_t* d, const char* name, uint32_t match, uint32_t mask)
+{
+  d->add_insn(new disasm_insn_t(name, match, mask, {&urd, &urs1, &uv_pred}));
+}
+
+static void NOINLINE add_uve_vmvsv_insn(disassembler_t* d, const char* name, uint32_t match, uint32_t mask)
+{
+  d->add_insn(new disasm_insn_t(name, match, mask, {&urd, &uxrs1}));
+}
+
+static void NOINLINE add_uve_vdp_insn(disassembler_t* d, const char* name, uint32_t match, uint32_t mask)
+{
+  d->add_insn(new disasm_insn_t(name, match, mask, {&urd, &uxrs1, &uv_pred}));
+}
+
+static void NOINLINE add_uve_arith_insn(disassembler_t* d, const char* name, uint32_t match, uint32_t mask)
+{
+  d->add_insn(new disasm_insn_t(name, match, mask, {&urd, &urs1, &urs2, &upred}));
+}
+
+static void NOINLINE add_uve_arith1_insn(disassembler_t* d, const char* name, uint32_t match, uint32_t mask)
+{
+  d->add_insn(new disasm_insn_t(name, match, mask, {&urd, &urs1, &upred}));
+}
+
+static void NOINLINE add_uve_arith2_insn(disassembler_t* d, const char* name, uint32_t match, uint32_t mask)
+{
+  d->add_insn(new disasm_insn_t(name, match, mask, {&uxrd, &urs1, &upred}));
+}
+
+static void NOINLINE add_uve_arith3_insn(disassembler_t* d, const char* name, uint32_t match, uint32_t mask)
+{
+  d->add_insn(new disasm_insn_t(name, match, mask, {&urd, &urs1, &uxrs2, &upred}));
+}
+
+static void NOINLINE add_uve_pred_insn(disassembler_t* d, const char* name, uint32_t match, uint32_t mask)
+{
+  d->add_insn(new disasm_insn_t(name, match, mask, {&up_rd, &up_rs1, &upred}));
+}
+
+static void NOINLINE add_uve_pred_comp_insn(disassembler_t* d, const char* name, uint32_t match, uint32_t mask)
+{
+  d->add_insn(new disasm_insn_t(name, match, mask, {&up_rd, &up_rs1, &up_rs2, &upred}));
+}
+
+static void NOINLINE add_uve_pred_comp1_insn(disassembler_t* d, const char* name, uint32_t match, uint32_t mask)
+{
+  d->add_insn(new disasm_insn_t(name, match, mask, {&up_rd, &up_vs1, &up_xrs2, &upred}));
+}
+
 static void NOINLINE add_unknown_insn(disassembler_t* d, const char* name, uint32_t match, uint32_t mask)
 {
   std::string s = name;
@@ -796,6 +1000,20 @@ void disassembler_t::add_instructions(const isa_parser_t* isa)
   #define DEFINE_FX2TYPE(code) add_fx2type_insn(this, #code, match_##code, mask_##code);
   #define DEFINE_XFTYPE(code) add_xftype_insn(this, #code, match_##code, mask_##code);
   #define DEFINE_SFENCE_TYPE(code) add_sfence_insn(this, #code, match_##code, mask_##code);
+  /*=== UVE ===*/
+  #define DEFINE_UCONF(code) add_uve_conf_insn(this, #code, match_##code, mask_##code);
+  #define DEFINE_UMOD(code) add_uve_mod_insn(this, #code, match_##code, mask_##code);
+  #define DEFINE_UBTYPE(code) add_uve_branch_insn(this, #code, match_##code, mask_##code);
+  #define DEFINE_UVTYPE_MOVE(code) add_uve_vmv_insn(this, #code, match_##code, mask_##code);
+  #define DEFINE_UVTYPE_MVSV(code) add_uve_vmvsv_insn(this, #code, match_##code, mask_##code);
+  #define DEFINE_UVTYPE_DP(code) add_uve_vdp_insn(this, #code, match_##code, mask_##code);
+  #define DEFINE_UATYPE(code) add_uve_arith_insn(this, #code, match_##code, mask_##code);
+  #define DEFINE_UA1TYPE(code) add_uve_arith1_insn(this, #code, match_##code, mask_##code);
+  #define DEFINE_UA2TYPE(code) add_uve_arith2_insn(this, #code, match_##code, mask_##code);
+  #define DEFINE_UA3TYPE(code) add_uve_arith3_insn(this, #code, match_##code, mask_##code);
+  #define DEFINE_UPRED(code) add_uve_pred_insn(this, #code, match_##code, mask_##code);
+  #define DEFINE_UPRED_COMP(code) add_uve_pred_comp_insn(this, #code, match_##code, mask_##code);
+  #define DEFINE_UPRED_COMP1(code) add_uve_pred_comp1_insn(this, #code, match_##code, mask_##code);

   add_insn(new disasm_insn_t("unimp", match_csrrw|(CSR_CYCLE<<20), 0xffffffff, {}));
   add_insn(new disasm_insn_t("c.unimp", 0, 0xffff, {}));
@@ -2137,6 +2355,144 @@ void disassembler_t::add_instructions(const isa_parser_t* isa)
       DISASM_INSN("c.sspopchk", c_sspopchk_x5, 0, {&rvc_t0});
     }
   }
+
+  /*=== UVE ===*/
+  DEFINE_UCONF(ss_sta_ld_d);
+  DEFINE_UCONF(ss_sta_ld_w);
+  DEFINE_UCONF(ss_sta_ld_h);
+  DEFINE_UCONF(ss_sta_ld_b);
+  DEFINE_UCONF(ss_sta_ld_d_inds);
+  DEFINE_UCONF(ss_sta_ld_w_inds);
+  DEFINE_UCONF(ss_sta_ld_h_inds);
+  DEFINE_UCONF(ss_sta_ld_b_inds);
+  DEFINE_UCONF(ss_sta_ld_d_v);
+  DEFINE_UCONF(ss_sta_ld_w_v);
+  DEFINE_UCONF(ss_sta_ld_h_v);
+  DEFINE_UCONF(ss_sta_ld_b_v);
+  DEFINE_UCONF(ss_sta_ld_d_v_1);
+  DEFINE_UCONF(ss_sta_ld_w_v_1);
+  DEFINE_UCONF(ss_sta_ld_h_v_1);
+  DEFINE_UCONF(ss_sta_ld_b_v_1);
+  DEFINE_UCONF(ss_sta_st_d);
+  DEFINE_UCONF(ss_sta_st_w);
+  DEFINE_UCONF(ss_sta_st_h);
+  DEFINE_UCONF(ss_sta_st_b);
+  DEFINE_UCONF(ss_sta_st_d_v_1);
+  DEFINE_UCONF(ss_sta_st_w_v_1);
+  DEFINE_UCONF(ss_sta_st_h_v_1);
+  DEFINE_UCONF(ss_sta_st_b_v_1);
+  DEFINE_UCONF(ss_sta_st_d_v);
+  DEFINE_UCONF(ss_sta_st_w_v);
+  DEFINE_UCONF(ss_sta_st_h_v);
+  DEFINE_UCONF(ss_sta_st_b_v);
+  DEFINE_UCONF(ss_app);
+  DEFINE_UMOD(ss_app_mod_ofs_dec_1);
+  DEFINE_UMOD(ss_app_mod_ofs_inc_1);
+  DEFINE_UMOD(ss_app_mod_siz_dec_1);
+  DEFINE_UMOD(ss_app_mod_siz_inc_1);
+  DEFINE_UCONF(ss_end);
+  //DISASM_INSN("ss.cfg.vec", ss_cfg_vec, 0, {&urd});
+  //DISASM_INSN("ss.cfg.ind", ss_cfg_ind, 0, {&urd});
+
+  DEFINE_UBTYPE(so_b_c);
+  DEFINE_UBTYPE(so_b_dc_1);
+  DEFINE_UBTYPE(so_b_dc_2);
+  DEFINE_UBTYPE(so_b_dc_3);
+  DEFINE_UBTYPE(so_b_dc_4);
+  DEFINE_UBTYPE(so_b_dc_5);
+  DEFINE_UBTYPE(so_b_dc_6);
+  DEFINE_UBTYPE(so_b_dc_7);
+  DEFINE_UBTYPE(so_b_nc);
+  DEFINE_UBTYPE(so_b_ndc_1);
+  DEFINE_UBTYPE(so_b_ndc_2);
+  DEFINE_UBTYPE(so_b_ndc_3);
+  DEFINE_UBTYPE(so_b_ndc_4);
+  DEFINE_UBTYPE(so_b_ndc_5);
+  DEFINE_UBTYPE(so_b_ndc_6);
+  DEFINE_UBTYPE(so_b_ndc_7);
+
+  DEFINE_UVTYPE_MOVE(so_v_mv);
+  //DEFINE_UVTYPE_MOVE(so_v_mv_stream);
+  DEFINE_UVTYPE_MOVE(so_v_mvt);
+  //DEFINE_UVTYPE_MOVE(so_v_mvt_stream);
+  DEFINE_UVTYPE_MVSV(so_v_mvsv_b);
+  DEFINE_UVTYPE_MVSV(so_v_mvsv_h);
+  DEFINE_UVTYPE_MVSV(so_v_mvsv_w);
+  DEFINE_UVTYPE_MVSV(so_v_mvsv_d);
+  DISASM_INSN("so.v.mvvs", so_v_mvvs, 0, {&uxrd, &urs1});
+  DEFINE_UVTYPE_DP(so_v_dp_d);
+  DEFINE_UVTYPE_DP(so_v_dp_w);
+  DEFINE_UVTYPE_DP(so_v_dp_h);
+  DEFINE_UVTYPE_DP(so_v_dp_b);
+
+  DEFINE_UATYPE(so_a_add_fp);
+  DEFINE_UATYPE(so_a_add_us);
+  DEFINE_UATYPE(so_a_add_sg);
+  DEFINE_UATYPE(so_a_sub_fp);
+  DEFINE_UATYPE(so_a_sub_us);
+  DEFINE_UATYPE(so_a_sub_sg);
+  DEFINE_UATYPE(so_a_mul_fp);
+  DEFINE_UATYPE(so_a_mul_us);
+  DEFINE_UATYPE(so_a_mul_sg);
+  DEFINE_UATYPE(so_a_div_fp);
+  DEFINE_UATYPE(so_a_div_us);
+  DEFINE_UATYPE(so_a_div_sg);
+  DEFINE_UATYPE(so_a_mac_fp);
+  DEFINE_UATYPE(so_a_mac_us);
+  DEFINE_UATYPE(so_a_mac_sg);
+  DEFINE_UATYPE(so_a_min_fp);
+  DEFINE_UATYPE(so_a_min_us);
+  DEFINE_UATYPE(so_a_min_sg);
+  DEFINE_UATYPE(so_a_max_fp);
+  DEFINE_UATYPE(so_a_max_us);
+  DEFINE_UATYPE(so_a_max_sg);
+  DEFINE_UA1TYPE(so_a_abs_fp);
+  DEFINE_UA1TYPE(so_a_abs_sg);
+  DEFINE_UA1TYPE(so_a_inc_fp);
+  DEFINE_UA1TYPE(so_a_inc_us);
+  DEFINE_UA1TYPE(so_a_inc_sg);
+  DEFINE_UA1TYPE(so_a_dec_fp);
+  DEFINE_UA1TYPE(so_a_dec_us);
+  DEFINE_UA1TYPE(so_a_dec_sg);
+  DEFINE_UA1TYPE(so_a_adde_fp);
+  DEFINE_UA1TYPE(so_a_adde_us);
+  DEFINE_UA1TYPE(so_a_adde_sg);
+  DEFINE_UA1TYPE(so_a_adde_acc_fp);
+  DEFINE_UA1TYPE(so_a_adde_acc_us);
+  DEFINE_UA1TYPE(so_a_adde_acc_sg);
+  DEFINE_UA1TYPE(so_a_mine_fp);
+  DEFINE_UA1TYPE(so_a_mine_us);
+  DEFINE_UA1TYPE(so_a_mine_sg);
+  DEFINE_UA1TYPE(so_a_maxe_fp);
+  DEFINE_UA1TYPE(so_a_maxe_us);
+  DEFINE_UA1TYPE(so_a_maxe_sg);
+  DEFINE_UA2TYPE(so_a_adds_fp);
+  DEFINE_UA2TYPE(so_a_adds_us);
+  DEFINE_UA2TYPE(so_a_adds_sg);
+  DISASM_INSN("so.a.adds.acc.fp", so_a_adds_acc_fp, 0, {&frd, &urs1, &upred});
+  DEFINE_UA2TYPE(so_a_adds_acc_us);
+  DEFINE_UA2TYPE(so_a_adds_acc_sg);
+  DEFINE_UATYPE(so_a_nand);
+  DEFINE_UATYPE(so_a_and);
+  DEFINE_UATYPE(so_a_nor);
+  DEFINE_UATYPE(so_a_or);
+  DEFINE_UA1TYPE(so_a_not);
+  DEFINE_UATYPE(so_a_xor);
+  DEFINE_UATYPE(so_a_sll);
+  DEFINE_UATYPE(so_a_srl);
+  DEFINE_UATYPE(so_a_sra);
+  DEFINE_UA3TYPE(so_a_slls);
+  DEFINE_UA3TYPE(so_a_srls);
+  DEFINE_UA3TYPE(so_a_sras);
+
+  DEFINE_UPRED(so_p_not);
+  DEFINE_UPRED(so_p_mv);
+  DEFINE_UPRED(so_p_mvt);
+  DEFINE_UPRED_COMP(so_p_eq_fp);
+  DEFINE_UPRED_COMP(so_p_ge_fp);
+  DEFINE_UPRED_COMP(so_p_lt_fp);
+  DISASM_INSN("so.p.zero", so_p_zero, 0, {&up_rd});
+  DISASM_INSN("so.p.one", so_p_one, 0, {&up_rd});
 }

 disassembler_t::disassembler_t(const isa_parser_t *isa)
diff --git a/disasm/regnames.cc b/disasm/regnames.cc
index 0a7fd4d2..1c08ead3 100644
--- a/disasm/regnames.cc
+++ b/disasm/regnames.cc
@@ -23,6 +23,20 @@ const char* vr_name[] = {
   "v24", "v25", "v26", "v27", "v28", "v29", "v30", "v31"
 };

+/*=== UVE ===*/
+
+const char* ur_name[] = {
+  "u0",  "u1",  "u2",  "u3",  "u4",  "u5",  "u6",  "u7",
+  "u8",  "u9",  "u10", "u11", "u12", "u13", "u14", "u15",
+  "u16", "u17", "u18", "u19", "u20", "u21", "u22", "u23",
+  "u24", "u25", "u26", "u27", "u28", "u29", "u30", "u31"
+};
+
+const char* pr_name[] = {
+  "p0",  "p1",  "p2",  "p3",  "p4",  "p5",  "p6",  "p7",
+  "p8",  "p9",  "p10", "p11", "p12", "p13", "p14", "p15"
+};
+
 const char* csr_name(int which) {
   switch (which) {
     #define DECLARE_CSR(name, number)  case number: return #name;
diff --git a/riscv/csrs.cc b/riscv/csrs.cc
index 02a2c4fe..472be7ce 100644
--- a/riscv/csrs.cc
+++ b/riscv/csrs.cc
@@ -1312,7 +1312,8 @@ reg_t dcsr_csr_t::read() const noexcept {
   result = set_field(result, DCSR_EBREAKU, ebreaku);
   result = set_field(result, CSR_DCSR_EBREAKVS, ebreakvs);
   result = set_field(result, CSR_DCSR_EBREAKVU, ebreakvu);
-  result = set_field(result, DCSR_STOPCYCLE, 0);
+  //result = set_field(result, DCSR_STOPCYCLE, 0);
+  result = set_field(result, DCSR_STOPCOUNT, 0);
   result = set_field(result, DCSR_STOPTIME, 0);
   result = set_field(result, DCSR_CAUSE, cause);
   result = set_field(result, DCSR_STEP, step);
@@ -1331,7 +1332,7 @@ bool dcsr_csr_t::unlogged_write(const reg_t val) noexcept {
   ebreaku = proc->extension_enabled('U') ? get_field(val, DCSR_EBREAKU) : false;
   ebreakvs = proc->extension_enabled('H') ? get_field(val, CSR_DCSR_EBREAKVS) : false;
   ebreakvu = proc->extension_enabled('H') ? get_field(val, CSR_DCSR_EBREAKVU) : false;
-  halt = get_field(val, DCSR_HALT);
+  //halt = get_field(val, DCSR_HALT);
   v = proc->extension_enabled('H') ? get_field(val, CSR_DCSR_V) : false;
   pelp = proc->extension_enabled(EXT_ZICFILP) ?
          static_cast<elp_t>(get_field(val, DCSR_PELP)) : elp_t::NO_LP_EXPECTED;
diff --git a/riscv/decode.h b/riscv/decode.h
index f36c04e5..34969a74 100644
--- a/riscv/decode.h
+++ b/riscv/decode.h
@@ -22,6 +22,8 @@ typedef float128_t freg_t;
 const int NXPR = 32;
 const int NFPR = 32;
 const int NVPR = 32;
+const int NUPR = 32; // UVE vector registers
+const int NPR = 16;  // UVE predicate registers
 const int NCSR = 4096;

 #define X_RA 1
@@ -149,6 +151,33 @@ public:
   uint64_t p_imm5() { return x(20, 5); }
   uint64_t p_imm6() { return x(20, 6); }

+  /*=== UVE ===*/
+  uint64_t uve_rd() { return x(7, 5); }
+  int64_t uve_rs1() { return x(15, 5); }
+  int64_t uve_rs2() { return x(20, 5); }
+  int64_t uve_rs3() { return x(27, 5); }
+  uint64_t uve_pred() { return x(25, 3); }
+  uint64_t uve_v_pred() { return x(20, 3); } // Vector manipulation instructions
+  // Registers for load/store instructions
+  uint64_t uve_conf_base() { return x(15, 5); } // RS1
+  int64_t uve_conf_size() { return x(20, 5); } // RS2
+  int64_t uve_conf_stride() { return x(27, 5); } // RS3
+  // Registers for modifier configuration instructions
+  int64_t uve_mod_size() { return x(15, 5); } // RS1
+  int64_t uve_mod_disp() { return x(27, 5); } // RS3
+  // Registers for dynamic modifier configuration instructions
+  int64_t uve_mod_origin() { return x(15, 5); } // RS1
+  // Registers for branching instructions
+  int64_t uve_branch_rs() { return x(15, 5); } // RS1
+  // Calculate offset for UVE branching instruction
+  //int64_t uve_branch_imm() { return (x(8, 4) << 1) + (x(22, 6) << 5) + (x(7, 1) << 11) + (imm_sign() << 12); }
+  int64_t uve_branch_imm() { return (x(8, 4) << 1) + (x(22, 6) << 5) + (x(7, 1) << 11) + ( xs(28, 1) << 12); }
+  // Registers for predicate instructions
+  uint64_t uve_pred_rd() { return x(7, 4); }  // RD
+  int64_t uve_pred_rs1() { return x(15, 4); } // Source: predicate register
+  int64_t uve_pred_vs1() { return x(15, 5); } // Source: vector register
+  int64_t uve_pred_rs2() { return x(20, 5); }
+
   uint64_t zcmp_regmask() {
     unsigned mask = 0;
     uint64_t rlist = rvc_rlist();
diff --git a/riscv/descriptors.cc b/riscv/descriptors.cc
new file mode 100644
index 00000000..d1e6455f
--- /dev/null
+++ b/riscv/descriptors.cc
@@ -0,0 +1,241 @@
+#include "descriptors.h"
+#include "streaming_unit.h"
+#include <iostream>
+#include <limits.h>
+
+/* Start of dimension_t function definitions */
+
+void dimension_t::resetIterValues() {
+    iter_offset = offset;
+    iter_size = size;
+    iter_stride = stride;
+}
+
+bool dimension_t::isEmpty() const {
+    return iter_size == 0;
+}
+
+void dimension_t::advance() {
+    ++iter_index;
+}
+
+bool dimension_t::isLastIteration() const {
+    return iter_index + 1 >= iter_size;
+}
+
+bool dimension_t::isEndOfDimension() const {
+    return endOfDimension;
+}
+
+void dimension_t::setEndOfDimension(bool b) {
+    // std::cout << "Setting end of dimension to: " << b << std::endl;
+    endOfDimension = b;
+    if (!b)
+        iter_index = 0;
+}
+
+size_t dimension_t::calcAddress(size_t width) const {
+    /*std::cout << "iter_offset: " << iter_offset << ", iter_stride: " <<
+    iter_stride << ", iter_index: " << iter_index << ", width: " << width << std::endl;
+    std::cout << "iter_stride * iter_index * width: " << iter_stride * iter_index * width << std::endl;
+    */
+    return iter_offset + iter_stride * iter_index * width;
+}
+
+size_t dimension_t::getSize() const {
+    return iter_size;
+}
+
+/* Start of modifier_t function definitions */
+
+void staticModifier_t::modDimension(std::deque<dimension_t> &dims, const size_t elementWidth) {
+    size_t valueChange = behaviour == staticBehaviour::Increment ? displacement : -1 * displacement;
+    dimension_t &dim = dims.at(targetDim);
+
+    if (target == Target::Offset) {
+        dim.iter_offset += valueChange * elementWidth;
+        // std::cout << "iter_offset: " << dim.iter_offset << std::endl;
+    } else if (target == Target::Size) {
+        dim.iter_size += valueChange;
+        // std::cout << "valueChange: " << (int)valueChange << " iter_size: " << dim.iter_size << std::endl;
+    } else if (target == Target::Stride) {
+        dim.iter_stride += valueChange;
+        // std::cout << "iter_stride: " << dim.iter_stride << std::endl;
+    } else {
+        assert_msg("Unexpected target for a static modifier", false);
+    }
+}
+
+void dynamicModifier_t::calculateValueChange(auto &target, auto baseValue, dynamicBehaviour behaviour, int valueChange) {
+    switch (behaviour) {
+    case dynamicBehaviour::Add:
+        target = baseValue + valueChange;
+        break;
+    case dynamicBehaviour::Subtract:
+        target = baseValue - valueChange;
+        break;
+    case dynamicBehaviour::Set:
+        target = valueChange;
+        break;
+    case dynamicBehaviour::Increment:
+        target += valueChange;
+        break;
+    case dynamicBehaviour::Decrement:
+        target -= valueChange;
+        break;
+    default:
+        assert_msg("Unexpected behaviour for a dynamic modifier", false);
+    }
+}
+
+void dynamicModifier_t::getIndirectRegisterValues() {
+    auto &src = (su->registers).at(sourceStream);
+    std::visit(overloaded{
+                   [&](auto &reg) { sourceEnd = !reg.getDynModElement(indirectRegisterValue); }},
+               src);
+
+    /*print values
+    for (auto &v : indirectRegisterValues) {
+        printf("value: %d\n", v);
+    }*/
+}
+
+void dynamicModifier_t::modDimension(std::deque<dimension_t> &dims, const size_t elementWidth) {
+    // size_t valueChange = behaviour == Behaviour::Increment ? displacement : -1*displacement;
+    dimension_t &dim = dims.at(targetDim);
+    if (!sourceEnd) {
+        getIndirectRegisterValues();
+
+        if (target == Target::Offset) {
+            calculateValueChange(dim.iter_offset, dim.offset, behaviour, indirectRegisterValue * elementWidth);
+            dim.setEndOfDimension(false);
+            // std::cout << "iter_offset: " << dim.iter_offset << std::endl;
+        } else if (target == Target::Size) {
+            calculateValueChange(dim.iter_size, dim.size, behaviour, indirectRegisterValue);
+            if (dim.iter_size)
+                dim.setEndOfDimension(false);
+            // std::cout << "iter_size: " << dim.iter_size << std::endl;
+        } else if (target == Target::Stride) {
+            calculateValueChange(dim.iter_stride, dim.stride, behaviour, indirectRegisterValue);
+            // std::cout << "iter_stride: " << dim.iter_stride << std::endl;
+        } else {
+            assert_msg("Unexpected target for a dynamic modifier", false);
+        }
+
+        modApplied = true;
+
+    } else {
+        dim.setEndOfDimension(true);
+        sourceEnd = false;
+    }
+}
+
+void scatterGModifier_t::calculateValueChange(auto &target, auto baseValue, dynamicBehaviour behaviour, int valueChange) {
+    switch (behaviour) {
+    case dynamicBehaviour::Add:
+        target = baseValue + valueChange;
+        break;
+    case dynamicBehaviour::Subtract:
+        target = baseValue - valueChange;
+        break;
+    case dynamicBehaviour::Set:
+        target = valueChange;
+        break;
+    case dynamicBehaviour::Increment:
+        target += valueChange;
+        break;
+    case dynamicBehaviour::Decrement:
+        target -= valueChange;
+        break;
+    default:
+        assert_msg("Unexpected behaviour for a scatter-gather modifier", false);
+    }
+}
+
+void scatterGModifier_t::getIndirectRegisterValues() {
+    auto &src = (su->registers).at(sourceStream);
+    std::visit(overloaded{
+                   [&](auto &reg) { sourceEnd = !reg.getDynModElement(indirectRegisterValue); }},
+               src);
+
+    /*print values
+    for (auto &v : indirectRegisterValues) {
+        printf("value: %d\n", v);
+    }*/
+}
+
+void scatterGModifier_t::modDimension(dimension_t &dim, const size_t elementWidth) {
+    // size_t valueChange = behaviour == Behaviour::Increment ? displacement : -1*displacement;
+    if (!sourceEnd) {
+        getIndirectRegisterValues();
+
+        calculateValueChange(dim.iter_offset, dim.offset, behaviour, indirectRegisterValue * elementWidth);
+        dim.setEndOfDimension(false);
+
+        if (behaviour != dynamicBehaviour::Increment && behaviour != dynamicBehaviour::Decrement)
+            dim.iter_size = UINT_MAX;
+        /* print dimension
+        std::cout << "dimension_t: ";
+        std::cout << "offset: " << dim.iter_offset << ", ";
+        std::cout << "size: " << dim.iter_size << ", ";
+        std::cout << "stride: " << dim.iter_stride << ", ";
+        std::cout << "EOD: " << (int)dim.endOfDimension << std::endl;*/
+        // std::cout << "iter_offset: " << dim.iter_offset << std::endl;
+
+        modApplied = true;
+
+    } else {
+        dim.setEndOfDimension(true);
+        sourceEnd = false;
+    }
+}
+
+/*void modifier_t::printModifier() const {
+    // print modifier
+    std::cout << "modifier_t: ";
+    switch (type) {
+    case Type::Static:
+        std::cout << "Static";
+        break;
+    case Type::Indirect:
+        std::cout << "Indirect";
+        break;
+    default:
+        assert_msg("Unhandled Type case in modifiers's printModifier",
+                   false);
+    }
+    std::cout << ", ";
+    switch (target) {
+    case Target::None:
+        std::cout << "None";
+        break;
+    case Target::Offset:
+        std::cout << "Offset";
+        break;
+    case Target::Size:
+        std::cout << "Size";
+        break;
+    case Target::Stride:
+        std::cout << "Stride";
+        break;
+    default:
+        assert_msg("Unhandled Target case in modifiers's printModifier",
+                   false);
+    }
+    std::cout << ", ";
+    switch (behaviour) {
+    case Behaviour::None:
+        std::cout << "None";
+        break;
+    case Behaviour::Increment:
+        std::cout << "Increment";
+        break;
+    case Behaviour::Decrement:
+        std::cout << "Decrement";
+        break;
+    default:
+        assert_msg("Unhandled Behaviour case in modifiers's printModifier",
+                   false);
+    }
+    std::cout << ", displacement: " << displacement << ", size: " << size;
+}*/
\ No newline at end of file
diff --git a/riscv/descriptors.h b/riscv/descriptors.h
new file mode 100644
index 00000000..71707e8f
--- /dev/null
+++ b/riscv/descriptors.h
@@ -0,0 +1,164 @@
+#ifndef DIMENSION_HPP
+#define DIMENSION_HPP
+
+#include "helpers.h"
+//#include "streaming_unit.h"
+
+class streamingUnit_t;
+
+struct dimension_t {
+    dimension_t(size_t offset, size_t size, int stride)
+        : offset(offset), size(size), stride(stride) {
+
+        iter_offset = offset;
+        iter_size = size;
+        iter_stride = stride;
+        iter_index = 0;
+        endOfDimension = iter_size == 0;
+
+        // endOfDimension = false;
+        // std::cout << "offset: " << offset << ", size: " << size << ", stride: "
+        // << stride << std::endl;
+    }
+
+    // void resetIndex();
+
+    void resetIterValues();
+    bool isEmpty() const;
+    void advance();
+    bool isLastIteration() const;
+    bool isModApplied() const;
+    bool isEndOfDimension() const;
+    void setEndOfDimension(bool b);
+    size_t calcAddress(size_t width) const;
+    size_t getSize() const;
+
+private:
+    const size_t offset;
+    const size_t size;
+    const int stride;
+    size_t iter_offset;
+    size_t iter_size;
+    int iter_stride;
+    size_t iter_index;
+    bool endOfDimension;
+
+    //friend class modifier_t;
+	friend class staticModifier_t;
+	friend class dynamicModifier_t;
+	friend class scatterGModifier_t;
+};
+
+enum class Target {
+    Offset,
+    Size,
+    Stride
+};
+
+enum class staticBehaviour {
+    Increment,
+    Decrement
+};
+
+enum class dynamicBehaviour {
+    Increment,
+    Decrement,
+    Set,
+    Add,
+    Subtract
+};
+
+struct staticModifier_t {
+    staticModifier_t(Target t, staticBehaviour b, int d = 0, unsigned int td = 0)
+        :target(t), behaviour(b), displacement(d), targetDim(td) {
+    }
+
+	void modDimension(std::deque<dimension_t> &dims, const size_t elementWidth);
+
+    int getTargetDim() const {
+        return targetDim;
+    }
+
+private:
+    const Target target;
+    const staticBehaviour behaviour;
+
+    const int displacement;
+    const int targetDim;
+};
+
+struct dynamicModifier_t {
+    dynamicModifier_t(Target t, dynamicBehaviour b, const size_t src, streamingUnit_t *su, int td = 0)
+        : target(t), behaviour(b), sourceStream(src), su(su), targetDim(td) {
+            indirectRegisterValue = 0;
+            sourceEnd = false;
+            modApplied = false;
+        }
+
+	void modDimension(std::deque<dimension_t> &dims, const size_t elementWidth);
+
+    bool isApplied() const {
+        return modApplied;
+    }
+
+    void setApplied(const bool s) {
+        modApplied = s;
+    }
+
+    int getTargetDim() const {
+        return targetDim;
+    }
+
+private:
+    const Target target;
+    const dynamicBehaviour behaviour;
+
+    bool modApplied;
+
+    const size_t sourceStream;
+    int indirectRegisterValue;
+    bool sourceEnd;
+
+    streamingUnit_t *su;
+
+    const int targetDim;
+
+    void calculateValueChange(auto &target, auto baseValue, dynamicBehaviour behaviour, int valueChange);
+    void getIndirectRegisterValues();
+};
+
+struct scatterGModifier_t {
+    scatterGModifier_t(dynamicBehaviour b, const size_t src, streamingUnit_t *su)
+        : behaviour(b), sourceStream(src), su(su) {
+            indirectRegisterValue = 0;
+            sourceEnd = false;
+            modApplied = false;
+        }
+
+	void modDimension(dimension_t &dim, const size_t elementWidth);
+
+    bool isApplied() const {
+        return modApplied;
+    }
+
+    void setApplied(const bool s) {
+        modApplied = s;
+    }
+
+private:
+    const Target target = Target::Offset; // Only offset is supported for now
+    const dynamicBehaviour behaviour;
+
+    bool modApplied;
+
+    const size_t sourceStream;
+    int indirectRegisterValue;
+    bool sourceEnd;
+
+    streamingUnit_t *su;
+
+    void calculateValueChange(auto &target, auto baseValue, dynamicBehaviour behaviour, int valueChange);
+    void getIndirectRegisterValues();
+};
+
+#endif // DIMENSION_HPP
diff --git a/riscv/disasm.h b/riscv/disasm.h
index d4b8c2c4..669aab38 100644
--- a/riscv/disasm.h
+++ b/riscv/disasm.h
@@ -14,6 +14,8 @@
 extern const char* xpr_name[NXPR];
 extern const char* fpr_name[NFPR];
 extern const char* vr_name[NVPR];
+extern const char* ur_name[NUPR]; // UVE vector registers
+extern const char* pr_name[NPR];  // UVE predicate registers
 extern const char* csr_name(int which);

 class arg_t
diff --git a/riscv/encoding.h b/riscv/encoding.h
index 4b2e0b65..ac9b67f1 100644
--- a/riscv/encoding.h
+++ b/riscv/encoding.h
@@ -4,7 +4,7 @@

 /*
  * This file is auto-generated by running 'make' in
- * https://github.com/riscv/riscv-opcodes (7bed351)
+ * https://github.com/riscv/riscv-opcodes (49f696b)
  */

 #ifndef RISCV_CSR_ENCODING_H
@@ -30,6 +30,7 @@
 #define MSTATUS_TW          0x00200000
 #define MSTATUS_TSR         0x00400000
 #define MSTATUS_SPELP       0x00800000
+#define MSTATUS_SDT         0x01000000
 #define MSTATUS32_SD        0x80000000
 #define MSTATUS_UXL         0x0000000300000000
 #define MSTATUS_SXL         0x0000000C00000000
@@ -38,12 +39,14 @@
 #define MSTATUS_GVA         0x0000004000000000
 #define MSTATUS_MPV         0x0000008000000000
 #define MSTATUS_MPELP       0x0000020000000000
+#define MSTATUS_MDT         0x0000040000000000
 #define MSTATUS64_SD        0x8000000000000000

 #define MSTATUSH_SBE        0x00000010
 #define MSTATUSH_MBE        0x00000020
 #define MSTATUSH_GVA        0x00000040
 #define MSTATUSH_MPV        0x00000080
+#define MSTATUSH_MDT        0x00000400

 #define SSTATUS_UIE         0x00000001
 #define SSTATUS_SIE         0x00000002
@@ -57,6 +60,7 @@
 #define SSTATUS_SUM         0x00040000
 #define SSTATUS_MXR         0x00080000
 #define SSTATUS_SPELP       0x00800000
+#define SSTATUS_SDT         0x01000000
 #define SSTATUS32_SD        0x80000000
 #define SSTATUS_UXL         0x0000000300000000
 #define SSTATUS64_SD        0x8000000000000000
@@ -79,19 +83,22 @@
 #define MNSTATUS_MNPP       0x00001800
 #define MNSTATUS_MNPV       0x00000080

-#define DCSR_XDEBUGVER      (3U<<30)
-#define DCSR_NDRESET        (1<<29)
-#define DCSR_FULLRESET      (1<<28)
+#define DCSR_XDEBUGVER      (15U<<28)
+#define DCSR_EXTCAUSE       (7<<24)
+#define DCSR_CETRIG         (1<<19)
 #define DCSR_PELP           (1<<18)
+#define DCSR_EBREAKVS       (1<<17)
+#define DCSR_EBREAKVU       (1<<16)
 #define DCSR_EBREAKM        (1<<15)
-#define DCSR_EBREAKH        (1<<14)
 #define DCSR_EBREAKS        (1<<13)
 #define DCSR_EBREAKU        (1<<12)
-#define DCSR_STOPCYCLE      (1<<10)
+#define DCSR_STEPIE         (1<<11)
+#define DCSR_STOPCOUNT      (1<<10)
 #define DCSR_STOPTIME       (1<<9)
 #define DCSR_CAUSE          (7<<6)
-#define DCSR_DEBUGINT       (1<<5)
-#define DCSR_HALT           (1<<3)
+#define DCSR_V              (1<<5)
+#define DCSR_MPRVEN         (1<<4)
+#define DCSR_NMIP           (1<<3)
 #define DCSR_STEP           (1<<2)
 #define DCSR_PRV            (3<<0)

@@ -168,10 +175,12 @@
 #define MENVCFG_CBIE  0x00000030
 #define MENVCFG_CBCFE 0x00000040
 #define MENVCFG_CBZE  0x00000080
+#define MENVCFG_DTE   0x0800000000000000
 #define MENVCFG_ADUE  0x2000000000000000
 #define MENVCFG_PBMTE 0x4000000000000000
 #define MENVCFG_STCE  0x8000000000000000

+#define MENVCFGH_DTE   0x08000000
 #define MENVCFGH_ADUE  0x20000000
 #define MENVCFGH_PBMTE 0x40000000
 #define MENVCFGH_STCE  0x80000000
@@ -179,6 +188,7 @@
 #define MSTATEEN0_CS       0x00000001
 #define MSTATEEN0_FCSR     0x00000002
 #define MSTATEEN0_JVT      0x00000004
+#define MSTATEEN0_CTR      0x0040000000000000
 #define MSTATEEN0_PRIV114  0x0080000000000000
 #define MSTATEEN0_HCONTEXT 0x0200000000000000
 #define MSTATEEN0_AIA      0x0800000000000000
@@ -186,6 +196,7 @@
 #define MSTATEEN0_HENVCFG  0x4000000000000000
 #define MSTATEEN_HSTATEEN  0x8000000000000000

+#define MSTATEEN0H_CTR      0x00400000
 #define MSTATEEN0H_PRIV114  0x00800000
 #define MSTATEEN0H_HCONTEXT 0x02000000
 #define MSTATEEN0H_AIA      0x08000000
@@ -213,10 +224,12 @@
 #define HENVCFG_CBIE  0x00000030
 #define HENVCFG_CBCFE 0x00000040
 #define HENVCFG_CBZE  0x00000080
+#define HENVCFG_DTE   0x0800000000000000
 #define HENVCFG_ADUE  0x2000000000000000
 #define HENVCFG_PBMTE 0x4000000000000000
 #define HENVCFG_STCE  0x8000000000000000

+#define HENVCFGH_DTE   0x08000000
 #define HENVCFGH_ADUE  0x20000000
 #define HENVCFGH_PBMTE 0x40000000
 #define HENVCFGH_STCE  0x80000000
@@ -236,12 +249,14 @@
 #define HSTATEEN0_CS       0x00000001
 #define HSTATEEN0_FCSR     0x00000002
 #define HSTATEEN0_JVT      0x00000004
+#define HSTATEEN0_CTR      0x0040000000000000
 #define HSTATEEN0_SCONTEXT 0x0200000000000000
 #define HSTATEEN0_AIA      0x0800000000000000
 #define HSTATEEN0_CSRIND   0x1000000000000000
 #define HSTATEEN0_SENVCFG  0x4000000000000000
 #define HSTATEEN_SSTATEEN  0x8000000000000000

+#define HSTATEEN0H_CTR      0x00400000
 #define HSTATEEN0H_SCONTEXT 0x02000000
 #define HSTATEEN0H_AIA      0x08000000
 #define HSTATEEN0H_CSRIND   0x10000000
@@ -324,6 +339,73 @@
 #define PMP_NA4   0x10
 #define PMP_NAPOT 0x18

+#define MCTRCTL_U          0x0000000000000001
+#define MCTRCTL_S          0x0000000000000002
+#define MCTRCTL_M          0x0000000000000004
+#define MCTRCTL_RASEMU     0x0000000000000080
+#define MCTRCTL_STE        0x0000000000000100
+#define MCTRCTL_MTE        0x0000000000000200
+#define MCTRCTL_BPFRZ      0x0000000000000800
+#define MCTRCTL_LCOFIFRZ   0x0000000000001000
+#define MCTRCTL_EXCINH     0x0000000200000000
+#define MCTRCTL_INTRINH    0x0000000400000000
+#define MCTRCTL_TRETINH    0x0000000800000000
+#define MCTRCTL_NTBREN     0x0000001000000000
+#define MCTRCTL_TKBRINH    0x0000002000000000
+#define MCTRCTL_INDCALLINH 0x0000010000000000
+#define MCTRCTL_DIRCALLINH 0x0000020000000000
+#define MCTRCTL_INDJMPINH  0x0000040000000000
+#define MCTRCTL_DIRJMPINH  0x0000080000000000
+#define MCTRCTL_CORSWAPINH 0x0000100000000000
+#define MCTRCTL_RETINH     0x0000200000000000
+#define MCTRCTL_INDLJMPINH 0x0000400000000000
+#define MCTRCTL_DIRLJMPINH 0x0000800000000000
+
+#define SCTRCTL_U          0x0000000000000001
+#define SCTRCTL_S          0x0000000000000002
+#define SCTRCTL_RASEMU     0x0000000000000080
+#define SCTRCTL_STE        0x0000000000000100
+#define SCTRCTL_BPFRZ      0x0000000000000800
+#define SCTRCTL_LCOFIFRZ   0x0000000000001000
+#define SCTRCTL_EXCINH     0x0000000200000000
+#define SCTRCTL_INTRINH    0x0000000400000000
+#define SCTRCTL_TRETINH    0x0000000800000000
+#define SCTRCTL_NTBREN     0x0000001000000000
+#define SCTRCTL_TKBRINH    0x0000002000000000
+#define SCTRCTL_INDCALLINH 0x0000010000000000
+#define SCTRCTL_DIRCALLINH 0x0000020000000000
+#define SCTRCTL_INDJMPINH  0x0000040000000000
+#define SCTRCTL_DIRJMPINH  0x0000080000000000
+#define SCTRCTL_CORSWAPINH 0x0000100000000000
+#define SCTRCTL_RETINH     0x0000200000000000
+#define SCTRCTL_INDLJMPINH 0x0000400000000000
+#define SCTRCTL_DIRLJMPINH 0x0000800000000000
+
+#define VSCTRCTL_U          0x0000000000000001
+#define VSCTRCTL_S          0x0000000000000002
+#define VSCTRCTL_RASEMU     0x0000000000000080
+#define VSCTRCTL_STE        0x0000000000000100
+#define VSCTRCTL_BPFRZ      0x0000000000000800
+#define VSCTRCTL_LCOFIFRZ   0x0000000000001000
+#define VSCTRCTL_EXCINH     0x0000000200000000
+#define VSCTRCTL_INTRINH    0x0000000400000000
+#define VSCTRCTL_TRETINH    0x0000000800000000
+#define VSCTRCTL_NTBREN     0x0000001000000000
+#define VSCTRCTL_TKBRINH    0x0000002000000000
+#define VSCTRCTL_INDCALLINH 0x0000010000000000
+#define VSCTRCTL_DIRCALLINH 0x0000020000000000
+#define VSCTRCTL_INDJMPINH  0x0000040000000000
+#define VSCTRCTL_DIRJMPINH  0x0000080000000000
+#define VSCTRCTL_CORSWAPINH 0x0000100000000000
+#define VSCTRCTL_RETINH     0x0000200000000000
+#define VSCTRCTL_INDLJMPINH 0x0000400000000000
+#define VSCTRCTL_DIRLJMPINH 0x0000800000000000
+
+#define SCTRDEPTH_DEPTH     0x00000007
+
+#define SCTRSTATUS_WRPTR    0x000000FF
+#define SCTRSTATUS_FROZEN   0x80000000
+
 #define IRQ_U_SOFT        0
 #define IRQ_S_SOFT        1
 #define IRQ_VS_SOFT       2
@@ -425,8 +507,6 @@
 #define RISCV_ENCODING_H
 #define MATCH_ADD 0x33
 #define MASK_ADD 0xfe00707f
-#define MATCH_ADD64 0xc0001077
-#define MASK_ADD64 0xfe00707f
 #define MATCH_ADD_UW 0x800003b
 #define MASK_ADD_UW 0xfe00707f
 #define MATCH_ADDI 0x13
@@ -1151,14 +1231,6 @@
 #define MASK_JAL 0x7f
 #define MATCH_JALR 0x67
 #define MASK_JALR 0x707f
-#define MATCH_KADD64 0x90001077
-#define MASK_KADD64 0xfe00707f
-#define MATCH_KMAR64 0x94001077
-#define MASK_KMAR64 0xfe00707f
-#define MATCH_KMSR64 0x96001077
-#define MASK_KMSR64 0xfe00707f
-#define MATCH_KSUB64 0x92001077
-#define MASK_KSUB64 0xfe00707f
 #define MATCH_LB 0x3
 #define MASK_LB 0x707f
 #define MATCH_LB_AQ 0x3400002f
@@ -1293,10 +1365,6 @@
 #define MASK_MULHSU 0xfe00707f
 #define MATCH_MULHU 0x2003033
 #define MASK_MULHU 0xfe00707f
-#define MATCH_MULR64 0xf0001077
-#define MASK_MULR64 0xfe00707f
-#define MATCH_MULSR64 0xe0001077
-#define MASK_MULSR64 0xfe00707f
 #define MATCH_MULW 0x200003b
 #define MASK_MULW 0xfe00707f
 #define MATCH_OR 0x6033
@@ -1319,8 +1387,6 @@
 #define MASK_PREFETCH_R 0x1f07fff
 #define MATCH_PREFETCH_W 0x306013
 #define MASK_PREFETCH_W 0x1f07fff
-#define MATCH_RADD64 0x80001077
-#define MASK_RADD64 0xfe00707f
 #define MATCH_REM 0x2006033
 #define MASK_REM 0xfe00707f
 #define MATCH_REMU 0x2007033
@@ -1341,8 +1407,6 @@
 #define MASK_RORIW 0xfe00707f
 #define MATCH_RORW 0x6000503b
 #define MASK_RORW 0xfe00707f
-#define MATCH_RSUB64 0x82001077
-#define MASK_RSUB64 0xfe00707f
 #define MATCH_SB 0x23
 #define MASK_SB 0x707f
 #define MATCH_SB_RL 0x3a00002f
@@ -1351,6 +1415,8 @@
 #define MASK_SC_D 0xf800707f
 #define MATCH_SC_W 0x1800202f
 #define MASK_SC_W 0xf800707f
+#define MATCH_SCTRCLR 0x10400073
+#define MASK_SCTRCLR 0xffffffff
 #define MATCH_SD 0x3023
 #define MASK_SD 0x707f
 #define MATCH_SD_RL 0x3a00302f
@@ -1425,14 +1491,6 @@
 #define MASK_SLLIW 0xfe00707f
 #define MATCH_SLLW 0x103b
 #define MASK_SLLW 0xfe00707f
-#define MATCH_SLO 0x20001033
-#define MASK_SLO 0xfe00707f
-#define MATCH_SLOI 0x20001013
-#define MASK_SLOI 0xfc00707f
-#define MATCH_SLOIW 0x2000101b
-#define MASK_SLOIW 0xfe00707f
-#define MATCH_SLOW 0x2000103b
-#define MASK_SLOW 0xfe00707f
 #define MATCH_SLT 0x2033
 #define MASK_SLT 0xfe00707f
 #define MATCH_SLTI 0x2013
@@ -1449,40 +1507,292 @@
 #define MASK_SM4ED 0x3e00707f
 #define MATCH_SM4KS 0x34000033
 #define MASK_SM4KS 0x3e00707f
-#define MATCH_SMAL 0x5e001077
-#define MASK_SMAL 0xfe00707f
-#define MATCH_SMALBB 0x88001077
-#define MASK_SMALBB 0xfe00707f
-#define MATCH_SMALBT 0x98001077
-#define MASK_SMALBT 0xfe00707f
-#define MATCH_SMALDA 0x8c001077
-#define MASK_SMALDA 0xfe00707f
-#define MATCH_SMALDRS 0x9a001077
-#define MASK_SMALDRS 0xfe00707f
-#define MATCH_SMALDS 0x8a001077
-#define MASK_SMALDS 0xfe00707f
-#define MATCH_SMALTT 0xa8001077
-#define MASK_SMALTT 0xfe00707f
-#define MATCH_SMALXDA 0x9c001077
-#define MASK_SMALXDA 0xfe00707f
-#define MATCH_SMALXDS 0xaa001077
-#define MASK_SMALXDS 0xfe00707f
-#define MATCH_SMAR64 0x84001077
-#define MASK_SMAR64 0xfe00707f
-#define MATCH_SMSLDA 0xac001077
-#define MASK_SMSLDA 0xfe00707f
-#define MATCH_SMSLXDA 0xbc001077
-#define MASK_SMSLXDA 0xfe00707f
-#define MATCH_SMSR64 0x86001077
-#define MASK_SMSR64 0xfe00707f
-#define MATCH_SMUL16 0xa0000077
-#define MASK_SMUL16 0xfe00707f
-#define MATCH_SMUL8 0xa8000077
-#define MASK_SMUL8 0xfe00707f
-#define MATCH_SMULX16 0xa2000077
-#define MASK_SMULX16 0xfe00707f
-#define MATCH_SMULX8 0xaa000077
-#define MASK_SMULX8 0xfe00707f
+#define MATCH_SO_A_ABS_FP 0x3000102b
+#define MASK_SO_A_ABS_FP 0xf1f0707f
+#define MATCH_SO_A_ABS_SG 0x3000002b
+#define MASK_SO_A_ABS_SG 0xf1f0707f
+#define MATCH_SO_A_ADD_FP 0x102b
+#define MASK_SO_A_ADD_FP 0xf000707f
+#define MATCH_SO_A_ADD_SG 0x202b
+#define MASK_SO_A_ADD_SG 0xf000707f
+#define MATCH_SO_A_ADD_US 0x2b
+#define MASK_SO_A_ADD_US 0xf000707f
+#define MATCH_SO_A_ADDE_ACC_FP 0x2010102b
+#define MASK_SO_A_ADDE_ACC_FP 0xf1f0707f
+#define MATCH_SO_A_ADDE_ACC_SG 0x2010202b
+#define MASK_SO_A_ADDE_ACC_SG 0xf1f0707f
+#define MATCH_SO_A_ADDE_ACC_US 0x2010002b
+#define MASK_SO_A_ADDE_ACC_US 0xf1f0707f
+#define MATCH_SO_A_ADDE_FP 0x2000102b
+#define MASK_SO_A_ADDE_FP 0xf1f0707f
+#define MATCH_SO_A_ADDE_SG 0x2000202b
+#define MASK_SO_A_ADDE_SG 0xf1f0707f
+#define MATCH_SO_A_ADDE_US 0x2000002b
+#define MASK_SO_A_ADDE_US 0xf1f0707f
+#define MATCH_SO_A_ADDS_ACC_FP 0x2010502b
+#define MASK_SO_A_ADDS_ACC_FP 0xf1f0707f
+#define MATCH_SO_A_ADDS_ACC_SG 0x2010602b
+#define MASK_SO_A_ADDS_ACC_SG 0xf1f0707f
+#define MATCH_SO_A_ADDS_ACC_US 0x2010402b
+#define MASK_SO_A_ADDS_ACC_US 0xf1f0707f
+#define MATCH_SO_A_ADDS_FP 0x2000502b
+#define MASK_SO_A_ADDS_FP 0xf1f0707f
+#define MATCH_SO_A_ADDS_SG 0x2000602b
+#define MASK_SO_A_ADDS_SG 0xf1f0707f
+#define MATCH_SO_A_ADDS_US 0x2000402b
+#define MASK_SO_A_ADDS_US 0xf1f0707f
+#define MATCH_SO_A_AND 0xc000102b
+#define MASK_SO_A_AND 0xf000707f
+#define MATCH_SO_A_DEC_FP 0x6000502b
+#define MASK_SO_A_DEC_FP 0xf1f0707f
+#define MATCH_SO_A_DEC_SG 0x6000602b
+#define MASK_SO_A_DEC_SG 0xf1f0707f
+#define MATCH_SO_A_DEC_US 0x6000402b
+#define MASK_SO_A_DEC_US 0xf1f0707f
+#define MATCH_SO_A_DIV_FP 0x1000502b
+#define MASK_SO_A_DIV_FP 0xf000707f
+#define MATCH_SO_A_DIV_SG 0x1000602b
+#define MASK_SO_A_DIV_SG 0xf000707f
+#define MATCH_SO_A_DIV_US 0x1000402b
+#define MASK_SO_A_DIV_US 0xf000707f
+#define MATCH_SO_A_INC_FP 0x6000102b
+#define MASK_SO_A_INC_FP 0xf1f0707f
+#define MATCH_SO_A_INC_SG 0x6000202b
+#define MASK_SO_A_INC_SG 0xf1f0707f
+#define MATCH_SO_A_INC_US 0x6000002b
+#define MASK_SO_A_INC_US 0xf1f0707f
+#define MATCH_SO_A_MAC_FP 0x3000502b
+#define MASK_SO_A_MAC_FP 0xf000707f
+#define MATCH_SO_A_MAC_SG 0x3000602b
+#define MASK_SO_A_MAC_SG 0xf000707f
+#define MATCH_SO_A_MAC_US 0x3000402b
+#define MASK_SO_A_MAC_US 0xf000707f
+#define MATCH_SO_A_MAX_FP 0x4000502b
+#define MASK_SO_A_MAX_FP 0xf000707f
+#define MATCH_SO_A_MAX_SG 0x4000602b
+#define MASK_SO_A_MAX_SG 0xf000707f
+#define MATCH_SO_A_MAX_US 0x4000402b
+#define MASK_SO_A_MAX_US 0xf000707f
+#define MATCH_SO_A_MAXE_FP 0x5000502b
+#define MASK_SO_A_MAXE_FP 0xf1f0707f
+#define MATCH_SO_A_MAXE_SG 0x5000602b
+#define MASK_SO_A_MAXE_SG 0xf1f0707f
+#define MATCH_SO_A_MAXE_US 0x5000402b
+#define MASK_SO_A_MAXE_US 0xf1f0707f
+#define MATCH_SO_A_MIN_FP 0x4000102b
+#define MASK_SO_A_MIN_FP 0xf000707f
+#define MATCH_SO_A_MIN_SG 0x4000202b
+#define MASK_SO_A_MIN_SG 0xf000707f
+#define MATCH_SO_A_MIN_US 0x4000002b
+#define MASK_SO_A_MIN_US 0xf000707f
+#define MATCH_SO_A_MINE_FP 0x5000102b
+#define MASK_SO_A_MINE_FP 0xf1f0707f
+#define MATCH_SO_A_MINE_SG 0x5000202b
+#define MASK_SO_A_MINE_SG 0xf1f0707f
+#define MATCH_SO_A_MINE_US 0x5000002b
+#define MASK_SO_A_MINE_US 0xf1f0707f
+#define MATCH_SO_A_MUL_FP 0x1000102b
+#define MASK_SO_A_MUL_FP 0xf000707f
+#define MATCH_SO_A_MUL_SG 0x1000202b
+#define MASK_SO_A_MUL_SG 0xf000707f
+#define MATCH_SO_A_MUL_US 0x1000002b
+#define MASK_SO_A_MUL_US 0xf000707f
+#define MATCH_SO_A_NAND 0xc000002b
+#define MASK_SO_A_NAND 0xf000707f
+#define MATCH_SO_A_NOR 0xc000202b
+#define MASK_SO_A_NOR 0xf000707f
+#define MATCH_SO_A_NOT 0xc000402b
+#define MASK_SO_A_NOT 0xf1f0707f
+#define MATCH_SO_A_OR 0xc000302b
+#define MASK_SO_A_OR 0xf000707f
+#define MATCH_SO_A_SLL 0xd000002b
+#define MASK_SO_A_SLL 0xf000707f
+#define MATCH_SO_A_SLLS 0xd000102b
+#define MASK_SO_A_SLLS 0xf000707f
+#define MATCH_SO_A_SRA 0xd000402b
+#define MASK_SO_A_SRA 0xf000707f
+#define MATCH_SO_A_SRAS 0xd000502b
+#define MASK_SO_A_SRAS 0xf000707f
+#define MATCH_SO_A_SRL 0xd000202b
+#define MASK_SO_A_SRL 0xf000707f
+#define MATCH_SO_A_SRLS 0xd000302b
+#define MASK_SO_A_SRLS 0xf000707f
+#define MATCH_SO_A_SUB_FP 0x502b
+#define MASK_SO_A_SUB_FP 0xf000707f
+#define MATCH_SO_A_SUB_SG 0x602b
+#define MASK_SO_A_SUB_SG 0xf000707f
+#define MATCH_SO_A_SUB_US 0x402b
+#define MASK_SO_A_SUB_US 0xf000707f
+#define MATCH_SO_A_XOR 0xc000502b
+#define MASK_SO_A_XOR 0xf000707f
+#define MATCH_SO_B_C 0xe000702b
+#define MASK_SO_B_C 0xe030707f
+#define MATCH_SO_B_DC_1 0xe000002b
+#define MASK_SO_B_DC_1 0xe030707f
+#define MATCH_SO_B_DC_2 0xe000102b
+#define MASK_SO_B_DC_2 0xe030707f
+#define MATCH_SO_B_DC_3 0xe000202b
+#define MASK_SO_B_DC_3 0xe030707f
+#define MATCH_SO_B_DC_4 0xe000302b
+#define MASK_SO_B_DC_4 0xe030707f
+#define MATCH_SO_B_DC_5 0xe000402b
+#define MASK_SO_B_DC_5 0xe030707f
+#define MATCH_SO_B_DC_6 0xe000502b
+#define MASK_SO_B_DC_6 0xe030707f
+#define MATCH_SO_B_DC_7 0xe000602b
+#define MASK_SO_B_DC_7 0xe030707f
+#define MATCH_SO_B_NC 0xe010702b
+#define MASK_SO_B_NC 0xe030707f
+#define MATCH_SO_B_NDC_1 0xe010002b
+#define MASK_SO_B_NDC_1 0xe030707f
+#define MATCH_SO_B_NDC_2 0xe010102b
+#define MASK_SO_B_NDC_2 0xe030707f
+#define MATCH_SO_B_NDC_3 0xe010202b
+#define MASK_SO_B_NDC_3 0xe030707f
+#define MATCH_SO_B_NDC_4 0xe010302b
+#define MASK_SO_B_NDC_4 0xe030707f
+#define MATCH_SO_B_NDC_5 0xe010402b
+#define MASK_SO_B_NDC_5 0xe030707f
+#define MATCH_SO_B_NDC_6 0xe010502b
+#define MASK_SO_B_NDC_6 0xe030707f
+#define MATCH_SO_B_NDC_7 0xe010602b
+#define MASK_SO_B_NDC_7 0xe030707f
+#define MATCH_SO_C_BREAK 0xb000302b
+#define MASK_SO_C_BREAK 0xfffff07f
+#define MATCH_SO_C_GETVL 0xb000702b
+#define MASK_SO_C_GETVL 0xfffff07f
+#define MATCH_SO_C_RESUM 0xb000202b
+#define MASK_SO_C_RESUM 0xfffff07f
+#define MATCH_SO_C_SETVL 0xb000002b
+#define MASK_SO_C_SETVL 0xfff0707f
+#define MATCH_SO_C_SUSPD 0xb000102b
+#define MASK_SO_C_SUSPD 0xfffff07f
+#define MATCH_SO_C_VLOAD 0xb000402b
+#define MASK_SO_C_VLOAD 0xfffff07f
+#define MATCH_SO_C_VSTOR 0xb000502b
+#define MASK_SO_C_VSTOR 0xfffff07f
+#define MATCH_SO_P_CV_B_B 0x8000302b
+#define MASK_SO_P_CV_B_B 0xfff8787f
+#define MATCH_SO_P_CV_B_B_Z 0x8100302b
+#define MASK_SO_P_CV_B_B_Z 0xfff8787f
+#define MATCH_SO_P_CV_D_D 0x80f0302b
+#define MASK_SO_P_CV_D_D 0xfff8787f
+#define MATCH_SO_P_CV_D_D_Z 0x81f0302b
+#define MASK_SO_P_CV_D_D_Z 0xfff8787f
+#define MATCH_SO_P_CV_H_H 0x8050302b
+#define MASK_SO_P_CV_H_H 0xfff8787f
+#define MATCH_SO_P_CV_H_H_Z 0x8150302b
+#define MASK_SO_P_CV_H_H_Z 0xfff8787f
+#define MATCH_SO_P_CV_W_W 0x80a0302b
+#define MASK_SO_P_CV_W_W 0xfff8787f
+#define MATCH_SO_P_CV_W_W_Z 0x81a0302b
+#define MASK_SO_P_CV_W_W_Z 0xfff8787f
+#define MATCH_SO_P_EQ_FP 0x9000102b
+#define MASK_SO_P_EQ_FP 0xf000787f
+#define MATCH_SO_P_EQ_FP_Z 0x9000182b
+#define MASK_SO_P_EQ_FP_Z 0xf000787f
+#define MATCH_SO_P_EQ_SG 0x9000202b
+#define MASK_SO_P_EQ_SG 0xf000787f
+#define MATCH_SO_P_EQ_SG_Z 0x9000282b
+#define MASK_SO_P_EQ_SG_Z 0xf000787f
+#define MATCH_SO_P_EQ_US 0x9000002b
+#define MASK_SO_P_EQ_US 0xf000787f
+#define MATCH_SO_P_EQ_US_Z 0x9000082b
+#define MASK_SO_P_EQ_US_Z 0xf000787f
+#define MATCH_SO_P_GE_FP 0x8000502b
+#define MASK_SO_P_GE_FP 0xf000787f
+#define MATCH_SO_P_GE_FP_Z 0x8000582b
+#define MASK_SO_P_GE_FP_Z 0xf000787f
+#define MATCH_SO_P_GE_SG 0x8000602b
+#define MASK_SO_P_GE_SG 0xf000787f
+#define MATCH_SO_P_GE_SG_Z 0x8000682b
+#define MASK_SO_P_GE_SG_Z 0xf000787f
+#define MATCH_SO_P_GE_US 0x8000402b
+#define MASK_SO_P_GE_US 0xf000787f
+#define MATCH_SO_P_GE_US_Z 0x8000482b
+#define MASK_SO_P_GE_US_Z 0xf000787f
+#define MATCH_SO_P_LT_FP 0x9000502b
+#define MASK_SO_P_LT_FP 0xf000787f
+#define MATCH_SO_P_LT_FP_Z 0x9000582b
+#define MASK_SO_P_LT_FP_Z 0xf000787f
+#define MATCH_SO_P_LT_SG 0x9000602b
+#define MASK_SO_P_LT_SG 0xf000787f
+#define MATCH_SO_P_LT_SG_Z 0x9000682b
+#define MASK_SO_P_LT_SG_Z 0xf000787f
+#define MATCH_SO_P_LT_US 0x9000402b
+#define MASK_SO_P_LT_US 0xf000787f
+#define MATCH_SO_P_LT_US_Z 0x9000482b
+#define MASK_SO_P_LT_US_Z 0xf000787f
+#define MATCH_SO_P_MV 0x8000202b
+#define MASK_SO_P_MV 0xf1f8787f
+#define MATCH_SO_P_MV_Z 0x8100202b
+#define MASK_SO_P_MV_Z 0xf1f8787f
+#define MATCH_SO_P_MVT 0x8000282b
+#define MASK_SO_P_MVT 0xf1f8787f
+#define MATCH_SO_P_MVT_Z 0x8100282b
+#define MASK_SO_P_MVT_Z 0xf1f8787f
+#define MATCH_SO_P_NOT 0x8000182b
+#define MASK_SO_P_NOT 0xf1f8787f
+#define MATCH_SO_P_NOT_Z 0x8100182b
+#define MASK_SO_P_NOT_Z 0xf1f8787f
+#define MATCH_SO_P_ONE 0x8000082b
+#define MASK_SO_P_ONE 0xf1fff87f
+#define MATCH_SO_P_ONE_Z 0x8100082b
+#define MASK_SO_P_ONE_Z 0xf1fff87f
+#define MATCH_SO_P_VR 0x8000102b
+#define MASK_SO_P_VR 0xf1f0787f
+#define MATCH_SO_P_VR_Z 0x8100102b
+#define MASK_SO_P_VR_Z 0xf1f0787f
+#define MATCH_SO_P_ZERO 0x8000002b
+#define MASK_SO_P_ZERO 0xf1fff87f
+#define MATCH_SO_P_ZERO_Z 0x8100002b
+#define MASK_SO_P_ZERO_Z 0xf1fff87f
+#define MATCH_SO_V_CV_FP_B 0xaa80002b
+#define MASK_SO_V_CV_FP_B 0xfff0707f
+#define MATCH_SO_V_CV_FP_D 0xaa80302b
+#define MASK_SO_V_CV_FP_D 0xfff0707f
+#define MATCH_SO_V_CV_FP_H 0xaa80102b
+#define MASK_SO_V_CV_FP_H 0xfff0707f
+#define MATCH_SO_V_CV_FP_W 0xaa80202b
+#define MASK_SO_V_CV_FP_W 0xfff0707f
+#define MATCH_SO_V_CV_SG_B 0xab00002b
+#define MASK_SO_V_CV_SG_B 0xfff0707f
+#define MATCH_SO_V_CV_SG_D 0xab00302b
+#define MASK_SO_V_CV_SG_D 0xfff0707f
+#define MATCH_SO_V_CV_SG_H 0xab00102b
+#define MASK_SO_V_CV_SG_H 0xfff0707f
+#define MATCH_SO_V_CV_SG_W 0xab00202b
+#define MASK_SO_V_CV_SG_W 0xfff0707f
+#define MATCH_SO_V_CV_US_B 0xaa00002b
+#define MASK_SO_V_CV_US_B 0xfff0707f
+#define MATCH_SO_V_CV_US_D 0xaa00302b
+#define MASK_SO_V_CV_US_D 0xfff0707f
+#define MATCH_SO_V_CV_US_H 0xaa00102b
+#define MASK_SO_V_CV_US_H 0xfff0707f
+#define MATCH_SO_V_CV_US_W 0xaa00202b
+#define MASK_SO_V_CV_US_W 0xfff0707f
+#define MATCH_SO_V_DP_B 0xac00002b
+#define MASK_SO_V_DP_B 0xff80707f
+#define MATCH_SO_V_DP_D 0xac00302b
+#define MASK_SO_V_DP_D 0xff80707f
+#define MATCH_SO_V_DP_H 0xac00102b
+#define MASK_SO_V_DP_H 0xff80707f
+#define MATCH_SO_V_DP_W 0xac00202b
+#define MASK_SO_V_DP_W 0xff80707f
+#define MATCH_SO_V_MV 0xa800002b
+#define MASK_SO_V_MV 0xff80707f
+#define MATCH_SO_V_MVSV_B 0xa980002b
+#define MASK_SO_V_MVSV_B 0xfff0707f
+#define MATCH_SO_V_MVSV_D 0xa980302b
+#define MASK_SO_V_MVSV_D 0xfff0707f
+#define MATCH_SO_V_MVSV_H 0xa980102b
+#define MASK_SO_V_MVSV_H 0xfff0707f
+#define MATCH_SO_V_MVSV_W 0xa980202b
+#define MASK_SO_V_MVSV_W 0xfff0707f
+#define MATCH_SO_V_MVT 0xa880002b
+#define MASK_SO_V_MVT 0xff80707f
+#define MATCH_SO_V_MVVS 0xa900002b
+#define MASK_SO_V_MVVS 0xfff0707f
 #define MATCH_SRA 0x40005033
 #define MASK_SRA 0xfe00707f
 #define MATCH_SRAI 0x40005013
@@ -1505,14 +1815,1582 @@
 #define MASK_SRLIW 0xfe00707f
 #define MATCH_SRLW 0x503b
 #define MASK_SRLW 0xfe00707f
-#define MATCH_SRO 0x20005033
-#define MASK_SRO 0xfe00707f
-#define MATCH_SROI 0x20005013
-#define MASK_SROI 0xfc00707f
-#define MATCH_SROIW 0x2000501b
-#define MASK_SROIW 0xfe00707f
-#define MATCH_SROW 0x2000503b
-#define MASK_SROW 0xfe00707f
+#define MATCH_SS_APP 0x200000b
+#define MASK_SS_APP 0x600707f
+#define MATCH_SS_APP_IND_OFS_ADD_1 0x2a0600b
+#define MASK_SS_APP_IND_OFS_ADD_1 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_ADD_2 0x12a0600b
+#define MASK_SS_APP_IND_OFS_ADD_2 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_ADD_3 0x22a0600b
+#define MASK_SS_APP_IND_OFS_ADD_3 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_ADD_4 0x32a0600b
+#define MASK_SS_APP_IND_OFS_ADD_4 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_ADD_5 0x42a0600b
+#define MASK_SS_APP_IND_OFS_ADD_5 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_ADD_6 0x52a0600b
+#define MASK_SS_APP_IND_OFS_ADD_6 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_ADD_7 0x62a0600b
+#define MASK_SS_APP_IND_OFS_ADD_7 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_ADD_L 0x72a0600b
+#define MASK_SS_APP_IND_OFS_ADD_L 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_DEC_1 0x260600b
+#define MASK_SS_APP_IND_OFS_DEC_1 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_DEC_2 0x1260600b
+#define MASK_SS_APP_IND_OFS_DEC_2 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_DEC_3 0x2260600b
+#define MASK_SS_APP_IND_OFS_DEC_3 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_DEC_4 0x3260600b
+#define MASK_SS_APP_IND_OFS_DEC_4 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_DEC_5 0x4260600b
+#define MASK_SS_APP_IND_OFS_DEC_5 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_DEC_6 0x5260600b
+#define MASK_SS_APP_IND_OFS_DEC_6 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_DEC_7 0x6260600b
+#define MASK_SS_APP_IND_OFS_DEC_7 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_DEC_L 0x7260600b
+#define MASK_SS_APP_IND_OFS_DEC_L 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_INC_1 0x220600b
+#define MASK_SS_APP_IND_OFS_INC_1 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_INC_2 0x1220600b
+#define MASK_SS_APP_IND_OFS_INC_2 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_INC_3 0x2220600b
+#define MASK_SS_APP_IND_OFS_INC_3 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_INC_4 0x3220600b
+#define MASK_SS_APP_IND_OFS_INC_4 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_INC_5 0x4220600b
+#define MASK_SS_APP_IND_OFS_INC_5 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_INC_6 0x5220600b
+#define MASK_SS_APP_IND_OFS_INC_6 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_INC_7 0x6220600b
+#define MASK_SS_APP_IND_OFS_INC_7 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_INC_L 0x7220600b
+#define MASK_SS_APP_IND_OFS_INC_L 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_SET_1 0x320600b
+#define MASK_SS_APP_IND_OFS_SET_1 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_SET_2 0x1320600b
+#define MASK_SS_APP_IND_OFS_SET_2 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_SET_3 0x2320600b
+#define MASK_SS_APP_IND_OFS_SET_3 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_SET_4 0x3320600b
+#define MASK_SS_APP_IND_OFS_SET_4 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_SET_5 0x4320600b
+#define MASK_SS_APP_IND_OFS_SET_5 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_SET_6 0x5320600b
+#define MASK_SS_APP_IND_OFS_SET_6 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_SET_7 0x6320600b
+#define MASK_SS_APP_IND_OFS_SET_7 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_SET_L 0x7320600b
+#define MASK_SS_APP_IND_OFS_SET_L 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_SG_ADD 0xaa0600b
+#define MASK_SS_APP_IND_OFS_SG_ADD 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_SG_DEC 0xa60600b
+#define MASK_SS_APP_IND_OFS_SG_DEC 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_SG_INC 0xa20600b
+#define MASK_SS_APP_IND_OFS_SG_INC 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_SG_SET 0xb20600b
+#define MASK_SS_APP_IND_OFS_SG_SET 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_SG_SUB 0xae0600b
+#define MASK_SS_APP_IND_OFS_SG_SUB 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_SUB_1 0x2e0600b
+#define MASK_SS_APP_IND_OFS_SUB_1 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_SUB_2 0x12e0600b
+#define MASK_SS_APP_IND_OFS_SUB_2 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_SUB_3 0x22e0600b
+#define MASK_SS_APP_IND_OFS_SUB_3 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_SUB_4 0x32e0600b
+#define MASK_SS_APP_IND_OFS_SUB_4 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_SUB_5 0x42e0600b
+#define MASK_SS_APP_IND_OFS_SUB_5 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_SUB_6 0x52e0600b
+#define MASK_SS_APP_IND_OFS_SUB_6 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_SUB_7 0x62e0600b
+#define MASK_SS_APP_IND_OFS_SUB_7 0xfff0707f
+#define MATCH_SS_APP_IND_OFS_SUB_L 0x72e0600b
+#define MASK_SS_APP_IND_OFS_SUB_L 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_ADD_1 0x280600b
+#define MASK_SS_APP_IND_SIZ_ADD_1 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_ADD_2 0x1280600b
+#define MASK_SS_APP_IND_SIZ_ADD_2 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_ADD_3 0x2280600b
+#define MASK_SS_APP_IND_SIZ_ADD_3 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_ADD_4 0x3280600b
+#define MASK_SS_APP_IND_SIZ_ADD_4 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_ADD_5 0x4280600b
+#define MASK_SS_APP_IND_SIZ_ADD_5 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_ADD_6 0x5280600b
+#define MASK_SS_APP_IND_SIZ_ADD_6 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_ADD_7 0x6280600b
+#define MASK_SS_APP_IND_SIZ_ADD_7 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_ADD_L 0x7280600b
+#define MASK_SS_APP_IND_SIZ_ADD_L 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_DEC_1 0x240600b
+#define MASK_SS_APP_IND_SIZ_DEC_1 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_DEC_2 0x1240600b
+#define MASK_SS_APP_IND_SIZ_DEC_2 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_DEC_3 0x2240600b
+#define MASK_SS_APP_IND_SIZ_DEC_3 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_DEC_4 0x3240600b
+#define MASK_SS_APP_IND_SIZ_DEC_4 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_DEC_5 0x4240600b
+#define MASK_SS_APP_IND_SIZ_DEC_5 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_DEC_6 0x5240600b
+#define MASK_SS_APP_IND_SIZ_DEC_6 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_DEC_7 0x6240600b
+#define MASK_SS_APP_IND_SIZ_DEC_7 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_DEC_L 0x7240600b
+#define MASK_SS_APP_IND_SIZ_DEC_L 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_INC_1 0x200600b
+#define MASK_SS_APP_IND_SIZ_INC_1 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_INC_2 0x1200600b
+#define MASK_SS_APP_IND_SIZ_INC_2 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_INC_3 0x2200600b
+#define MASK_SS_APP_IND_SIZ_INC_3 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_INC_4 0x3200600b
+#define MASK_SS_APP_IND_SIZ_INC_4 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_INC_5 0x4200600b
+#define MASK_SS_APP_IND_SIZ_INC_5 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_INC_6 0x5200600b
+#define MASK_SS_APP_IND_SIZ_INC_6 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_INC_7 0x6200600b
+#define MASK_SS_APP_IND_SIZ_INC_7 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_INC_L 0x7200600b
+#define MASK_SS_APP_IND_SIZ_INC_L 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_SET_1 0x300600b
+#define MASK_SS_APP_IND_SIZ_SET_1 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_SET_2 0x1300600b
+#define MASK_SS_APP_IND_SIZ_SET_2 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_SET_3 0x2300600b
+#define MASK_SS_APP_IND_SIZ_SET_3 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_SET_4 0x3300600b
+#define MASK_SS_APP_IND_SIZ_SET_4 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_SET_5 0x4300600b
+#define MASK_SS_APP_IND_SIZ_SET_5 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_SET_6 0x5300600b
+#define MASK_SS_APP_IND_SIZ_SET_6 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_SET_7 0x6300600b
+#define MASK_SS_APP_IND_SIZ_SET_7 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_SET_L 0x7300600b
+#define MASK_SS_APP_IND_SIZ_SET_L 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_SUB_1 0x2c0600b
+#define MASK_SS_APP_IND_SIZ_SUB_1 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_SUB_2 0x12c0600b
+#define MASK_SS_APP_IND_SIZ_SUB_2 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_SUB_3 0x22c0600b
+#define MASK_SS_APP_IND_SIZ_SUB_3 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_SUB_4 0x32c0600b
+#define MASK_SS_APP_IND_SIZ_SUB_4 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_SUB_5 0x42c0600b
+#define MASK_SS_APP_IND_SIZ_SUB_5 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_SUB_6 0x52c0600b
+#define MASK_SS_APP_IND_SIZ_SUB_6 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_SUB_7 0x62c0600b
+#define MASK_SS_APP_IND_SIZ_SUB_7 0xfff0707f
+#define MATCH_SS_APP_IND_SIZ_SUB_L 0x72c0600b
+#define MASK_SS_APP_IND_SIZ_SUB_L 0xfff0707f
+#define MATCH_SS_APP_IND_STR_ADD_1 0x290600b
+#define MASK_SS_APP_IND_STR_ADD_1 0xfff0707f
+#define MATCH_SS_APP_IND_STR_ADD_2 0x1290600b
+#define MASK_SS_APP_IND_STR_ADD_2 0xfff0707f
+#define MATCH_SS_APP_IND_STR_ADD_3 0x2290600b
+#define MASK_SS_APP_IND_STR_ADD_3 0xfff0707f
+#define MATCH_SS_APP_IND_STR_ADD_4 0x3290600b
+#define MASK_SS_APP_IND_STR_ADD_4 0xfff0707f
+#define MATCH_SS_APP_IND_STR_ADD_5 0x4290600b
+#define MASK_SS_APP_IND_STR_ADD_5 0xfff0707f
+#define MATCH_SS_APP_IND_STR_ADD_6 0x5290600b
+#define MASK_SS_APP_IND_STR_ADD_6 0xfff0707f
+#define MATCH_SS_APP_IND_STR_ADD_7 0x6290600b
+#define MASK_SS_APP_IND_STR_ADD_7 0xfff0707f
+#define MATCH_SS_APP_IND_STR_ADD_L 0x7290600b
+#define MASK_SS_APP_IND_STR_ADD_L 0xfff0707f
+#define MATCH_SS_APP_IND_STR_DEC_1 0x250600b
+#define MASK_SS_APP_IND_STR_DEC_1 0xfff0707f
+#define MATCH_SS_APP_IND_STR_DEC_2 0x1250600b
+#define MASK_SS_APP_IND_STR_DEC_2 0xfff0707f
+#define MATCH_SS_APP_IND_STR_DEC_3 0x2250600b
+#define MASK_SS_APP_IND_STR_DEC_3 0xfff0707f
+#define MATCH_SS_APP_IND_STR_DEC_4 0x3250600b
+#define MASK_SS_APP_IND_STR_DEC_4 0xfff0707f
+#define MATCH_SS_APP_IND_STR_DEC_5 0x4250600b
+#define MASK_SS_APP_IND_STR_DEC_5 0xfff0707f
+#define MATCH_SS_APP_IND_STR_DEC_6 0x5250600b
+#define MASK_SS_APP_IND_STR_DEC_6 0xfff0707f
+#define MATCH_SS_APP_IND_STR_DEC_7 0x6250600b
+#define MASK_SS_APP_IND_STR_DEC_7 0xfff0707f
+#define MATCH_SS_APP_IND_STR_DEC_L 0x7250600b
+#define MASK_SS_APP_IND_STR_DEC_L 0xfff0707f
+#define MATCH_SS_APP_IND_STR_INC_1 0x210600b
+#define MASK_SS_APP_IND_STR_INC_1 0xfff0707f
+#define MATCH_SS_APP_IND_STR_INC_2 0x1210600b
+#define MASK_SS_APP_IND_STR_INC_2 0xfff0707f
+#define MATCH_SS_APP_IND_STR_INC_3 0x2210600b
+#define MASK_SS_APP_IND_STR_INC_3 0xfff0707f
+#define MATCH_SS_APP_IND_STR_INC_4 0x3210600b
+#define MASK_SS_APP_IND_STR_INC_4 0xfff0707f
+#define MATCH_SS_APP_IND_STR_INC_5 0x4210600b
+#define MASK_SS_APP_IND_STR_INC_5 0xfff0707f
+#define MATCH_SS_APP_IND_STR_INC_6 0x5210600b
+#define MASK_SS_APP_IND_STR_INC_6 0xfff0707f
+#define MATCH_SS_APP_IND_STR_INC_7 0x6210600b
+#define MASK_SS_APP_IND_STR_INC_7 0xfff0707f
+#define MATCH_SS_APP_IND_STR_INC_L 0x7210600b
+#define MASK_SS_APP_IND_STR_INC_L 0xfff0707f
+#define MATCH_SS_APP_IND_STR_SET_1 0x310600b
+#define MASK_SS_APP_IND_STR_SET_1 0xfff0707f
+#define MATCH_SS_APP_IND_STR_SET_2 0x1310600b
+#define MASK_SS_APP_IND_STR_SET_2 0xfff0707f
+#define MATCH_SS_APP_IND_STR_SET_3 0x2310600b
+#define MASK_SS_APP_IND_STR_SET_3 0xfff0707f
+#define MATCH_SS_APP_IND_STR_SET_4 0x3310600b
+#define MASK_SS_APP_IND_STR_SET_4 0xfff0707f
+#define MATCH_SS_APP_IND_STR_SET_5 0x4310600b
+#define MASK_SS_APP_IND_STR_SET_5 0xfff0707f
+#define MATCH_SS_APP_IND_STR_SET_6 0x5310600b
+#define MASK_SS_APP_IND_STR_SET_6 0xfff0707f
+#define MATCH_SS_APP_IND_STR_SET_7 0x6310600b
+#define MASK_SS_APP_IND_STR_SET_7 0xfff0707f
+#define MATCH_SS_APP_IND_STR_SET_L 0x7310600b
+#define MASK_SS_APP_IND_STR_SET_L 0xfff0707f
+#define MATCH_SS_APP_IND_STR_SUB_1 0x2d0600b
+#define MASK_SS_APP_IND_STR_SUB_1 0xfff0707f
+#define MATCH_SS_APP_IND_STR_SUB_2 0x12d0600b
+#define MASK_SS_APP_IND_STR_SUB_2 0xfff0707f
+#define MATCH_SS_APP_IND_STR_SUB_3 0x22d0600b
+#define MASK_SS_APP_IND_STR_SUB_3 0xfff0707f
+#define MATCH_SS_APP_IND_STR_SUB_4 0x32d0600b
+#define MASK_SS_APP_IND_STR_SUB_4 0xfff0707f
+#define MATCH_SS_APP_IND_STR_SUB_5 0x42d0600b
+#define MASK_SS_APP_IND_STR_SUB_5 0xfff0707f
+#define MATCH_SS_APP_IND_STR_SUB_6 0x52d0600b
+#define MASK_SS_APP_IND_STR_SUB_6 0xfff0707f
+#define MATCH_SS_APP_IND_STR_SUB_7 0x62d0600b
+#define MASK_SS_APP_IND_STR_SUB_7 0xfff0707f
+#define MATCH_SS_APP_IND_STR_SUB_L 0x72d0600b
+#define MASK_SS_APP_IND_STR_SUB_L 0xfff0707f
+#define MATCH_SS_APP_MOD_OFS_DEC_1 0x260400b
+#define MASK_SS_APP_MOD_OFS_DEC_1 0x7fff07f
+#define MATCH_SS_APP_MOD_OFS_DEC_2 0x260c00b
+#define MASK_SS_APP_MOD_OFS_DEC_2 0x7fff07f
+#define MATCH_SS_APP_MOD_OFS_DEC_3 0x261400b
+#define MASK_SS_APP_MOD_OFS_DEC_3 0x7fff07f
+#define MATCH_SS_APP_MOD_OFS_DEC_4 0x261c00b
+#define MASK_SS_APP_MOD_OFS_DEC_4 0x7fff07f
+#define MATCH_SS_APP_MOD_OFS_DEC_5 0x262400b
+#define MASK_SS_APP_MOD_OFS_DEC_5 0x7fff07f
+#define MATCH_SS_APP_MOD_OFS_DEC_6 0x262c00b
+#define MASK_SS_APP_MOD_OFS_DEC_6 0x7fff07f
+#define MATCH_SS_APP_MOD_OFS_DEC_7 0x263400b
+#define MASK_SS_APP_MOD_OFS_DEC_7 0x7fff07f
+#define MATCH_SS_APP_MOD_OFS_DEC_L 0x263c00b
+#define MASK_SS_APP_MOD_OFS_DEC_L 0x7fff07f
+#define MATCH_SS_APP_MOD_OFS_INC_1 0x220400b
+#define MASK_SS_APP_MOD_OFS_INC_1 0x7fff07f
+#define MATCH_SS_APP_MOD_OFS_INC_2 0x220c00b
+#define MASK_SS_APP_MOD_OFS_INC_2 0x7fff07f
+#define MATCH_SS_APP_MOD_OFS_INC_3 0x221400b
+#define MASK_SS_APP_MOD_OFS_INC_3 0x7fff07f
+#define MATCH_SS_APP_MOD_OFS_INC_4 0x221c00b
+#define MASK_SS_APP_MOD_OFS_INC_4 0x7fff07f
+#define MATCH_SS_APP_MOD_OFS_INC_5 0x222400b
+#define MASK_SS_APP_MOD_OFS_INC_5 0x7fff07f
+#define MATCH_SS_APP_MOD_OFS_INC_6 0x222c00b
+#define MASK_SS_APP_MOD_OFS_INC_6 0x7fff07f
+#define MATCH_SS_APP_MOD_OFS_INC_7 0x223400b
+#define MASK_SS_APP_MOD_OFS_INC_7 0x7fff07f
+#define MATCH_SS_APP_MOD_OFS_INC_L 0x223c00b
+#define MASK_SS_APP_MOD_OFS_INC_L 0x7fff07f
+#define MATCH_SS_APP_MOD_SIZ_DEC_1 0x240400b
+#define MASK_SS_APP_MOD_SIZ_DEC_1 0x7fff07f
+#define MATCH_SS_APP_MOD_SIZ_DEC_2 0x240c00b
+#define MASK_SS_APP_MOD_SIZ_DEC_2 0x7fff07f
+#define MATCH_SS_APP_MOD_SIZ_DEC_3 0x241400b
+#define MASK_SS_APP_MOD_SIZ_DEC_3 0x7fff07f
+#define MATCH_SS_APP_MOD_SIZ_DEC_4 0x241c00b
+#define MASK_SS_APP_MOD_SIZ_DEC_4 0x7fff07f
+#define MATCH_SS_APP_MOD_SIZ_DEC_5 0x242400b
+#define MASK_SS_APP_MOD_SIZ_DEC_5 0x7fff07f
+#define MATCH_SS_APP_MOD_SIZ_DEC_6 0x242c00b
+#define MASK_SS_APP_MOD_SIZ_DEC_6 0x7fff07f
+#define MATCH_SS_APP_MOD_SIZ_DEC_7 0x243400b
+#define MASK_SS_APP_MOD_SIZ_DEC_7 0x7fff07f
+#define MATCH_SS_APP_MOD_SIZ_DEC_L 0x243c00b
+#define MASK_SS_APP_MOD_SIZ_DEC_L 0x7fff07f
+#define MATCH_SS_APP_MOD_SIZ_INC_1 0x200400b
+#define MASK_SS_APP_MOD_SIZ_INC_1 0x7fff07f
+#define MATCH_SS_APP_MOD_SIZ_INC_2 0x200c00b
+#define MASK_SS_APP_MOD_SIZ_INC_2 0x7fff07f
+#define MATCH_SS_APP_MOD_SIZ_INC_3 0x201400b
+#define MASK_SS_APP_MOD_SIZ_INC_3 0x7fff07f
+#define MATCH_SS_APP_MOD_SIZ_INC_4 0x201c00b
+#define MASK_SS_APP_MOD_SIZ_INC_4 0x7fff07f
+#define MATCH_SS_APP_MOD_SIZ_INC_5 0x202400b
+#define MASK_SS_APP_MOD_SIZ_INC_5 0x7fff07f
+#define MATCH_SS_APP_MOD_SIZ_INC_6 0x202c00b
+#define MASK_SS_APP_MOD_SIZ_INC_6 0x7fff07f
+#define MATCH_SS_APP_MOD_SIZ_INC_7 0x203400b
+#define MASK_SS_APP_MOD_SIZ_INC_7 0x7fff07f
+#define MATCH_SS_APP_MOD_SIZ_INC_L 0x203c00b
+#define MASK_SS_APP_MOD_SIZ_INC_L 0x7fff07f
+#define MATCH_SS_APP_MOD_STR_DEC_1 0x250400b
+#define MASK_SS_APP_MOD_STR_DEC_1 0x7fff07f
+#define MATCH_SS_APP_MOD_STR_DEC_2 0x250c00b
+#define MASK_SS_APP_MOD_STR_DEC_2 0x7fff07f
+#define MATCH_SS_APP_MOD_STR_DEC_3 0x251400b
+#define MASK_SS_APP_MOD_STR_DEC_3 0x7fff07f
+#define MATCH_SS_APP_MOD_STR_DEC_4 0x251c00b
+#define MASK_SS_APP_MOD_STR_DEC_4 0x7fff07f
+#define MATCH_SS_APP_MOD_STR_DEC_5 0x252400b
+#define MASK_SS_APP_MOD_STR_DEC_5 0x7fff07f
+#define MATCH_SS_APP_MOD_STR_DEC_6 0x252c00b
+#define MASK_SS_APP_MOD_STR_DEC_6 0x7fff07f
+#define MATCH_SS_APP_MOD_STR_DEC_7 0x253400b
+#define MASK_SS_APP_MOD_STR_DEC_7 0x7fff07f
+#define MATCH_SS_APP_MOD_STR_DEC_L 0x253c00b
+#define MASK_SS_APP_MOD_STR_DEC_L 0x7fff07f
+#define MATCH_SS_APP_MOD_STR_INC_1 0x210400b
+#define MASK_SS_APP_MOD_STR_INC_1 0x7fff07f
+#define MATCH_SS_APP_MOD_STR_INC_2 0x210c00b
+#define MASK_SS_APP_MOD_STR_INC_2 0x7fff07f
+#define MATCH_SS_APP_MOD_STR_INC_3 0x211400b
+#define MASK_SS_APP_MOD_STR_INC_3 0x7fff07f
+#define MATCH_SS_APP_MOD_STR_INC_4 0x211c00b
+#define MASK_SS_APP_MOD_STR_INC_4 0x7fff07f
+#define MATCH_SS_APP_MOD_STR_INC_5 0x212400b
+#define MASK_SS_APP_MOD_STR_INC_5 0x7fff07f
+#define MATCH_SS_APP_MOD_STR_INC_6 0x212c00b
+#define MASK_SS_APP_MOD_STR_INC_6 0x7fff07f
+#define MATCH_SS_APP_MOD_STR_INC_7 0x213400b
+#define MASK_SS_APP_MOD_STR_INC_7 0x7fff07f
+#define MATCH_SS_APP_MOD_STR_INC_L 0x213c00b
+#define MASK_SS_APP_MOD_STR_INC_L 0x7fff07f
+#define MATCH_SS_END 0x400000b
+#define MASK_SS_END 0x600707f
+#define MATCH_SS_END_IND_OFS_SG_ADD 0xca0600b
+#define MASK_SS_END_IND_OFS_SG_ADD 0xfff0707f
+#define MATCH_SS_END_IND_OFS_SG_DEC 0xc60600b
+#define MASK_SS_END_IND_OFS_SG_DEC 0xfff0707f
+#define MATCH_SS_END_IND_OFS_SG_INC 0xc20600b
+#define MASK_SS_END_IND_OFS_SG_INC 0xfff0707f
+#define MATCH_SS_END_IND_OFS_SG_SET 0xd20600b
+#define MASK_SS_END_IND_OFS_SG_SET 0xfff0707f
+#define MATCH_SS_END_IND_OFS_SG_SUB 0xce0600b
+#define MASK_SS_END_IND_OFS_SG_SUB 0xfff0707f
+#define MATCH_SS_STA_LD_B 0x400b
+#define MASK_SS_STA_LD_B 0xfff0707f
+#define MATCH_SS_STA_LD_B_INDS 0x100400b
+#define MASK_SS_STA_LD_B_INDS 0xfff0707f
+#define MATCH_SS_STA_LD_B_INDS_MEM1 0x140400b
+#define MASK_SS_STA_LD_B_INDS_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_B_INDS_MEM2 0x180400b
+#define MASK_SS_STA_LD_B_INDS_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_B_INDS_MEM3 0x1c0400b
+#define MASK_SS_STA_LD_B_INDS_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_B_M 0x8000400b
+#define MASK_SS_STA_LD_B_M 0xfff0707f
+#define MATCH_SS_STA_LD_B_M_INDS 0x8100400b
+#define MASK_SS_STA_LD_B_M_INDS 0xfff0707f
+#define MATCH_SS_STA_LD_B_M_INDS_MEM1 0x8140400b
+#define MASK_SS_STA_LD_B_M_INDS_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_B_M_INDS_MEM2 0x8180400b
+#define MASK_SS_STA_LD_B_M_INDS_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_B_M_INDS_MEM3 0x81c0400b
+#define MASK_SS_STA_LD_B_M_INDS_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_B_M_MEM1 0x8040400b
+#define MASK_SS_STA_LD_B_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_B_M_MEM2 0x8080400b
+#define MASK_SS_STA_LD_B_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_B_M_MEM3 0x80c0400b
+#define MASK_SS_STA_LD_B_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_B_MEM1 0x40400b
+#define MASK_SS_STA_LD_B_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_B_MEM2 0x80400b
+#define MASK_SS_STA_LD_B_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_B_MEM3 0xc0400b
+#define MASK_SS_STA_LD_B_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_B_V 0x7800400b
+#define MASK_SS_STA_LD_B_V 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_1 0x4000400b
+#define MASK_SS_STA_LD_B_V_1 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_1_M 0xc000400b
+#define MASK_SS_STA_LD_B_V_1_M 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_1_M_MEM1 0xc040400b
+#define MASK_SS_STA_LD_B_V_1_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_1_M_MEM2 0xc080400b
+#define MASK_SS_STA_LD_B_V_1_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_1_M_MEM3 0xc0c0400b
+#define MASK_SS_STA_LD_B_V_1_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_1_MEM1 0x4040400b
+#define MASK_SS_STA_LD_B_V_1_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_1_MEM2 0x4080400b
+#define MASK_SS_STA_LD_B_V_1_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_1_MEM3 0x40c0400b
+#define MASK_SS_STA_LD_B_V_1_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_2 0x4800400b
+#define MASK_SS_STA_LD_B_V_2 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_2_M 0xc800400b
+#define MASK_SS_STA_LD_B_V_2_M 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_2_M_MEM1 0xc840400b
+#define MASK_SS_STA_LD_B_V_2_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_2_M_MEM2 0xc880400b
+#define MASK_SS_STA_LD_B_V_2_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_2_M_MEM3 0xc8c0400b
+#define MASK_SS_STA_LD_B_V_2_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_2_MEM1 0x4840400b
+#define MASK_SS_STA_LD_B_V_2_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_2_MEM2 0x4880400b
+#define MASK_SS_STA_LD_B_V_2_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_2_MEM3 0x48c0400b
+#define MASK_SS_STA_LD_B_V_2_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_3 0x5000400b
+#define MASK_SS_STA_LD_B_V_3 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_3_M 0xd000400b
+#define MASK_SS_STA_LD_B_V_3_M 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_3_M_MEM1 0xd040400b
+#define MASK_SS_STA_LD_B_V_3_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_3_M_MEM2 0xd080400b
+#define MASK_SS_STA_LD_B_V_3_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_3_M_MEM3 0xd0c0400b
+#define MASK_SS_STA_LD_B_V_3_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_3_MEM1 0x5040400b
+#define MASK_SS_STA_LD_B_V_3_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_3_MEM2 0x5080400b
+#define MASK_SS_STA_LD_B_V_3_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_3_MEM3 0x50c0400b
+#define MASK_SS_STA_LD_B_V_3_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_4 0x5800400b
+#define MASK_SS_STA_LD_B_V_4 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_4_M 0xd800400b
+#define MASK_SS_STA_LD_B_V_4_M 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_4_M_MEM1 0xd840400b
+#define MASK_SS_STA_LD_B_V_4_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_4_M_MEM2 0xd880400b
+#define MASK_SS_STA_LD_B_V_4_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_4_M_MEM3 0xd8c0400b
+#define MASK_SS_STA_LD_B_V_4_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_4_MEM1 0x5840400b
+#define MASK_SS_STA_LD_B_V_4_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_4_MEM2 0x5880400b
+#define MASK_SS_STA_LD_B_V_4_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_4_MEM3 0x58c0400b
+#define MASK_SS_STA_LD_B_V_4_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_5 0x6000400b
+#define MASK_SS_STA_LD_B_V_5 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_5_M 0xe000400b
+#define MASK_SS_STA_LD_B_V_5_M 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_5_M_MEM1 0xe040400b
+#define MASK_SS_STA_LD_B_V_5_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_5_M_MEM2 0xe080400b
+#define MASK_SS_STA_LD_B_V_5_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_5_M_MEM3 0xe0c0400b
+#define MASK_SS_STA_LD_B_V_5_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_5_MEM1 0x6040400b
+#define MASK_SS_STA_LD_B_V_5_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_5_MEM2 0x6080400b
+#define MASK_SS_STA_LD_B_V_5_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_5_MEM3 0x60c0400b
+#define MASK_SS_STA_LD_B_V_5_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_6 0x6800400b
+#define MASK_SS_STA_LD_B_V_6 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_6_M 0xe800400b
+#define MASK_SS_STA_LD_B_V_6_M 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_6_M_MEM1 0xe840400b
+#define MASK_SS_STA_LD_B_V_6_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_6_M_MEM2 0xe880400b
+#define MASK_SS_STA_LD_B_V_6_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_6_M_MEM3 0xe8c0400b
+#define MASK_SS_STA_LD_B_V_6_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_6_MEM1 0x6840400b
+#define MASK_SS_STA_LD_B_V_6_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_6_MEM2 0x6880400b
+#define MASK_SS_STA_LD_B_V_6_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_6_MEM3 0x68c0400b
+#define MASK_SS_STA_LD_B_V_6_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_7 0x7000400b
+#define MASK_SS_STA_LD_B_V_7 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_7_M 0xf000400b
+#define MASK_SS_STA_LD_B_V_7_M 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_7_M_MEM1 0xf040400b
+#define MASK_SS_STA_LD_B_V_7_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_7_M_MEM2 0xf080400b
+#define MASK_SS_STA_LD_B_V_7_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_7_M_MEM3 0xf0c0400b
+#define MASK_SS_STA_LD_B_V_7_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_7_MEM1 0x7040400b
+#define MASK_SS_STA_LD_B_V_7_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_7_MEM2 0x7080400b
+#define MASK_SS_STA_LD_B_V_7_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_7_MEM3 0x70c0400b
+#define MASK_SS_STA_LD_B_V_7_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_M 0xf800400b
+#define MASK_SS_STA_LD_B_V_M 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_M_MEM1 0xf840400b
+#define MASK_SS_STA_LD_B_V_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_M_MEM2 0xf880400b
+#define MASK_SS_STA_LD_B_V_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_M_MEM3 0xf8c0400b
+#define MASK_SS_STA_LD_B_V_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_MEM1 0x7840400b
+#define MASK_SS_STA_LD_B_V_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_MEM2 0x7880400b
+#define MASK_SS_STA_LD_B_V_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_B_V_MEM3 0x78c0400b
+#define MASK_SS_STA_LD_B_V_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_D 0x700b
+#define MASK_SS_STA_LD_D 0xfff0707f
+#define MATCH_SS_STA_LD_D_INDS 0x100700b
+#define MASK_SS_STA_LD_D_INDS 0xfff0707f
+#define MATCH_SS_STA_LD_D_INDS_MEM1 0x140700b
+#define MASK_SS_STA_LD_D_INDS_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_D_INDS_MEM2 0x180700b
+#define MASK_SS_STA_LD_D_INDS_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_D_INDS_MEM3 0x1c0700b
+#define MASK_SS_STA_LD_D_INDS_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_D_M 0x8000700b
+#define MASK_SS_STA_LD_D_M 0xfff0707f
+#define MATCH_SS_STA_LD_D_M_INDS 0x8100700b
+#define MASK_SS_STA_LD_D_M_INDS 0xfff0707f
+#define MATCH_SS_STA_LD_D_M_INDS_MEM1 0x8140700b
+#define MASK_SS_STA_LD_D_M_INDS_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_D_M_INDS_MEM2 0x8180700b
+#define MASK_SS_STA_LD_D_M_INDS_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_D_M_INDS_MEM3 0x81c0700b
+#define MASK_SS_STA_LD_D_M_INDS_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_D_M_MEM1 0x8040700b
+#define MASK_SS_STA_LD_D_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_D_M_MEM2 0x8080700b
+#define MASK_SS_STA_LD_D_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_D_M_MEM3 0x80c0700b
+#define MASK_SS_STA_LD_D_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_D_MEM1 0x40700b
+#define MASK_SS_STA_LD_D_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_D_MEM2 0x80700b
+#define MASK_SS_STA_LD_D_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_D_MEM3 0xc0700b
+#define MASK_SS_STA_LD_D_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_D_V 0x7800700b
+#define MASK_SS_STA_LD_D_V 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_1 0x4000700b
+#define MASK_SS_STA_LD_D_V_1 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_1_M 0xc000700b
+#define MASK_SS_STA_LD_D_V_1_M 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_1_M_MEM1 0xc040700b
+#define MASK_SS_STA_LD_D_V_1_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_1_M_MEM2 0xc080700b
+#define MASK_SS_STA_LD_D_V_1_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_1_M_MEM3 0xc0c0700b
+#define MASK_SS_STA_LD_D_V_1_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_1_MEM1 0x4040700b
+#define MASK_SS_STA_LD_D_V_1_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_1_MEM2 0x4080700b
+#define MASK_SS_STA_LD_D_V_1_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_1_MEM3 0x40c0700b
+#define MASK_SS_STA_LD_D_V_1_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_2 0x4800700b
+#define MASK_SS_STA_LD_D_V_2 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_2_M 0xc800700b
+#define MASK_SS_STA_LD_D_V_2_M 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_2_M_MEM1 0xc840700b
+#define MASK_SS_STA_LD_D_V_2_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_2_M_MEM2 0xc880700b
+#define MASK_SS_STA_LD_D_V_2_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_2_M_MEM3 0xc8c0700b
+#define MASK_SS_STA_LD_D_V_2_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_2_MEM1 0x4840700b
+#define MASK_SS_STA_LD_D_V_2_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_2_MEM2 0x4880700b
+#define MASK_SS_STA_LD_D_V_2_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_2_MEM3 0x48c0700b
+#define MASK_SS_STA_LD_D_V_2_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_3 0x5000700b
+#define MASK_SS_STA_LD_D_V_3 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_3_M 0xd000700b
+#define MASK_SS_STA_LD_D_V_3_M 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_3_M_MEM1 0xd040700b
+#define MASK_SS_STA_LD_D_V_3_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_3_M_MEM2 0xd080700b
+#define MASK_SS_STA_LD_D_V_3_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_3_M_MEM3 0xd0c0700b
+#define MASK_SS_STA_LD_D_V_3_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_3_MEM1 0x5040700b
+#define MASK_SS_STA_LD_D_V_3_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_3_MEM2 0x5080700b
+#define MASK_SS_STA_LD_D_V_3_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_3_MEM3 0x50c0700b
+#define MASK_SS_STA_LD_D_V_3_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_4 0x5800700b
+#define MASK_SS_STA_LD_D_V_4 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_4_M 0xd800700b
+#define MASK_SS_STA_LD_D_V_4_M 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_4_M_MEM1 0xd840700b
+#define MASK_SS_STA_LD_D_V_4_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_4_M_MEM2 0xd880700b
+#define MASK_SS_STA_LD_D_V_4_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_4_M_MEM3 0xd8c0700b
+#define MASK_SS_STA_LD_D_V_4_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_4_MEM1 0x5840700b
+#define MASK_SS_STA_LD_D_V_4_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_4_MEM2 0x5880700b
+#define MASK_SS_STA_LD_D_V_4_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_4_MEM3 0x58c0700b
+#define MASK_SS_STA_LD_D_V_4_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_5 0x6000700b
+#define MASK_SS_STA_LD_D_V_5 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_5_M 0xe000700b
+#define MASK_SS_STA_LD_D_V_5_M 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_5_M_MEM1 0xe040700b
+#define MASK_SS_STA_LD_D_V_5_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_5_M_MEM2 0xe080700b
+#define MASK_SS_STA_LD_D_V_5_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_5_M_MEM3 0xe0c0700b
+#define MASK_SS_STA_LD_D_V_5_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_5_MEM1 0x6040700b
+#define MASK_SS_STA_LD_D_V_5_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_5_MEM2 0x6080700b
+#define MASK_SS_STA_LD_D_V_5_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_5_MEM3 0x60c0700b
+#define MASK_SS_STA_LD_D_V_5_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_6 0x6800700b
+#define MASK_SS_STA_LD_D_V_6 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_6_M 0xe800700b
+#define MASK_SS_STA_LD_D_V_6_M 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_6_M_MEM1 0xe840700b
+#define MASK_SS_STA_LD_D_V_6_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_6_M_MEM2 0xe880700b
+#define MASK_SS_STA_LD_D_V_6_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_6_M_MEM3 0xe8c0700b
+#define MASK_SS_STA_LD_D_V_6_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_6_MEM1 0x6840700b
+#define MASK_SS_STA_LD_D_V_6_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_6_MEM2 0x6880700b
+#define MASK_SS_STA_LD_D_V_6_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_6_MEM3 0x68c0700b
+#define MASK_SS_STA_LD_D_V_6_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_7 0x7000700b
+#define MASK_SS_STA_LD_D_V_7 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_7_M 0xf000700b
+#define MASK_SS_STA_LD_D_V_7_M 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_7_M_MEM1 0xf040700b
+#define MASK_SS_STA_LD_D_V_7_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_7_M_MEM2 0xf080700b
+#define MASK_SS_STA_LD_D_V_7_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_7_M_MEM3 0xf0c0700b
+#define MASK_SS_STA_LD_D_V_7_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_7_MEM1 0x7040700b
+#define MASK_SS_STA_LD_D_V_7_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_7_MEM2 0x7080700b
+#define MASK_SS_STA_LD_D_V_7_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_7_MEM3 0x70c0700b
+#define MASK_SS_STA_LD_D_V_7_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_M 0xf800700b
+#define MASK_SS_STA_LD_D_V_M 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_M_MEM1 0xf840700b
+#define MASK_SS_STA_LD_D_V_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_M_MEM2 0xf880700b
+#define MASK_SS_STA_LD_D_V_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_M_MEM3 0xf8c0700b
+#define MASK_SS_STA_LD_D_V_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_MEM1 0x7840700b
+#define MASK_SS_STA_LD_D_V_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_MEM2 0x7880700b
+#define MASK_SS_STA_LD_D_V_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_D_V_MEM3 0x78c0700b
+#define MASK_SS_STA_LD_D_V_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_H 0x500b
+#define MASK_SS_STA_LD_H 0xfff0707f
+#define MATCH_SS_STA_LD_H_INDS 0x100500b
+#define MASK_SS_STA_LD_H_INDS 0xfff0707f
+#define MATCH_SS_STA_LD_H_INDS_MEM1 0x140500b
+#define MASK_SS_STA_LD_H_INDS_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_H_INDS_MEM2 0x180500b
+#define MASK_SS_STA_LD_H_INDS_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_H_INDS_MEM3 0x1c0500b
+#define MASK_SS_STA_LD_H_INDS_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_H_M 0x8000500b
+#define MASK_SS_STA_LD_H_M 0xfff0707f
+#define MATCH_SS_STA_LD_H_M_INDS 0x8100500b
+#define MASK_SS_STA_LD_H_M_INDS 0xfff0707f
+#define MATCH_SS_STA_LD_H_M_INDS_MEM1 0x8140500b
+#define MASK_SS_STA_LD_H_M_INDS_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_H_M_INDS_MEM2 0x8180500b
+#define MASK_SS_STA_LD_H_M_INDS_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_H_M_INDS_MEM3 0x81c0500b
+#define MASK_SS_STA_LD_H_M_INDS_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_H_M_MEM1 0x8040500b
+#define MASK_SS_STA_LD_H_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_H_M_MEM2 0x8080500b
+#define MASK_SS_STA_LD_H_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_H_M_MEM3 0x80c0500b
+#define MASK_SS_STA_LD_H_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_H_MEM1 0x40500b
+#define MASK_SS_STA_LD_H_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_H_MEM2 0x80500b
+#define MASK_SS_STA_LD_H_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_H_MEM3 0xc0500b
+#define MASK_SS_STA_LD_H_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_H_V 0x7800500b
+#define MASK_SS_STA_LD_H_V 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_1 0x4000500b
+#define MASK_SS_STA_LD_H_V_1 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_1_M 0xc000500b
+#define MASK_SS_STA_LD_H_V_1_M 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_1_M_MEM1 0xc040500b
+#define MASK_SS_STA_LD_H_V_1_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_1_M_MEM2 0xc080500b
+#define MASK_SS_STA_LD_H_V_1_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_1_M_MEM3 0xc0c0500b
+#define MASK_SS_STA_LD_H_V_1_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_1_MEM1 0x4040500b
+#define MASK_SS_STA_LD_H_V_1_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_1_MEM2 0x4080500b
+#define MASK_SS_STA_LD_H_V_1_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_1_MEM3 0x40c0500b
+#define MASK_SS_STA_LD_H_V_1_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_2 0x4800500b
+#define MASK_SS_STA_LD_H_V_2 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_2_M 0xc800500b
+#define MASK_SS_STA_LD_H_V_2_M 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_2_M_MEM1 0xc840500b
+#define MASK_SS_STA_LD_H_V_2_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_2_M_MEM2 0xc880500b
+#define MASK_SS_STA_LD_H_V_2_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_2_M_MEM3 0xc8c0500b
+#define MASK_SS_STA_LD_H_V_2_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_2_MEM1 0x4840500b
+#define MASK_SS_STA_LD_H_V_2_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_2_MEM2 0x4880500b
+#define MASK_SS_STA_LD_H_V_2_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_2_MEM3 0x48c0500b
+#define MASK_SS_STA_LD_H_V_2_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_3 0x5000500b
+#define MASK_SS_STA_LD_H_V_3 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_3_M 0xd000500b
+#define MASK_SS_STA_LD_H_V_3_M 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_3_M_MEM1 0xd040500b
+#define MASK_SS_STA_LD_H_V_3_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_3_M_MEM2 0xd080500b
+#define MASK_SS_STA_LD_H_V_3_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_3_M_MEM3 0xd0c0500b
+#define MASK_SS_STA_LD_H_V_3_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_3_MEM1 0x5040500b
+#define MASK_SS_STA_LD_H_V_3_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_3_MEM2 0x5080500b
+#define MASK_SS_STA_LD_H_V_3_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_3_MEM3 0x50c0500b
+#define MASK_SS_STA_LD_H_V_3_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_4 0x5800500b
+#define MASK_SS_STA_LD_H_V_4 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_4_M 0xd800500b
+#define MASK_SS_STA_LD_H_V_4_M 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_4_M_MEM1 0xd840500b
+#define MASK_SS_STA_LD_H_V_4_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_4_M_MEM2 0xd880500b
+#define MASK_SS_STA_LD_H_V_4_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_4_M_MEM3 0xd8c0500b
+#define MASK_SS_STA_LD_H_V_4_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_4_MEM1 0x5840500b
+#define MASK_SS_STA_LD_H_V_4_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_4_MEM2 0x5880500b
+#define MASK_SS_STA_LD_H_V_4_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_4_MEM3 0x58c0500b
+#define MASK_SS_STA_LD_H_V_4_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_5 0x6000500b
+#define MASK_SS_STA_LD_H_V_5 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_5_M 0xe000500b
+#define MASK_SS_STA_LD_H_V_5_M 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_5_M_MEM1 0xe040500b
+#define MASK_SS_STA_LD_H_V_5_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_5_M_MEM2 0xe080500b
+#define MASK_SS_STA_LD_H_V_5_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_5_M_MEM3 0xe0c0500b
+#define MASK_SS_STA_LD_H_V_5_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_5_MEM1 0x6040500b
+#define MASK_SS_STA_LD_H_V_5_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_5_MEM2 0x6080500b
+#define MASK_SS_STA_LD_H_V_5_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_5_MEM3 0x60c0500b
+#define MASK_SS_STA_LD_H_V_5_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_6 0x6800500b
+#define MASK_SS_STA_LD_H_V_6 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_6_M 0xe800500b
+#define MASK_SS_STA_LD_H_V_6_M 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_6_M_MEM1 0xe840500b
+#define MASK_SS_STA_LD_H_V_6_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_6_M_MEM2 0xe880500b
+#define MASK_SS_STA_LD_H_V_6_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_6_M_MEM3 0xe8c0500b
+#define MASK_SS_STA_LD_H_V_6_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_6_MEM1 0x6840500b
+#define MASK_SS_STA_LD_H_V_6_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_6_MEM2 0x6880500b
+#define MASK_SS_STA_LD_H_V_6_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_6_MEM3 0x68c0500b
+#define MASK_SS_STA_LD_H_V_6_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_7 0x7000500b
+#define MASK_SS_STA_LD_H_V_7 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_7_M 0xf000500b
+#define MASK_SS_STA_LD_H_V_7_M 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_7_M_MEM1 0xf040500b
+#define MASK_SS_STA_LD_H_V_7_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_7_M_MEM2 0xf080500b
+#define MASK_SS_STA_LD_H_V_7_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_7_M_MEM3 0xf0c0500b
+#define MASK_SS_STA_LD_H_V_7_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_7_MEM1 0x7040500b
+#define MASK_SS_STA_LD_H_V_7_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_7_MEM2 0x7080500b
+#define MASK_SS_STA_LD_H_V_7_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_7_MEM3 0x70c0500b
+#define MASK_SS_STA_LD_H_V_7_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_M 0xf800500b
+#define MASK_SS_STA_LD_H_V_M 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_M_MEM1 0xf840500b
+#define MASK_SS_STA_LD_H_V_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_M_MEM2 0xf880500b
+#define MASK_SS_STA_LD_H_V_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_M_MEM3 0xf8c0500b
+#define MASK_SS_STA_LD_H_V_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_MEM1 0x7840500b
+#define MASK_SS_STA_LD_H_V_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_MEM2 0x7880500b
+#define MASK_SS_STA_LD_H_V_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_H_V_MEM3 0x78c0500b
+#define MASK_SS_STA_LD_H_V_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_W 0x600b
+#define MASK_SS_STA_LD_W 0xfff0707f
+#define MATCH_SS_STA_LD_W_INDS 0x100600b
+#define MASK_SS_STA_LD_W_INDS 0xfff0707f
+#define MATCH_SS_STA_LD_W_INDS_MEM1 0x140600b
+#define MASK_SS_STA_LD_W_INDS_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_W_INDS_MEM2 0x180600b
+#define MASK_SS_STA_LD_W_INDS_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_W_INDS_MEM3 0x1c0600b
+#define MASK_SS_STA_LD_W_INDS_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_W_M 0x8000600b
+#define MASK_SS_STA_LD_W_M 0xfff0707f
+#define MATCH_SS_STA_LD_W_M_INDS 0x8100600b
+#define MASK_SS_STA_LD_W_M_INDS 0xfff0707f
+#define MATCH_SS_STA_LD_W_M_INDS_MEM1 0x8140600b
+#define MASK_SS_STA_LD_W_M_INDS_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_W_M_INDS_MEM2 0x8180600b
+#define MASK_SS_STA_LD_W_M_INDS_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_W_M_INDS_MEM3 0x81c0600b
+#define MASK_SS_STA_LD_W_M_INDS_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_W_M_MEM1 0x8040600b
+#define MASK_SS_STA_LD_W_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_W_M_MEM2 0x8080600b
+#define MASK_SS_STA_LD_W_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_W_M_MEM3 0x80c0600b
+#define MASK_SS_STA_LD_W_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_W_MEM1 0x40600b
+#define MASK_SS_STA_LD_W_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_W_MEM2 0x80600b
+#define MASK_SS_STA_LD_W_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_W_MEM3 0xc0600b
+#define MASK_SS_STA_LD_W_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_W_V 0x7800600b
+#define MASK_SS_STA_LD_W_V 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_1 0x4000600b
+#define MASK_SS_STA_LD_W_V_1 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_1_M 0xc000600b
+#define MASK_SS_STA_LD_W_V_1_M 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_1_M_MEM1 0xc040600b
+#define MASK_SS_STA_LD_W_V_1_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_1_M_MEM2 0xc080600b
+#define MASK_SS_STA_LD_W_V_1_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_1_M_MEM3 0xc0c0600b
+#define MASK_SS_STA_LD_W_V_1_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_1_MEM1 0x4040600b
+#define MASK_SS_STA_LD_W_V_1_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_1_MEM2 0x4080600b
+#define MASK_SS_STA_LD_W_V_1_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_1_MEM3 0x40c0600b
+#define MASK_SS_STA_LD_W_V_1_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_2 0x4800600b
+#define MASK_SS_STA_LD_W_V_2 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_2_M 0xc800600b
+#define MASK_SS_STA_LD_W_V_2_M 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_2_M_MEM1 0xc840600b
+#define MASK_SS_STA_LD_W_V_2_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_2_M_MEM2 0xc880600b
+#define MASK_SS_STA_LD_W_V_2_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_2_M_MEM3 0xc8c0600b
+#define MASK_SS_STA_LD_W_V_2_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_2_MEM1 0x4840600b
+#define MASK_SS_STA_LD_W_V_2_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_2_MEM2 0x4880600b
+#define MASK_SS_STA_LD_W_V_2_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_2_MEM3 0x48c0600b
+#define MASK_SS_STA_LD_W_V_2_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_3 0x5000600b
+#define MASK_SS_STA_LD_W_V_3 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_3_M 0xd000600b
+#define MASK_SS_STA_LD_W_V_3_M 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_3_M_MEM1 0xd040600b
+#define MASK_SS_STA_LD_W_V_3_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_3_M_MEM2 0xd080600b
+#define MASK_SS_STA_LD_W_V_3_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_3_M_MEM3 0xd0c0600b
+#define MASK_SS_STA_LD_W_V_3_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_3_MEM1 0x5040600b
+#define MASK_SS_STA_LD_W_V_3_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_3_MEM2 0x5080600b
+#define MASK_SS_STA_LD_W_V_3_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_3_MEM3 0x50c0600b
+#define MASK_SS_STA_LD_W_V_3_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_4 0x5800600b
+#define MASK_SS_STA_LD_W_V_4 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_4_M 0xd800600b
+#define MASK_SS_STA_LD_W_V_4_M 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_4_M_MEM1 0xd840600b
+#define MASK_SS_STA_LD_W_V_4_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_4_M_MEM2 0xd880600b
+#define MASK_SS_STA_LD_W_V_4_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_4_M_MEM3 0xd8c0600b
+#define MASK_SS_STA_LD_W_V_4_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_4_MEM1 0x5840600b
+#define MASK_SS_STA_LD_W_V_4_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_4_MEM2 0x5880600b
+#define MASK_SS_STA_LD_W_V_4_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_4_MEM3 0x58c0600b
+#define MASK_SS_STA_LD_W_V_4_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_5 0x6000600b
+#define MASK_SS_STA_LD_W_V_5 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_5_M 0xe000600b
+#define MASK_SS_STA_LD_W_V_5_M 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_5_M_MEM1 0xe040600b
+#define MASK_SS_STA_LD_W_V_5_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_5_M_MEM2 0xe080600b
+#define MASK_SS_STA_LD_W_V_5_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_5_M_MEM3 0xe0c0600b
+#define MASK_SS_STA_LD_W_V_5_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_5_MEM1 0x6040600b
+#define MASK_SS_STA_LD_W_V_5_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_5_MEM2 0x6080600b
+#define MASK_SS_STA_LD_W_V_5_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_5_MEM3 0x60c0600b
+#define MASK_SS_STA_LD_W_V_5_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_6 0x6800600b
+#define MASK_SS_STA_LD_W_V_6 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_6_M 0xe800600b
+#define MASK_SS_STA_LD_W_V_6_M 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_6_M_MEM1 0xe840600b
+#define MASK_SS_STA_LD_W_V_6_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_6_M_MEM2 0xe880600b
+#define MASK_SS_STA_LD_W_V_6_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_6_M_MEM3 0xe8c0600b
+#define MASK_SS_STA_LD_W_V_6_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_6_MEM1 0x6840600b
+#define MASK_SS_STA_LD_W_V_6_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_6_MEM2 0x6880600b
+#define MASK_SS_STA_LD_W_V_6_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_6_MEM3 0x68c0600b
+#define MASK_SS_STA_LD_W_V_6_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_7 0x7000600b
+#define MASK_SS_STA_LD_W_V_7 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_7_M 0xf000600b
+#define MASK_SS_STA_LD_W_V_7_M 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_7_M_MEM1 0xf040600b
+#define MASK_SS_STA_LD_W_V_7_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_7_M_MEM2 0xf080600b
+#define MASK_SS_STA_LD_W_V_7_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_7_M_MEM3 0xf0c0600b
+#define MASK_SS_STA_LD_W_V_7_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_7_MEM1 0x7040600b
+#define MASK_SS_STA_LD_W_V_7_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_7_MEM2 0x7080600b
+#define MASK_SS_STA_LD_W_V_7_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_7_MEM3 0x70c0600b
+#define MASK_SS_STA_LD_W_V_7_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_M 0xf800600b
+#define MASK_SS_STA_LD_W_V_M 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_M_MEM1 0xf840600b
+#define MASK_SS_STA_LD_W_V_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_M_MEM2 0xf880600b
+#define MASK_SS_STA_LD_W_V_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_M_MEM3 0xf8c0600b
+#define MASK_SS_STA_LD_W_V_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_MEM1 0x7840600b
+#define MASK_SS_STA_LD_W_V_MEM1 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_MEM2 0x7880600b
+#define MASK_SS_STA_LD_W_V_MEM2 0xfff0707f
+#define MATCH_SS_STA_LD_W_V_MEM3 0x78c0600b
+#define MASK_SS_STA_LD_W_V_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_B 0xb
+#define MASK_SS_STA_ST_B 0xfff0707f
+#define MATCH_SS_STA_ST_B_M 0x8000000b
+#define MASK_SS_STA_ST_B_M 0xfff0707f
+#define MATCH_SS_STA_ST_B_M_MEM1 0x8040000b
+#define MASK_SS_STA_ST_B_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_B_M_MEM2 0x8080000b
+#define MASK_SS_STA_ST_B_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_B_M_MEM3 0x80c0000b
+#define MASK_SS_STA_ST_B_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_B_MEM1 0x40000b
+#define MASK_SS_STA_ST_B_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_B_MEM2 0x80000b
+#define MASK_SS_STA_ST_B_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_B_MEM3 0xc0000b
+#define MASK_SS_STA_ST_B_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_B_V 0x7800000b
+#define MASK_SS_STA_ST_B_V 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_1 0x4000000b
+#define MASK_SS_STA_ST_B_V_1 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_1_M 0xc000000b
+#define MASK_SS_STA_ST_B_V_1_M 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_1_M_MEM1 0xc040000b
+#define MASK_SS_STA_ST_B_V_1_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_1_M_MEM2 0xc080000b
+#define MASK_SS_STA_ST_B_V_1_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_1_M_MEM3 0xc0c0000b
+#define MASK_SS_STA_ST_B_V_1_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_1_MEM1 0x4040000b
+#define MASK_SS_STA_ST_B_V_1_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_1_MEM2 0x4080000b
+#define MASK_SS_STA_ST_B_V_1_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_1_MEM3 0x40c0000b
+#define MASK_SS_STA_ST_B_V_1_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_2 0x4800000b
+#define MASK_SS_STA_ST_B_V_2 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_2_M 0xc800000b
+#define MASK_SS_STA_ST_B_V_2_M 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_2_M_MEM1 0xc840000b
+#define MASK_SS_STA_ST_B_V_2_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_2_M_MEM2 0xc880000b
+#define MASK_SS_STA_ST_B_V_2_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_2_M_MEM3 0xc8c0000b
+#define MASK_SS_STA_ST_B_V_2_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_2_MEM1 0x4840000b
+#define MASK_SS_STA_ST_B_V_2_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_2_MEM2 0x4880000b
+#define MASK_SS_STA_ST_B_V_2_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_2_MEM3 0x48c0000b
+#define MASK_SS_STA_ST_B_V_2_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_3 0x5000000b
+#define MASK_SS_STA_ST_B_V_3 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_3_M 0xd000000b
+#define MASK_SS_STA_ST_B_V_3_M 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_3_M_MEM1 0xd040000b
+#define MASK_SS_STA_ST_B_V_3_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_3_M_MEM2 0xd080000b
+#define MASK_SS_STA_ST_B_V_3_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_3_M_MEM3 0xd0c0000b
+#define MASK_SS_STA_ST_B_V_3_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_3_MEM1 0x5040000b
+#define MASK_SS_STA_ST_B_V_3_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_3_MEM2 0x5080000b
+#define MASK_SS_STA_ST_B_V_3_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_3_MEM3 0x50c0000b
+#define MASK_SS_STA_ST_B_V_3_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_4 0x5800000b
+#define MASK_SS_STA_ST_B_V_4 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_4_M 0xd800000b
+#define MASK_SS_STA_ST_B_V_4_M 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_4_M_MEM1 0xd840000b
+#define MASK_SS_STA_ST_B_V_4_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_4_M_MEM2 0xd880000b
+#define MASK_SS_STA_ST_B_V_4_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_4_M_MEM3 0xd8c0000b
+#define MASK_SS_STA_ST_B_V_4_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_4_MEM1 0x5840000b
+#define MASK_SS_STA_ST_B_V_4_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_4_MEM2 0x5880000b
+#define MASK_SS_STA_ST_B_V_4_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_4_MEM3 0x58c0000b
+#define MASK_SS_STA_ST_B_V_4_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_5 0x6000000b
+#define MASK_SS_STA_ST_B_V_5 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_5_M 0xe000000b
+#define MASK_SS_STA_ST_B_V_5_M 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_5_M_MEM1 0xe040000b
+#define MASK_SS_STA_ST_B_V_5_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_5_M_MEM2 0xe080000b
+#define MASK_SS_STA_ST_B_V_5_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_5_M_MEM3 0xe0c0000b
+#define MASK_SS_STA_ST_B_V_5_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_5_MEM1 0x6040000b
+#define MASK_SS_STA_ST_B_V_5_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_5_MEM2 0x6080000b
+#define MASK_SS_STA_ST_B_V_5_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_5_MEM3 0x60c0000b
+#define MASK_SS_STA_ST_B_V_5_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_6 0x6800000b
+#define MASK_SS_STA_ST_B_V_6 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_6_M 0xe800000b
+#define MASK_SS_STA_ST_B_V_6_M 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_6_M_MEM1 0xe840000b
+#define MASK_SS_STA_ST_B_V_6_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_6_M_MEM2 0xe880000b
+#define MASK_SS_STA_ST_B_V_6_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_6_M_MEM3 0xe8c0000b
+#define MASK_SS_STA_ST_B_V_6_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_6_MEM1 0x6840000b
+#define MASK_SS_STA_ST_B_V_6_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_6_MEM2 0x6880000b
+#define MASK_SS_STA_ST_B_V_6_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_6_MEM3 0x68c0000b
+#define MASK_SS_STA_ST_B_V_6_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_7 0x7000000b
+#define MASK_SS_STA_ST_B_V_7 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_7_M 0xf000000b
+#define MASK_SS_STA_ST_B_V_7_M 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_7_M_MEM1 0xf040000b
+#define MASK_SS_STA_ST_B_V_7_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_7_M_MEM2 0xf080000b
+#define MASK_SS_STA_ST_B_V_7_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_7_M_MEM3 0xf0c0000b
+#define MASK_SS_STA_ST_B_V_7_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_7_MEM1 0x7040000b
+#define MASK_SS_STA_ST_B_V_7_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_7_MEM2 0x7080000b
+#define MASK_SS_STA_ST_B_V_7_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_7_MEM3 0x70c0000b
+#define MASK_SS_STA_ST_B_V_7_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_M 0xf800000b
+#define MASK_SS_STA_ST_B_V_M 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_M_MEM1 0xf840000b
+#define MASK_SS_STA_ST_B_V_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_M_MEM2 0xf880000b
+#define MASK_SS_STA_ST_B_V_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_M_MEM3 0xf8c0000b
+#define MASK_SS_STA_ST_B_V_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_MEM1 0x7840000b
+#define MASK_SS_STA_ST_B_V_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_MEM2 0x7880000b
+#define MASK_SS_STA_ST_B_V_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_B_V_MEM3 0x78c0000b
+#define MASK_SS_STA_ST_B_V_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_D 0x300b
+#define MASK_SS_STA_ST_D 0xfff0707f
+#define MATCH_SS_STA_ST_D_M 0x8000300b
+#define MASK_SS_STA_ST_D_M 0xfff0707f
+#define MATCH_SS_STA_ST_D_M_MEM1 0x8040300b
+#define MASK_SS_STA_ST_D_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_D_M_MEM2 0x8080300b
+#define MASK_SS_STA_ST_D_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_D_M_MEM3 0x80c0300b
+#define MASK_SS_STA_ST_D_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_D_MEM1 0x40300b
+#define MASK_SS_STA_ST_D_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_D_MEM2 0x80300b
+#define MASK_SS_STA_ST_D_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_D_MEM3 0xc0300b
+#define MASK_SS_STA_ST_D_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_D_V 0x7800300b
+#define MASK_SS_STA_ST_D_V 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_1 0x4000300b
+#define MASK_SS_STA_ST_D_V_1 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_1_M 0xc000300b
+#define MASK_SS_STA_ST_D_V_1_M 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_1_M_MEM1 0xc040300b
+#define MASK_SS_STA_ST_D_V_1_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_1_M_MEM2 0xc080300b
+#define MASK_SS_STA_ST_D_V_1_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_1_M_MEM3 0xc0c0300b
+#define MASK_SS_STA_ST_D_V_1_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_1_MEM1 0x4040300b
+#define MASK_SS_STA_ST_D_V_1_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_1_MEM2 0x4080300b
+#define MASK_SS_STA_ST_D_V_1_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_1_MEM3 0x40c0300b
+#define MASK_SS_STA_ST_D_V_1_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_2 0x4800300b
+#define MASK_SS_STA_ST_D_V_2 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_2_M 0xc800300b
+#define MASK_SS_STA_ST_D_V_2_M 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_2_M_MEM1 0xc840300b
+#define MASK_SS_STA_ST_D_V_2_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_2_M_MEM2 0xc880300b
+#define MASK_SS_STA_ST_D_V_2_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_2_M_MEM3 0xc8c0300b
+#define MASK_SS_STA_ST_D_V_2_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_2_MEM1 0x4840300b
+#define MASK_SS_STA_ST_D_V_2_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_2_MEM2 0x4880300b
+#define MASK_SS_STA_ST_D_V_2_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_2_MEM3 0x48c0300b
+#define MASK_SS_STA_ST_D_V_2_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_3 0x5000300b
+#define MASK_SS_STA_ST_D_V_3 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_3_M 0xd000300b
+#define MASK_SS_STA_ST_D_V_3_M 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_3_M_MEM1 0xd040300b
+#define MASK_SS_STA_ST_D_V_3_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_3_M_MEM2 0xd080300b
+#define MASK_SS_STA_ST_D_V_3_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_3_M_MEM3 0xd0c0300b
+#define MASK_SS_STA_ST_D_V_3_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_3_MEM1 0x5040300b
+#define MASK_SS_STA_ST_D_V_3_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_3_MEM2 0x5080300b
+#define MASK_SS_STA_ST_D_V_3_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_3_MEM3 0x50c0300b
+#define MASK_SS_STA_ST_D_V_3_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_4 0x5800300b
+#define MASK_SS_STA_ST_D_V_4 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_4_M 0xd800300b
+#define MASK_SS_STA_ST_D_V_4_M 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_4_M_MEM1 0xd840300b
+#define MASK_SS_STA_ST_D_V_4_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_4_M_MEM2 0xd880300b
+#define MASK_SS_STA_ST_D_V_4_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_4_M_MEM3 0xd8c0300b
+#define MASK_SS_STA_ST_D_V_4_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_4_MEM1 0x5840300b
+#define MASK_SS_STA_ST_D_V_4_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_4_MEM2 0x5880300b
+#define MASK_SS_STA_ST_D_V_4_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_4_MEM3 0x58c0300b
+#define MASK_SS_STA_ST_D_V_4_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_5 0x6000300b
+#define MASK_SS_STA_ST_D_V_5 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_5_M 0xe000300b
+#define MASK_SS_STA_ST_D_V_5_M 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_5_M_MEM1 0xe040300b
+#define MASK_SS_STA_ST_D_V_5_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_5_M_MEM2 0xe080300b
+#define MASK_SS_STA_ST_D_V_5_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_5_M_MEM3 0xe0c0300b
+#define MASK_SS_STA_ST_D_V_5_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_5_MEM1 0x6040300b
+#define MASK_SS_STA_ST_D_V_5_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_5_MEM2 0x6080300b
+#define MASK_SS_STA_ST_D_V_5_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_5_MEM3 0x60c0300b
+#define MASK_SS_STA_ST_D_V_5_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_6 0x6800300b
+#define MASK_SS_STA_ST_D_V_6 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_6_M 0xe800300b
+#define MASK_SS_STA_ST_D_V_6_M 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_6_M_MEM1 0xe840300b
+#define MASK_SS_STA_ST_D_V_6_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_6_M_MEM2 0xe880300b
+#define MASK_SS_STA_ST_D_V_6_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_6_M_MEM3 0xe8c0300b
+#define MASK_SS_STA_ST_D_V_6_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_6_MEM1 0x6840300b
+#define MASK_SS_STA_ST_D_V_6_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_6_MEM2 0x6880300b
+#define MASK_SS_STA_ST_D_V_6_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_6_MEM3 0x68c0300b
+#define MASK_SS_STA_ST_D_V_6_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_7 0x7000300b
+#define MASK_SS_STA_ST_D_V_7 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_7_M 0xf000300b
+#define MASK_SS_STA_ST_D_V_7_M 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_7_M_MEM1 0xf040300b
+#define MASK_SS_STA_ST_D_V_7_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_7_M_MEM2 0xf080300b
+#define MASK_SS_STA_ST_D_V_7_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_7_M_MEM3 0xf0c0300b
+#define MASK_SS_STA_ST_D_V_7_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_7_MEM1 0x7040300b
+#define MASK_SS_STA_ST_D_V_7_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_7_MEM2 0x7080300b
+#define MASK_SS_STA_ST_D_V_7_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_7_MEM3 0x70c0300b
+#define MASK_SS_STA_ST_D_V_7_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_M 0xf800300b
+#define MASK_SS_STA_ST_D_V_M 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_M_MEM1 0xf840300b
+#define MASK_SS_STA_ST_D_V_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_M_MEM2 0xf880300b
+#define MASK_SS_STA_ST_D_V_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_M_MEM3 0xf8c0300b
+#define MASK_SS_STA_ST_D_V_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_MEM1 0x7840300b
+#define MASK_SS_STA_ST_D_V_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_MEM2 0x7880300b
+#define MASK_SS_STA_ST_D_V_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_D_V_MEM3 0x78c0300b
+#define MASK_SS_STA_ST_D_V_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_H 0x100b
+#define MASK_SS_STA_ST_H 0xfff0707f
+#define MATCH_SS_STA_ST_H_M 0x8000100b
+#define MASK_SS_STA_ST_H_M 0xfff0707f
+#define MATCH_SS_STA_ST_H_M_MEM1 0x8040100b
+#define MASK_SS_STA_ST_H_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_H_M_MEM2 0x8080100b
+#define MASK_SS_STA_ST_H_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_H_M_MEM3 0x80c0100b
+#define MASK_SS_STA_ST_H_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_H_MEM1 0x40100b
+#define MASK_SS_STA_ST_H_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_H_MEM2 0x80100b
+#define MASK_SS_STA_ST_H_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_H_MEM3 0xc0100b
+#define MASK_SS_STA_ST_H_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_H_V 0x7800100b
+#define MASK_SS_STA_ST_H_V 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_1 0x4000100b
+#define MASK_SS_STA_ST_H_V_1 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_1_M 0xc000100b
+#define MASK_SS_STA_ST_H_V_1_M 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_1_M_MEM1 0xc040100b
+#define MASK_SS_STA_ST_H_V_1_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_1_M_MEM2 0xc080100b
+#define MASK_SS_STA_ST_H_V_1_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_1_M_MEM3 0xc0c0100b
+#define MASK_SS_STA_ST_H_V_1_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_1_MEM1 0x4040100b
+#define MASK_SS_STA_ST_H_V_1_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_1_MEM2 0x4080100b
+#define MASK_SS_STA_ST_H_V_1_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_1_MEM3 0x40c0100b
+#define MASK_SS_STA_ST_H_V_1_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_2 0x4800100b
+#define MASK_SS_STA_ST_H_V_2 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_2_M 0xc800100b
+#define MASK_SS_STA_ST_H_V_2_M 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_2_M_MEM1 0xc840100b
+#define MASK_SS_STA_ST_H_V_2_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_2_M_MEM2 0xc880100b
+#define MASK_SS_STA_ST_H_V_2_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_2_M_MEM3 0xc8c0100b
+#define MASK_SS_STA_ST_H_V_2_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_2_MEM1 0x4840100b
+#define MASK_SS_STA_ST_H_V_2_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_2_MEM2 0x4880100b
+#define MASK_SS_STA_ST_H_V_2_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_2_MEM3 0x48c0100b
+#define MASK_SS_STA_ST_H_V_2_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_3 0x5000100b
+#define MASK_SS_STA_ST_H_V_3 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_3_M 0xd000100b
+#define MASK_SS_STA_ST_H_V_3_M 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_3_M_MEM1 0xd040100b
+#define MASK_SS_STA_ST_H_V_3_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_3_M_MEM2 0xd080100b
+#define MASK_SS_STA_ST_H_V_3_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_3_M_MEM3 0xd0c0100b
+#define MASK_SS_STA_ST_H_V_3_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_3_MEM1 0x5040100b
+#define MASK_SS_STA_ST_H_V_3_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_3_MEM2 0x5080100b
+#define MASK_SS_STA_ST_H_V_3_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_3_MEM3 0x50c0100b
+#define MASK_SS_STA_ST_H_V_3_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_4 0x5800100b
+#define MASK_SS_STA_ST_H_V_4 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_4_M 0xd800100b
+#define MASK_SS_STA_ST_H_V_4_M 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_4_M_MEM1 0xd840100b
+#define MASK_SS_STA_ST_H_V_4_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_4_M_MEM2 0xd880100b
+#define MASK_SS_STA_ST_H_V_4_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_4_M_MEM3 0xd8c0100b
+#define MASK_SS_STA_ST_H_V_4_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_4_MEM1 0x5840100b
+#define MASK_SS_STA_ST_H_V_4_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_4_MEM2 0x5880100b
+#define MASK_SS_STA_ST_H_V_4_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_4_MEM3 0x58c0100b
+#define MASK_SS_STA_ST_H_V_4_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_5 0x6000100b
+#define MASK_SS_STA_ST_H_V_5 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_5_M 0xe000100b
+#define MASK_SS_STA_ST_H_V_5_M 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_5_M_MEM1 0xe040100b
+#define MASK_SS_STA_ST_H_V_5_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_5_M_MEM2 0xe080100b
+#define MASK_SS_STA_ST_H_V_5_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_5_M_MEM3 0xe0c0100b
+#define MASK_SS_STA_ST_H_V_5_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_5_MEM1 0x6040100b
+#define MASK_SS_STA_ST_H_V_5_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_5_MEM2 0x6080100b
+#define MASK_SS_STA_ST_H_V_5_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_5_MEM3 0x60c0100b
+#define MASK_SS_STA_ST_H_V_5_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_6 0x6800100b
+#define MASK_SS_STA_ST_H_V_6 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_6_M 0xe800100b
+#define MASK_SS_STA_ST_H_V_6_M 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_6_M_MEM1 0xe840100b
+#define MASK_SS_STA_ST_H_V_6_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_6_M_MEM2 0xe880100b
+#define MASK_SS_STA_ST_H_V_6_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_6_M_MEM3 0xe8c0100b
+#define MASK_SS_STA_ST_H_V_6_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_6_MEM1 0x6840100b
+#define MASK_SS_STA_ST_H_V_6_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_6_MEM2 0x6880100b
+#define MASK_SS_STA_ST_H_V_6_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_6_MEM3 0x68c0100b
+#define MASK_SS_STA_ST_H_V_6_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_7 0x7000100b
+#define MASK_SS_STA_ST_H_V_7 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_7_M 0xf000100b
+#define MASK_SS_STA_ST_H_V_7_M 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_7_M_MEM1 0xf040100b
+#define MASK_SS_STA_ST_H_V_7_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_7_M_MEM2 0xf080100b
+#define MASK_SS_STA_ST_H_V_7_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_7_M_MEM3 0xf0c0100b
+#define MASK_SS_STA_ST_H_V_7_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_7_MEM1 0x7040100b
+#define MASK_SS_STA_ST_H_V_7_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_7_MEM2 0x7080100b
+#define MASK_SS_STA_ST_H_V_7_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_7_MEM3 0x70c0100b
+#define MASK_SS_STA_ST_H_V_7_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_M 0xf800100b
+#define MASK_SS_STA_ST_H_V_M 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_M_MEM1 0xf840100b
+#define MASK_SS_STA_ST_H_V_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_M_MEM2 0xf880100b
+#define MASK_SS_STA_ST_H_V_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_M_MEM3 0xf8c0100b
+#define MASK_SS_STA_ST_H_V_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_MEM1 0x7840100b
+#define MASK_SS_STA_ST_H_V_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_MEM2 0x7880100b
+#define MASK_SS_STA_ST_H_V_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_H_V_MEM3 0x78c0100b
+#define MASK_SS_STA_ST_H_V_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_W 0x200b
+#define MASK_SS_STA_ST_W 0xfff0707f
+#define MATCH_SS_STA_ST_W_M 0x8000200b
+#define MASK_SS_STA_ST_W_M 0xfff0707f
+#define MATCH_SS_STA_ST_W_M_MEM1 0x8040200b
+#define MASK_SS_STA_ST_W_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_W_M_MEM2 0x8080200b
+#define MASK_SS_STA_ST_W_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_W_M_MEM3 0x80c0200b
+#define MASK_SS_STA_ST_W_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_W_MEM1 0x40200b
+#define MASK_SS_STA_ST_W_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_W_MEM2 0x80200b
+#define MASK_SS_STA_ST_W_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_W_MEM3 0xc0200b
+#define MASK_SS_STA_ST_W_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_W_V 0x7800200b
+#define MASK_SS_STA_ST_W_V 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_1 0x4000200b
+#define MASK_SS_STA_ST_W_V_1 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_1_M 0xc000200b
+#define MASK_SS_STA_ST_W_V_1_M 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_1_M_MEM1 0xc040200b
+#define MASK_SS_STA_ST_W_V_1_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_1_M_MEM2 0xc080200b
+#define MASK_SS_STA_ST_W_V_1_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_1_M_MEM3 0xc0c0200b
+#define MASK_SS_STA_ST_W_V_1_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_1_MEM1 0x4040200b
+#define MASK_SS_STA_ST_W_V_1_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_1_MEM2 0x4080200b
+#define MASK_SS_STA_ST_W_V_1_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_1_MEM3 0x40c0200b
+#define MASK_SS_STA_ST_W_V_1_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_2 0x4800200b
+#define MASK_SS_STA_ST_W_V_2 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_2_M 0xc800200b
+#define MASK_SS_STA_ST_W_V_2_M 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_2_M_MEM1 0xc840200b
+#define MASK_SS_STA_ST_W_V_2_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_2_M_MEM2 0xc880200b
+#define MASK_SS_STA_ST_W_V_2_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_2_M_MEM3 0xc8c0200b
+#define MASK_SS_STA_ST_W_V_2_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_2_MEM1 0x4840200b
+#define MASK_SS_STA_ST_W_V_2_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_2_MEM2 0x4880200b
+#define MASK_SS_STA_ST_W_V_2_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_2_MEM3 0x48c0200b
+#define MASK_SS_STA_ST_W_V_2_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_3 0x5000200b
+#define MASK_SS_STA_ST_W_V_3 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_3_M 0xd000200b
+#define MASK_SS_STA_ST_W_V_3_M 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_3_M_MEM1 0xd040200b
+#define MASK_SS_STA_ST_W_V_3_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_3_M_MEM2 0xd080200b
+#define MASK_SS_STA_ST_W_V_3_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_3_M_MEM3 0xd0c0200b
+#define MASK_SS_STA_ST_W_V_3_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_3_MEM1 0x5040200b
+#define MASK_SS_STA_ST_W_V_3_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_3_MEM2 0x5080200b
+#define MASK_SS_STA_ST_W_V_3_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_3_MEM3 0x50c0200b
+#define MASK_SS_STA_ST_W_V_3_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_4 0x5800200b
+#define MASK_SS_STA_ST_W_V_4 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_4_M 0xd800200b
+#define MASK_SS_STA_ST_W_V_4_M 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_4_M_MEM1 0xd840200b
+#define MASK_SS_STA_ST_W_V_4_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_4_M_MEM2 0xd880200b
+#define MASK_SS_STA_ST_W_V_4_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_4_M_MEM3 0xd8c0200b
+#define MASK_SS_STA_ST_W_V_4_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_4_MEM1 0x5840200b
+#define MASK_SS_STA_ST_W_V_4_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_4_MEM2 0x5880200b
+#define MASK_SS_STA_ST_W_V_4_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_4_MEM3 0x58c0200b
+#define MASK_SS_STA_ST_W_V_4_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_5 0x6000200b
+#define MASK_SS_STA_ST_W_V_5 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_5_M 0xe000200b
+#define MASK_SS_STA_ST_W_V_5_M 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_5_M_MEM1 0xe040200b
+#define MASK_SS_STA_ST_W_V_5_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_5_M_MEM2 0xe080200b
+#define MASK_SS_STA_ST_W_V_5_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_5_M_MEM3 0xe0c0200b
+#define MASK_SS_STA_ST_W_V_5_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_5_MEM1 0x6040200b
+#define MASK_SS_STA_ST_W_V_5_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_5_MEM2 0x6080200b
+#define MASK_SS_STA_ST_W_V_5_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_5_MEM3 0x60c0200b
+#define MASK_SS_STA_ST_W_V_5_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_6 0x6800200b
+#define MASK_SS_STA_ST_W_V_6 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_6_M 0xe800200b
+#define MASK_SS_STA_ST_W_V_6_M 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_6_M_MEM1 0xe840200b
+#define MASK_SS_STA_ST_W_V_6_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_6_M_MEM2 0xe880200b
+#define MASK_SS_STA_ST_W_V_6_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_6_M_MEM3 0xe8c0200b
+#define MASK_SS_STA_ST_W_V_6_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_6_MEM1 0x6840200b
+#define MASK_SS_STA_ST_W_V_6_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_6_MEM2 0x6880200b
+#define MASK_SS_STA_ST_W_V_6_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_6_MEM3 0x68c0200b
+#define MASK_SS_STA_ST_W_V_6_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_7 0x7000200b
+#define MASK_SS_STA_ST_W_V_7 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_7_M 0xf000200b
+#define MASK_SS_STA_ST_W_V_7_M 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_7_M_MEM1 0xf040200b
+#define MASK_SS_STA_ST_W_V_7_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_7_M_MEM2 0xf080200b
+#define MASK_SS_STA_ST_W_V_7_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_7_M_MEM3 0xf0c0200b
+#define MASK_SS_STA_ST_W_V_7_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_7_MEM1 0x7040200b
+#define MASK_SS_STA_ST_W_V_7_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_7_MEM2 0x7080200b
+#define MASK_SS_STA_ST_W_V_7_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_7_MEM3 0x70c0200b
+#define MASK_SS_STA_ST_W_V_7_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_M 0xf800200b
+#define MASK_SS_STA_ST_W_V_M 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_M_MEM1 0xf840200b
+#define MASK_SS_STA_ST_W_V_M_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_M_MEM2 0xf880200b
+#define MASK_SS_STA_ST_W_V_M_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_M_MEM3 0xf8c0200b
+#define MASK_SS_STA_ST_W_V_M_MEM3 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_MEM1 0x7840200b
+#define MASK_SS_STA_ST_W_V_MEM1 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_MEM2 0x7880200b
+#define MASK_SS_STA_ST_W_V_MEM2 0xfff0707f
+#define MATCH_SS_STA_ST_W_V_MEM3 0x78c0200b
+#define MASK_SS_STA_ST_W_V_MEM3 0xfff0707f
 #define MATCH_SSAMOSWAP_D 0x4800302f
 #define MASK_SSAMOSWAP_D 0xf800707f
 #define MATCH_SSAMOSWAP_W 0x4800202f
@@ -1529,40 +3407,14 @@
 #define MASK_SSRDP 0xfffff07f
 #define MATCH_SUB 0x40000033
 #define MASK_SUB 0xfe00707f
-#define MATCH_SUB64 0xc2001077
-#define MASK_SUB64 0xfe00707f
 #define MATCH_SUBW 0x4000003b
 #define MASK_SUBW 0xfe00707f
 #define MATCH_SW 0x2023
 #define MASK_SW 0x707f
 #define MATCH_SW_RL 0x3a00202f
 #define MASK_SW_RL 0xfa007fff
-#define MATCH_UKADD64 0xb0001077
-#define MASK_UKADD64 0xfe00707f
-#define MATCH_UKMAR64 0xb4001077
-#define MASK_UKMAR64 0xfe00707f
-#define MATCH_UKMSR64 0xb6001077
-#define MASK_UKMSR64 0xfe00707f
-#define MATCH_UKSUB64 0xb2001077
-#define MASK_UKSUB64 0xfe00707f
-#define MATCH_UMAR64 0xa4001077
-#define MASK_UMAR64 0xfe00707f
-#define MATCH_UMSR64 0xa6001077
-#define MASK_UMSR64 0xfe00707f
-#define MATCH_UMUL16 0xb0000077
-#define MASK_UMUL16 0xfe00707f
-#define MATCH_UMUL8 0xb8000077
-#define MASK_UMUL8 0xfe00707f
-#define MATCH_UMULX16 0xb2000077
-#define MASK_UMULX16 0xfe00707f
-#define MATCH_UMULX8 0xba000077
-#define MASK_UMULX8 0xfe00707f
 #define MATCH_UNSHFLI 0x8005013
 #define MASK_UNSHFLI 0xfe00707f
-#define MATCH_URADD64 0xa0001077
-#define MASK_URADD64 0xfe00707f
-#define MATCH_URSUB64 0xa2001077
-#define MASK_URSUB64 0xfe00707f
 #define MATCH_VAADD_VV 0x24002057
 #define MASK_VAADD_VV 0xfc00707f
 #define MATCH_VAADD_VX 0x24006057
@@ -2487,6 +4339,8 @@
 #define CSR_STVAL 0x143
 #define CSR_SIP 0x144
 #define CSR_STIMECMP 0x14d
+#define CSR_SCTRCTL 0x14e
+#define CSR_SCTRSTATUS 0x14f
 #define CSR_SISELECT 0x150
 #define CSR_SIREG 0x151
 #define CSR_SIREG2 0x152
@@ -2495,6 +4349,7 @@
 #define CSR_SIREG5 0x156
 #define CSR_SIREG6 0x157
 #define CSR_STOPEI 0x15c
+#define CSR_SCTRDEPTH 0x15f
 #define CSR_SATP 0x180
 #define CSR_SRMCFG 0x181
 #define CSR_SCONTEXT 0x5a8
@@ -2507,6 +4362,7 @@
 #define CSR_VSTVAL 0x243
 #define CSR_VSIP 0x244
 #define CSR_VSTIMECMP 0x24d
+#define CSR_VSCTRCTL 0x24e
 #define CSR_VSISELECT 0x250
 #define CSR_VSIREG 0x251
 #define CSR_VSIREG2 0x252
@@ -2579,6 +4435,7 @@
 #define CSR_MIP 0x344
 #define CSR_MTINST 0x34a
 #define CSR_MTVAL2 0x34b
+#define CSR_MCTRCTL 0x34e
 #define CSR_MISELECT 0x350
 #define CSR_MIREG 0x351
 #define CSR_MIREG2 0x352
@@ -2998,16 +4855,38 @@
 #define INSN_FIELD_C_RS2 0x7c
 #define INSN_FIELD_C_SREG1 0x380
 #define INSN_FIELD_C_SREG2 0x1c
+#define INSN_FIELD_PD 0x780
+#define INSN_FIELD_PS1 0x78000
+#define INSN_FIELD_PS1F 0xf8000
+#define INSN_FIELD_PS2 0x700000
+#define INSN_FIELD_PS3 0xe000000
+#define INSN_FIELD_RVD 0xf80
+#define INSN_FIELD_RVS1 0xf8000
+#define INSN_FIELD_VPS1 0xf8000
+#define INSN_FIELD_RVS2 0x1f00000
+#define INSN_FIELD_RVS3 0xf8000000
+#define INSN_FIELD_FUNCT4A 0xf0000000
+#define INSN_FIELD_FUNCT4B 0x7800
+#define INSN_FIELD_FUNCT9 0xff800000
+#define INSN_FIELD_FUNCT3B 0xe0000000
+#define INSN_FIELD_FUNCT2B 0x300000
+#define INSN_FIELD_DWIDTH 0xc00000
+#define INSN_FIELD_SWIDTH 0x300000
+#define INSN_FIELD_NS 0x4000
+#define INSN_FIELD_TYPE 0x3000
+#define INSN_FIELD_TYPE1 0x1000
+#define INSN_FIELD_TYPE2 0x1800000
 #define INSN_FIELD_MOP_R_T_30 0x40000000
 #define INSN_FIELD_MOP_R_T_27_26 0xc000000
 #define INSN_FIELD_MOP_R_T_21_20 0x300000
 #define INSN_FIELD_MOP_RR_T_30 0x40000000
 #define INSN_FIELD_MOP_RR_T_27_26 0xc000000
 #define INSN_FIELD_C_MOP_T 0x700
+#define INSN_FIELD_IMM12AHI 0x1fc00000
+#define INSN_FIELD_IMM12ALO 0xf80
 #endif
 #ifdef DECLARE_INSN
 DECLARE_INSN(add, MATCH_ADD, MASK_ADD)
-DECLARE_INSN(add64, MATCH_ADD64, MASK_ADD64)
 DECLARE_INSN(add_uw, MATCH_ADD_UW, MASK_ADD_UW)
 DECLARE_INSN(addi, MATCH_ADDI, MASK_ADDI)
 DECLARE_INSN(addiw, MATCH_ADDIW, MASK_ADDIW)
@@ -3370,10 +5249,6 @@ DECLARE_INSN(hsv_h, MATCH_HSV_H, MASK_HSV_H)
 DECLARE_INSN(hsv_w, MATCH_HSV_W, MASK_HSV_W)
 DECLARE_INSN(jal, MATCH_JAL, MASK_JAL)
 DECLARE_INSN(jalr, MATCH_JALR, MASK_JALR)
-DECLARE_INSN(kadd64, MATCH_KADD64, MASK_KADD64)
-DECLARE_INSN(kmar64, MATCH_KMAR64, MASK_KMAR64)
-DECLARE_INSN(kmsr64, MATCH_KMSR64, MASK_KMSR64)
-DECLARE_INSN(ksub64, MATCH_KSUB64, MASK_KSUB64)
 DECLARE_INSN(lb, MATCH_LB, MASK_LB)
 DECLARE_INSN(lb_aq, MATCH_LB_AQ, MASK_LB_AQ)
 DECLARE_INSN(lbu, MATCH_LBU, MASK_LBU)
@@ -3441,8 +5316,6 @@ DECLARE_INSN(mul, MATCH_MUL, MASK_MUL)
 DECLARE_INSN(mulh, MATCH_MULH, MASK_MULH)
 DECLARE_INSN(mulhsu, MATCH_MULHSU, MASK_MULHSU)
 DECLARE_INSN(mulhu, MATCH_MULHU, MASK_MULHU)
-DECLARE_INSN(mulr64, MATCH_MULR64, MASK_MULR64)
-DECLARE_INSN(mulsr64, MATCH_MULSR64, MASK_MULSR64)
 DECLARE_INSN(mulw, MATCH_MULW, MASK_MULW)
 DECLARE_INSN(or, MATCH_OR, MASK_OR)
 DECLARE_INSN(ori, MATCH_ORI, MASK_ORI)
@@ -3454,7 +5327,6 @@ DECLARE_INSN(pause, MATCH_PAUSE, MASK_PAUSE)
 DECLARE_INSN(prefetch_i, MATCH_PREFETCH_I, MASK_PREFETCH_I)
 DECLARE_INSN(prefetch_r, MATCH_PREFETCH_R, MASK_PREFETCH_R)
 DECLARE_INSN(prefetch_w, MATCH_PREFETCH_W, MASK_PREFETCH_W)
-DECLARE_INSN(radd64, MATCH_RADD64, MASK_RADD64)
 DECLARE_INSN(rem, MATCH_REM, MASK_REM)
 DECLARE_INSN(remu, MATCH_REMU, MASK_REMU)
 DECLARE_INSN(remuw, MATCH_REMUW, MASK_REMUW)
@@ -3465,11 +5337,11 @@ DECLARE_INSN(ror, MATCH_ROR, MASK_ROR)
 DECLARE_INSN(rori, MATCH_RORI, MASK_RORI)
 DECLARE_INSN(roriw, MATCH_RORIW, MASK_RORIW)
 DECLARE_INSN(rorw, MATCH_RORW, MASK_RORW)
-DECLARE_INSN(rsub64, MATCH_RSUB64, MASK_RSUB64)
 DECLARE_INSN(sb, MATCH_SB, MASK_SB)
 DECLARE_INSN(sb_rl, MATCH_SB_RL, MASK_SB_RL)
 DECLARE_INSN(sc_d, MATCH_SC_D, MASK_SC_D)
 DECLARE_INSN(sc_w, MATCH_SC_W, MASK_SC_W)
+DECLARE_INSN(sctrclr, MATCH_SCTRCLR, MASK_SCTRCLR)
 DECLARE_INSN(sd, MATCH_SD, MASK_SD)
 DECLARE_INSN(sd_rl, MATCH_SD_RL, MASK_SD_RL)
 DECLARE_INSN(sext_b, MATCH_SEXT_B, MASK_SEXT_B)
@@ -3507,10 +5379,6 @@ DECLARE_INSN(slli_rv32, MATCH_SLLI_RV32, MASK_SLLI_RV32)
 DECLARE_INSN(slli_uw, MATCH_SLLI_UW, MASK_SLLI_UW)
 DECLARE_INSN(slliw, MATCH_SLLIW, MASK_SLLIW)
 DECLARE_INSN(sllw, MATCH_SLLW, MASK_SLLW)
-DECLARE_INSN(slo, MATCH_SLO, MASK_SLO)
-DECLARE_INSN(sloi, MATCH_SLOI, MASK_SLOI)
-DECLARE_INSN(sloiw, MATCH_SLOIW, MASK_SLOIW)
-DECLARE_INSN(slow, MATCH_SLOW, MASK_SLOW)
 DECLARE_INSN(slt, MATCH_SLT, MASK_SLT)
 DECLARE_INSN(slti, MATCH_SLTI, MASK_SLTI)
 DECLARE_INSN(sltiu, MATCH_SLTIU, MASK_SLTIU)
@@ -3519,23 +5387,149 @@ DECLARE_INSN(sm3p0, MATCH_SM3P0, MASK_SM3P0)
 DECLARE_INSN(sm3p1, MATCH_SM3P1, MASK_SM3P1)
 DECLARE_INSN(sm4ed, MATCH_SM4ED, MASK_SM4ED)
 DECLARE_INSN(sm4ks, MATCH_SM4KS, MASK_SM4KS)
-DECLARE_INSN(smal, MATCH_SMAL, MASK_SMAL)
-DECLARE_INSN(smalbb, MATCH_SMALBB, MASK_SMALBB)
-DECLARE_INSN(smalbt, MATCH_SMALBT, MASK_SMALBT)
-DECLARE_INSN(smalda, MATCH_SMALDA, MASK_SMALDA)
-DECLARE_INSN(smaldrs, MATCH_SMALDRS, MASK_SMALDRS)
-DECLARE_INSN(smalds, MATCH_SMALDS, MASK_SMALDS)
-DECLARE_INSN(smaltt, MATCH_SMALTT, MASK_SMALTT)
-DECLARE_INSN(smalxda, MATCH_SMALXDA, MASK_SMALXDA)
-DECLARE_INSN(smalxds, MATCH_SMALXDS, MASK_SMALXDS)
-DECLARE_INSN(smar64, MATCH_SMAR64, MASK_SMAR64)
-DECLARE_INSN(smslda, MATCH_SMSLDA, MASK_SMSLDA)
-DECLARE_INSN(smslxda, MATCH_SMSLXDA, MASK_SMSLXDA)
-DECLARE_INSN(smsr64, MATCH_SMSR64, MASK_SMSR64)
-DECLARE_INSN(smul16, MATCH_SMUL16, MASK_SMUL16)
-DECLARE_INSN(smul8, MATCH_SMUL8, MASK_SMUL8)
-DECLARE_INSN(smulx16, MATCH_SMULX16, MASK_SMULX16)
-DECLARE_INSN(smulx8, MATCH_SMULX8, MASK_SMULX8)
+DECLARE_INSN(so_a_abs_fp, MATCH_SO_A_ABS_FP, MASK_SO_A_ABS_FP)
+DECLARE_INSN(so_a_abs_sg, MATCH_SO_A_ABS_SG, MASK_SO_A_ABS_SG)
+DECLARE_INSN(so_a_add_fp, MATCH_SO_A_ADD_FP, MASK_SO_A_ADD_FP)
+DECLARE_INSN(so_a_add_sg, MATCH_SO_A_ADD_SG, MASK_SO_A_ADD_SG)
+DECLARE_INSN(so_a_add_us, MATCH_SO_A_ADD_US, MASK_SO_A_ADD_US)
+DECLARE_INSN(so_a_adde_acc_fp, MATCH_SO_A_ADDE_ACC_FP, MASK_SO_A_ADDE_ACC_FP)
+DECLARE_INSN(so_a_adde_acc_sg, MATCH_SO_A_ADDE_ACC_SG, MASK_SO_A_ADDE_ACC_SG)
+DECLARE_INSN(so_a_adde_acc_us, MATCH_SO_A_ADDE_ACC_US, MASK_SO_A_ADDE_ACC_US)
+DECLARE_INSN(so_a_adde_fp, MATCH_SO_A_ADDE_FP, MASK_SO_A_ADDE_FP)
+DECLARE_INSN(so_a_adde_sg, MATCH_SO_A_ADDE_SG, MASK_SO_A_ADDE_SG)
+DECLARE_INSN(so_a_adde_us, MATCH_SO_A_ADDE_US, MASK_SO_A_ADDE_US)
+DECLARE_INSN(so_a_adds_acc_fp, MATCH_SO_A_ADDS_ACC_FP, MASK_SO_A_ADDS_ACC_FP)
+DECLARE_INSN(so_a_adds_acc_sg, MATCH_SO_A_ADDS_ACC_SG, MASK_SO_A_ADDS_ACC_SG)
+DECLARE_INSN(so_a_adds_acc_us, MATCH_SO_A_ADDS_ACC_US, MASK_SO_A_ADDS_ACC_US)
+DECLARE_INSN(so_a_adds_fp, MATCH_SO_A_ADDS_FP, MASK_SO_A_ADDS_FP)
+DECLARE_INSN(so_a_adds_sg, MATCH_SO_A_ADDS_SG, MASK_SO_A_ADDS_SG)
+DECLARE_INSN(so_a_adds_us, MATCH_SO_A_ADDS_US, MASK_SO_A_ADDS_US)
+DECLARE_INSN(so_a_and, MATCH_SO_A_AND, MASK_SO_A_AND)
+DECLARE_INSN(so_a_dec_fp, MATCH_SO_A_DEC_FP, MASK_SO_A_DEC_FP)
+DECLARE_INSN(so_a_dec_sg, MATCH_SO_A_DEC_SG, MASK_SO_A_DEC_SG)
+DECLARE_INSN(so_a_dec_us, MATCH_SO_A_DEC_US, MASK_SO_A_DEC_US)
+DECLARE_INSN(so_a_div_fp, MATCH_SO_A_DIV_FP, MASK_SO_A_DIV_FP)
+DECLARE_INSN(so_a_div_sg, MATCH_SO_A_DIV_SG, MASK_SO_A_DIV_SG)
+DECLARE_INSN(so_a_div_us, MATCH_SO_A_DIV_US, MASK_SO_A_DIV_US)
+DECLARE_INSN(so_a_inc_fp, MATCH_SO_A_INC_FP, MASK_SO_A_INC_FP)
+DECLARE_INSN(so_a_inc_sg, MATCH_SO_A_INC_SG, MASK_SO_A_INC_SG)
+DECLARE_INSN(so_a_inc_us, MATCH_SO_A_INC_US, MASK_SO_A_INC_US)
+DECLARE_INSN(so_a_mac_fp, MATCH_SO_A_MAC_FP, MASK_SO_A_MAC_FP)
+DECLARE_INSN(so_a_mac_sg, MATCH_SO_A_MAC_SG, MASK_SO_A_MAC_SG)
+DECLARE_INSN(so_a_mac_us, MATCH_SO_A_MAC_US, MASK_SO_A_MAC_US)
+DECLARE_INSN(so_a_max_fp, MATCH_SO_A_MAX_FP, MASK_SO_A_MAX_FP)
+DECLARE_INSN(so_a_max_sg, MATCH_SO_A_MAX_SG, MASK_SO_A_MAX_SG)
+DECLARE_INSN(so_a_max_us, MATCH_SO_A_MAX_US, MASK_SO_A_MAX_US)
+DECLARE_INSN(so_a_maxe_fp, MATCH_SO_A_MAXE_FP, MASK_SO_A_MAXE_FP)
+DECLARE_INSN(so_a_maxe_sg, MATCH_SO_A_MAXE_SG, MASK_SO_A_MAXE_SG)
+DECLARE_INSN(so_a_maxe_us, MATCH_SO_A_MAXE_US, MASK_SO_A_MAXE_US)
+DECLARE_INSN(so_a_min_fp, MATCH_SO_A_MIN_FP, MASK_SO_A_MIN_FP)
+DECLARE_INSN(so_a_min_sg, MATCH_SO_A_MIN_SG, MASK_SO_A_MIN_SG)
+DECLARE_INSN(so_a_min_us, MATCH_SO_A_MIN_US, MASK_SO_A_MIN_US)
+DECLARE_INSN(so_a_mine_fp, MATCH_SO_A_MINE_FP, MASK_SO_A_MINE_FP)
+DECLARE_INSN(so_a_mine_sg, MATCH_SO_A_MINE_SG, MASK_SO_A_MINE_SG)
+DECLARE_INSN(so_a_mine_us, MATCH_SO_A_MINE_US, MASK_SO_A_MINE_US)
+DECLARE_INSN(so_a_mul_fp, MATCH_SO_A_MUL_FP, MASK_SO_A_MUL_FP)
+DECLARE_INSN(so_a_mul_sg, MATCH_SO_A_MUL_SG, MASK_SO_A_MUL_SG)
+DECLARE_INSN(so_a_mul_us, MATCH_SO_A_MUL_US, MASK_SO_A_MUL_US)
+DECLARE_INSN(so_a_nand, MATCH_SO_A_NAND, MASK_SO_A_NAND)
+DECLARE_INSN(so_a_nor, MATCH_SO_A_NOR, MASK_SO_A_NOR)
+DECLARE_INSN(so_a_not, MATCH_SO_A_NOT, MASK_SO_A_NOT)
+DECLARE_INSN(so_a_or, MATCH_SO_A_OR, MASK_SO_A_OR)
+DECLARE_INSN(so_a_sll, MATCH_SO_A_SLL, MASK_SO_A_SLL)
+DECLARE_INSN(so_a_slls, MATCH_SO_A_SLLS, MASK_SO_A_SLLS)
+DECLARE_INSN(so_a_sra, MATCH_SO_A_SRA, MASK_SO_A_SRA)
+DECLARE_INSN(so_a_sras, MATCH_SO_A_SRAS, MASK_SO_A_SRAS)
+DECLARE_INSN(so_a_srl, MATCH_SO_A_SRL, MASK_SO_A_SRL)
+DECLARE_INSN(so_a_srls, MATCH_SO_A_SRLS, MASK_SO_A_SRLS)
+DECLARE_INSN(so_a_sub_fp, MATCH_SO_A_SUB_FP, MASK_SO_A_SUB_FP)
+DECLARE_INSN(so_a_sub_sg, MATCH_SO_A_SUB_SG, MASK_SO_A_SUB_SG)
+DECLARE_INSN(so_a_sub_us, MATCH_SO_A_SUB_US, MASK_SO_A_SUB_US)
+DECLARE_INSN(so_a_xor, MATCH_SO_A_XOR, MASK_SO_A_XOR)
+DECLARE_INSN(so_b_c, MATCH_SO_B_C, MASK_SO_B_C)
+DECLARE_INSN(so_b_dc_1, MATCH_SO_B_DC_1, MASK_SO_B_DC_1)
+DECLARE_INSN(so_b_dc_2, MATCH_SO_B_DC_2, MASK_SO_B_DC_2)
+DECLARE_INSN(so_b_dc_3, MATCH_SO_B_DC_3, MASK_SO_B_DC_3)
+DECLARE_INSN(so_b_dc_4, MATCH_SO_B_DC_4, MASK_SO_B_DC_4)
+DECLARE_INSN(so_b_dc_5, MATCH_SO_B_DC_5, MASK_SO_B_DC_5)
+DECLARE_INSN(so_b_dc_6, MATCH_SO_B_DC_6, MASK_SO_B_DC_6)
+DECLARE_INSN(so_b_dc_7, MATCH_SO_B_DC_7, MASK_SO_B_DC_7)
+DECLARE_INSN(so_b_nc, MATCH_SO_B_NC, MASK_SO_B_NC)
+DECLARE_INSN(so_b_ndc_1, MATCH_SO_B_NDC_1, MASK_SO_B_NDC_1)
+DECLARE_INSN(so_b_ndc_2, MATCH_SO_B_NDC_2, MASK_SO_B_NDC_2)
+DECLARE_INSN(so_b_ndc_3, MATCH_SO_B_NDC_3, MASK_SO_B_NDC_3)
+DECLARE_INSN(so_b_ndc_4, MATCH_SO_B_NDC_4, MASK_SO_B_NDC_4)
+DECLARE_INSN(so_b_ndc_5, MATCH_SO_B_NDC_5, MASK_SO_B_NDC_5)
+DECLARE_INSN(so_b_ndc_6, MATCH_SO_B_NDC_6, MASK_SO_B_NDC_6)
+DECLARE_INSN(so_b_ndc_7, MATCH_SO_B_NDC_7, MASK_SO_B_NDC_7)
+DECLARE_INSN(so_c_break, MATCH_SO_C_BREAK, MASK_SO_C_BREAK)
+DECLARE_INSN(so_c_getvl, MATCH_SO_C_GETVL, MASK_SO_C_GETVL)
+DECLARE_INSN(so_c_resum, MATCH_SO_C_RESUM, MASK_SO_C_RESUM)
+DECLARE_INSN(so_c_setvl, MATCH_SO_C_SETVL, MASK_SO_C_SETVL)
+DECLARE_INSN(so_c_suspd, MATCH_SO_C_SUSPD, MASK_SO_C_SUSPD)
+DECLARE_INSN(so_c_vload, MATCH_SO_C_VLOAD, MASK_SO_C_VLOAD)
+DECLARE_INSN(so_c_vstor, MATCH_SO_C_VSTOR, MASK_SO_C_VSTOR)
+DECLARE_INSN(so_p_cv_b_b, MATCH_SO_P_CV_B_B, MASK_SO_P_CV_B_B)
+DECLARE_INSN(so_p_cv_b_b_z, MATCH_SO_P_CV_B_B_Z, MASK_SO_P_CV_B_B_Z)
+DECLARE_INSN(so_p_cv_d_d, MATCH_SO_P_CV_D_D, MASK_SO_P_CV_D_D)
+DECLARE_INSN(so_p_cv_d_d_z, MATCH_SO_P_CV_D_D_Z, MASK_SO_P_CV_D_D_Z)
+DECLARE_INSN(so_p_cv_h_h, MATCH_SO_P_CV_H_H, MASK_SO_P_CV_H_H)
+DECLARE_INSN(so_p_cv_h_h_z, MATCH_SO_P_CV_H_H_Z, MASK_SO_P_CV_H_H_Z)
+DECLARE_INSN(so_p_cv_w_w, MATCH_SO_P_CV_W_W, MASK_SO_P_CV_W_W)
+DECLARE_INSN(so_p_cv_w_w_z, MATCH_SO_P_CV_W_W_Z, MASK_SO_P_CV_W_W_Z)
+DECLARE_INSN(so_p_eq_fp, MATCH_SO_P_EQ_FP, MASK_SO_P_EQ_FP)
+DECLARE_INSN(so_p_eq_fp_z, MATCH_SO_P_EQ_FP_Z, MASK_SO_P_EQ_FP_Z)
+DECLARE_INSN(so_p_eq_sg, MATCH_SO_P_EQ_SG, MASK_SO_P_EQ_SG)
+DECLARE_INSN(so_p_eq_sg_z, MATCH_SO_P_EQ_SG_Z, MASK_SO_P_EQ_SG_Z)
+DECLARE_INSN(so_p_eq_us, MATCH_SO_P_EQ_US, MASK_SO_P_EQ_US)
+DECLARE_INSN(so_p_eq_us_z, MATCH_SO_P_EQ_US_Z, MASK_SO_P_EQ_US_Z)
+DECLARE_INSN(so_p_ge_fp, MATCH_SO_P_GE_FP, MASK_SO_P_GE_FP)
+DECLARE_INSN(so_p_ge_fp_z, MATCH_SO_P_GE_FP_Z, MASK_SO_P_GE_FP_Z)
+DECLARE_INSN(so_p_ge_sg, MATCH_SO_P_GE_SG, MASK_SO_P_GE_SG)
+DECLARE_INSN(so_p_ge_sg_z, MATCH_SO_P_GE_SG_Z, MASK_SO_P_GE_SG_Z)
+DECLARE_INSN(so_p_ge_us, MATCH_SO_P_GE_US, MASK_SO_P_GE_US)
+DECLARE_INSN(so_p_ge_us_z, MATCH_SO_P_GE_US_Z, MASK_SO_P_GE_US_Z)
+DECLARE_INSN(so_p_lt_fp, MATCH_SO_P_LT_FP, MASK_SO_P_LT_FP)
+DECLARE_INSN(so_p_lt_fp_z, MATCH_SO_P_LT_FP_Z, MASK_SO_P_LT_FP_Z)
+DECLARE_INSN(so_p_lt_sg, MATCH_SO_P_LT_SG, MASK_SO_P_LT_SG)
+DECLARE_INSN(so_p_lt_sg_z, MATCH_SO_P_LT_SG_Z, MASK_SO_P_LT_SG_Z)
+DECLARE_INSN(so_p_lt_us, MATCH_SO_P_LT_US, MASK_SO_P_LT_US)
+DECLARE_INSN(so_p_lt_us_z, MATCH_SO_P_LT_US_Z, MASK_SO_P_LT_US_Z)
+DECLARE_INSN(so_p_mv, MATCH_SO_P_MV, MASK_SO_P_MV)
+DECLARE_INSN(so_p_mv_z, MATCH_SO_P_MV_Z, MASK_SO_P_MV_Z)
+DECLARE_INSN(so_p_mvt, MATCH_SO_P_MVT, MASK_SO_P_MVT)
+DECLARE_INSN(so_p_mvt_z, MATCH_SO_P_MVT_Z, MASK_SO_P_MVT_Z)
+DECLARE_INSN(so_p_not, MATCH_SO_P_NOT, MASK_SO_P_NOT)
+DECLARE_INSN(so_p_not_z, MATCH_SO_P_NOT_Z, MASK_SO_P_NOT_Z)
+DECLARE_INSN(so_p_one, MATCH_SO_P_ONE, MASK_SO_P_ONE)
+DECLARE_INSN(so_p_one_z, MATCH_SO_P_ONE_Z, MASK_SO_P_ONE_Z)
+DECLARE_INSN(so_p_vr, MATCH_SO_P_VR, MASK_SO_P_VR)
+DECLARE_INSN(so_p_vr_z, MATCH_SO_P_VR_Z, MASK_SO_P_VR_Z)
+DECLARE_INSN(so_p_zero, MATCH_SO_P_ZERO, MASK_SO_P_ZERO)
+DECLARE_INSN(so_p_zero_z, MATCH_SO_P_ZERO_Z, MASK_SO_P_ZERO_Z)
+DECLARE_INSN(so_v_cv_fp_b, MATCH_SO_V_CV_FP_B, MASK_SO_V_CV_FP_B)
+DECLARE_INSN(so_v_cv_fp_d, MATCH_SO_V_CV_FP_D, MASK_SO_V_CV_FP_D)
+DECLARE_INSN(so_v_cv_fp_h, MATCH_SO_V_CV_FP_H, MASK_SO_V_CV_FP_H)
+DECLARE_INSN(so_v_cv_fp_w, MATCH_SO_V_CV_FP_W, MASK_SO_V_CV_FP_W)
+DECLARE_INSN(so_v_cv_sg_b, MATCH_SO_V_CV_SG_B, MASK_SO_V_CV_SG_B)
+DECLARE_INSN(so_v_cv_sg_d, MATCH_SO_V_CV_SG_D, MASK_SO_V_CV_SG_D)
+DECLARE_INSN(so_v_cv_sg_h, MATCH_SO_V_CV_SG_H, MASK_SO_V_CV_SG_H)
+DECLARE_INSN(so_v_cv_sg_w, MATCH_SO_V_CV_SG_W, MASK_SO_V_CV_SG_W)
+DECLARE_INSN(so_v_cv_us_b, MATCH_SO_V_CV_US_B, MASK_SO_V_CV_US_B)
+DECLARE_INSN(so_v_cv_us_d, MATCH_SO_V_CV_US_D, MASK_SO_V_CV_US_D)
+DECLARE_INSN(so_v_cv_us_h, MATCH_SO_V_CV_US_H, MASK_SO_V_CV_US_H)
+DECLARE_INSN(so_v_cv_us_w, MATCH_SO_V_CV_US_W, MASK_SO_V_CV_US_W)
+DECLARE_INSN(so_v_dp_b, MATCH_SO_V_DP_B, MASK_SO_V_DP_B)
+DECLARE_INSN(so_v_dp_d, MATCH_SO_V_DP_D, MASK_SO_V_DP_D)
+DECLARE_INSN(so_v_dp_h, MATCH_SO_V_DP_H, MASK_SO_V_DP_H)
+DECLARE_INSN(so_v_dp_w, MATCH_SO_V_DP_W, MASK_SO_V_DP_W)
+DECLARE_INSN(so_v_mv, MATCH_SO_V_MV, MASK_SO_V_MV)
+DECLARE_INSN(so_v_mvsv_b, MATCH_SO_V_MVSV_B, MASK_SO_V_MVSV_B)
+DECLARE_INSN(so_v_mvsv_d, MATCH_SO_V_MVSV_D, MASK_SO_V_MVSV_D)
+DECLARE_INSN(so_v_mvsv_h, MATCH_SO_V_MVSV_H, MASK_SO_V_MVSV_H)
+DECLARE_INSN(so_v_mvsv_w, MATCH_SO_V_MVSV_W, MASK_SO_V_MVSV_W)
+DECLARE_INSN(so_v_mvt, MATCH_SO_V_MVT, MASK_SO_V_MVT)
+DECLARE_INSN(so_v_mvvs, MATCH_SO_V_MVVS, MASK_SO_V_MVVS)
 DECLARE_INSN(sra, MATCH_SRA, MASK_SRA)
 DECLARE_INSN(srai, MATCH_SRAI, MASK_SRAI)
 DECLARE_INSN(srai_rv32, MATCH_SRAI_RV32, MASK_SRAI_RV32)
@@ -3547,10 +5541,794 @@ DECLARE_INSN(srli, MATCH_SRLI, MASK_SRLI)
 DECLARE_INSN(srli_rv32, MATCH_SRLI_RV32, MASK_SRLI_RV32)
 DECLARE_INSN(srliw, MATCH_SRLIW, MASK_SRLIW)
 DECLARE_INSN(srlw, MATCH_SRLW, MASK_SRLW)
-DECLARE_INSN(sro, MATCH_SRO, MASK_SRO)
-DECLARE_INSN(sroi, MATCH_SROI, MASK_SROI)
-DECLARE_INSN(sroiw, MATCH_SROIW, MASK_SROIW)
-DECLARE_INSN(srow, MATCH_SROW, MASK_SROW)
+DECLARE_INSN(ss_app, MATCH_SS_APP, MASK_SS_APP)
+DECLARE_INSN(ss_app_ind_ofs_add_1, MATCH_SS_APP_IND_OFS_ADD_1, MASK_SS_APP_IND_OFS_ADD_1)
+DECLARE_INSN(ss_app_ind_ofs_add_2, MATCH_SS_APP_IND_OFS_ADD_2, MASK_SS_APP_IND_OFS_ADD_2)
+DECLARE_INSN(ss_app_ind_ofs_add_3, MATCH_SS_APP_IND_OFS_ADD_3, MASK_SS_APP_IND_OFS_ADD_3)
+DECLARE_INSN(ss_app_ind_ofs_add_4, MATCH_SS_APP_IND_OFS_ADD_4, MASK_SS_APP_IND_OFS_ADD_4)
+DECLARE_INSN(ss_app_ind_ofs_add_5, MATCH_SS_APP_IND_OFS_ADD_5, MASK_SS_APP_IND_OFS_ADD_5)
+DECLARE_INSN(ss_app_ind_ofs_add_6, MATCH_SS_APP_IND_OFS_ADD_6, MASK_SS_APP_IND_OFS_ADD_6)
+DECLARE_INSN(ss_app_ind_ofs_add_7, MATCH_SS_APP_IND_OFS_ADD_7, MASK_SS_APP_IND_OFS_ADD_7)
+DECLARE_INSN(ss_app_ind_ofs_add_l, MATCH_SS_APP_IND_OFS_ADD_L, MASK_SS_APP_IND_OFS_ADD_L)
+DECLARE_INSN(ss_app_ind_ofs_dec_1, MATCH_SS_APP_IND_OFS_DEC_1, MASK_SS_APP_IND_OFS_DEC_1)
+DECLARE_INSN(ss_app_ind_ofs_dec_2, MATCH_SS_APP_IND_OFS_DEC_2, MASK_SS_APP_IND_OFS_DEC_2)
+DECLARE_INSN(ss_app_ind_ofs_dec_3, MATCH_SS_APP_IND_OFS_DEC_3, MASK_SS_APP_IND_OFS_DEC_3)
+DECLARE_INSN(ss_app_ind_ofs_dec_4, MATCH_SS_APP_IND_OFS_DEC_4, MASK_SS_APP_IND_OFS_DEC_4)
+DECLARE_INSN(ss_app_ind_ofs_dec_5, MATCH_SS_APP_IND_OFS_DEC_5, MASK_SS_APP_IND_OFS_DEC_5)
+DECLARE_INSN(ss_app_ind_ofs_dec_6, MATCH_SS_APP_IND_OFS_DEC_6, MASK_SS_APP_IND_OFS_DEC_6)
+DECLARE_INSN(ss_app_ind_ofs_dec_7, MATCH_SS_APP_IND_OFS_DEC_7, MASK_SS_APP_IND_OFS_DEC_7)
+DECLARE_INSN(ss_app_ind_ofs_dec_l, MATCH_SS_APP_IND_OFS_DEC_L, MASK_SS_APP_IND_OFS_DEC_L)
+DECLARE_INSN(ss_app_ind_ofs_inc_1, MATCH_SS_APP_IND_OFS_INC_1, MASK_SS_APP_IND_OFS_INC_1)
+DECLARE_INSN(ss_app_ind_ofs_inc_2, MATCH_SS_APP_IND_OFS_INC_2, MASK_SS_APP_IND_OFS_INC_2)
+DECLARE_INSN(ss_app_ind_ofs_inc_3, MATCH_SS_APP_IND_OFS_INC_3, MASK_SS_APP_IND_OFS_INC_3)
+DECLARE_INSN(ss_app_ind_ofs_inc_4, MATCH_SS_APP_IND_OFS_INC_4, MASK_SS_APP_IND_OFS_INC_4)
+DECLARE_INSN(ss_app_ind_ofs_inc_5, MATCH_SS_APP_IND_OFS_INC_5, MASK_SS_APP_IND_OFS_INC_5)
+DECLARE_INSN(ss_app_ind_ofs_inc_6, MATCH_SS_APP_IND_OFS_INC_6, MASK_SS_APP_IND_OFS_INC_6)
+DECLARE_INSN(ss_app_ind_ofs_inc_7, MATCH_SS_APP_IND_OFS_INC_7, MASK_SS_APP_IND_OFS_INC_7)
+DECLARE_INSN(ss_app_ind_ofs_inc_l, MATCH_SS_APP_IND_OFS_INC_L, MASK_SS_APP_IND_OFS_INC_L)
+DECLARE_INSN(ss_app_ind_ofs_set_1, MATCH_SS_APP_IND_OFS_SET_1, MASK_SS_APP_IND_OFS_SET_1)
+DECLARE_INSN(ss_app_ind_ofs_set_2, MATCH_SS_APP_IND_OFS_SET_2, MASK_SS_APP_IND_OFS_SET_2)
+DECLARE_INSN(ss_app_ind_ofs_set_3, MATCH_SS_APP_IND_OFS_SET_3, MASK_SS_APP_IND_OFS_SET_3)
+DECLARE_INSN(ss_app_ind_ofs_set_4, MATCH_SS_APP_IND_OFS_SET_4, MASK_SS_APP_IND_OFS_SET_4)
+DECLARE_INSN(ss_app_ind_ofs_set_5, MATCH_SS_APP_IND_OFS_SET_5, MASK_SS_APP_IND_OFS_SET_5)
+DECLARE_INSN(ss_app_ind_ofs_set_6, MATCH_SS_APP_IND_OFS_SET_6, MASK_SS_APP_IND_OFS_SET_6)
+DECLARE_INSN(ss_app_ind_ofs_set_7, MATCH_SS_APP_IND_OFS_SET_7, MASK_SS_APP_IND_OFS_SET_7)
+DECLARE_INSN(ss_app_ind_ofs_set_l, MATCH_SS_APP_IND_OFS_SET_L, MASK_SS_APP_IND_OFS_SET_L)
+DECLARE_INSN(ss_app_ind_ofs_sg_add, MATCH_SS_APP_IND_OFS_SG_ADD, MASK_SS_APP_IND_OFS_SG_ADD)
+DECLARE_INSN(ss_app_ind_ofs_sg_dec, MATCH_SS_APP_IND_OFS_SG_DEC, MASK_SS_APP_IND_OFS_SG_DEC)
+DECLARE_INSN(ss_app_ind_ofs_sg_inc, MATCH_SS_APP_IND_OFS_SG_INC, MASK_SS_APP_IND_OFS_SG_INC)
+DECLARE_INSN(ss_app_ind_ofs_sg_set, MATCH_SS_APP_IND_OFS_SG_SET, MASK_SS_APP_IND_OFS_SG_SET)
+DECLARE_INSN(ss_app_ind_ofs_sg_sub, MATCH_SS_APP_IND_OFS_SG_SUB, MASK_SS_APP_IND_OFS_SG_SUB)
+DECLARE_INSN(ss_app_ind_ofs_sub_1, MATCH_SS_APP_IND_OFS_SUB_1, MASK_SS_APP_IND_OFS_SUB_1)
+DECLARE_INSN(ss_app_ind_ofs_sub_2, MATCH_SS_APP_IND_OFS_SUB_2, MASK_SS_APP_IND_OFS_SUB_2)
+DECLARE_INSN(ss_app_ind_ofs_sub_3, MATCH_SS_APP_IND_OFS_SUB_3, MASK_SS_APP_IND_OFS_SUB_3)
+DECLARE_INSN(ss_app_ind_ofs_sub_4, MATCH_SS_APP_IND_OFS_SUB_4, MASK_SS_APP_IND_OFS_SUB_4)
+DECLARE_INSN(ss_app_ind_ofs_sub_5, MATCH_SS_APP_IND_OFS_SUB_5, MASK_SS_APP_IND_OFS_SUB_5)
+DECLARE_INSN(ss_app_ind_ofs_sub_6, MATCH_SS_APP_IND_OFS_SUB_6, MASK_SS_APP_IND_OFS_SUB_6)
+DECLARE_INSN(ss_app_ind_ofs_sub_7, MATCH_SS_APP_IND_OFS_SUB_7, MASK_SS_APP_IND_OFS_SUB_7)
+DECLARE_INSN(ss_app_ind_ofs_sub_l, MATCH_SS_APP_IND_OFS_SUB_L, MASK_SS_APP_IND_OFS_SUB_L)
+DECLARE_INSN(ss_app_ind_siz_add_1, MATCH_SS_APP_IND_SIZ_ADD_1, MASK_SS_APP_IND_SIZ_ADD_1)
+DECLARE_INSN(ss_app_ind_siz_add_2, MATCH_SS_APP_IND_SIZ_ADD_2, MASK_SS_APP_IND_SIZ_ADD_2)
+DECLARE_INSN(ss_app_ind_siz_add_3, MATCH_SS_APP_IND_SIZ_ADD_3, MASK_SS_APP_IND_SIZ_ADD_3)
+DECLARE_INSN(ss_app_ind_siz_add_4, MATCH_SS_APP_IND_SIZ_ADD_4, MASK_SS_APP_IND_SIZ_ADD_4)
+DECLARE_INSN(ss_app_ind_siz_add_5, MATCH_SS_APP_IND_SIZ_ADD_5, MASK_SS_APP_IND_SIZ_ADD_5)
+DECLARE_INSN(ss_app_ind_siz_add_6, MATCH_SS_APP_IND_SIZ_ADD_6, MASK_SS_APP_IND_SIZ_ADD_6)
+DECLARE_INSN(ss_app_ind_siz_add_7, MATCH_SS_APP_IND_SIZ_ADD_7, MASK_SS_APP_IND_SIZ_ADD_7)
+DECLARE_INSN(ss_app_ind_siz_add_l, MATCH_SS_APP_IND_SIZ_ADD_L, MASK_SS_APP_IND_SIZ_ADD_L)
+DECLARE_INSN(ss_app_ind_siz_dec_1, MATCH_SS_APP_IND_SIZ_DEC_1, MASK_SS_APP_IND_SIZ_DEC_1)
+DECLARE_INSN(ss_app_ind_siz_dec_2, MATCH_SS_APP_IND_SIZ_DEC_2, MASK_SS_APP_IND_SIZ_DEC_2)
+DECLARE_INSN(ss_app_ind_siz_dec_3, MATCH_SS_APP_IND_SIZ_DEC_3, MASK_SS_APP_IND_SIZ_DEC_3)
+DECLARE_INSN(ss_app_ind_siz_dec_4, MATCH_SS_APP_IND_SIZ_DEC_4, MASK_SS_APP_IND_SIZ_DEC_4)
+DECLARE_INSN(ss_app_ind_siz_dec_5, MATCH_SS_APP_IND_SIZ_DEC_5, MASK_SS_APP_IND_SIZ_DEC_5)
+DECLARE_INSN(ss_app_ind_siz_dec_6, MATCH_SS_APP_IND_SIZ_DEC_6, MASK_SS_APP_IND_SIZ_DEC_6)
+DECLARE_INSN(ss_app_ind_siz_dec_7, MATCH_SS_APP_IND_SIZ_DEC_7, MASK_SS_APP_IND_SIZ_DEC_7)
+DECLARE_INSN(ss_app_ind_siz_dec_l, MATCH_SS_APP_IND_SIZ_DEC_L, MASK_SS_APP_IND_SIZ_DEC_L)
+DECLARE_INSN(ss_app_ind_siz_inc_1, MATCH_SS_APP_IND_SIZ_INC_1, MASK_SS_APP_IND_SIZ_INC_1)
+DECLARE_INSN(ss_app_ind_siz_inc_2, MATCH_SS_APP_IND_SIZ_INC_2, MASK_SS_APP_IND_SIZ_INC_2)
+DECLARE_INSN(ss_app_ind_siz_inc_3, MATCH_SS_APP_IND_SIZ_INC_3, MASK_SS_APP_IND_SIZ_INC_3)
+DECLARE_INSN(ss_app_ind_siz_inc_4, MATCH_SS_APP_IND_SIZ_INC_4, MASK_SS_APP_IND_SIZ_INC_4)
+DECLARE_INSN(ss_app_ind_siz_inc_5, MATCH_SS_APP_IND_SIZ_INC_5, MASK_SS_APP_IND_SIZ_INC_5)
+DECLARE_INSN(ss_app_ind_siz_inc_6, MATCH_SS_APP_IND_SIZ_INC_6, MASK_SS_APP_IND_SIZ_INC_6)
+DECLARE_INSN(ss_app_ind_siz_inc_7, MATCH_SS_APP_IND_SIZ_INC_7, MASK_SS_APP_IND_SIZ_INC_7)
+DECLARE_INSN(ss_app_ind_siz_inc_l, MATCH_SS_APP_IND_SIZ_INC_L, MASK_SS_APP_IND_SIZ_INC_L)
+DECLARE_INSN(ss_app_ind_siz_set_1, MATCH_SS_APP_IND_SIZ_SET_1, MASK_SS_APP_IND_SIZ_SET_1)
+DECLARE_INSN(ss_app_ind_siz_set_2, MATCH_SS_APP_IND_SIZ_SET_2, MASK_SS_APP_IND_SIZ_SET_2)
+DECLARE_INSN(ss_app_ind_siz_set_3, MATCH_SS_APP_IND_SIZ_SET_3, MASK_SS_APP_IND_SIZ_SET_3)
+DECLARE_INSN(ss_app_ind_siz_set_4, MATCH_SS_APP_IND_SIZ_SET_4, MASK_SS_APP_IND_SIZ_SET_4)
+DECLARE_INSN(ss_app_ind_siz_set_5, MATCH_SS_APP_IND_SIZ_SET_5, MASK_SS_APP_IND_SIZ_SET_5)
+DECLARE_INSN(ss_app_ind_siz_set_6, MATCH_SS_APP_IND_SIZ_SET_6, MASK_SS_APP_IND_SIZ_SET_6)
+DECLARE_INSN(ss_app_ind_siz_set_7, MATCH_SS_APP_IND_SIZ_SET_7, MASK_SS_APP_IND_SIZ_SET_7)
+DECLARE_INSN(ss_app_ind_siz_set_l, MATCH_SS_APP_IND_SIZ_SET_L, MASK_SS_APP_IND_SIZ_SET_L)
+DECLARE_INSN(ss_app_ind_siz_sub_1, MATCH_SS_APP_IND_SIZ_SUB_1, MASK_SS_APP_IND_SIZ_SUB_1)
+DECLARE_INSN(ss_app_ind_siz_sub_2, MATCH_SS_APP_IND_SIZ_SUB_2, MASK_SS_APP_IND_SIZ_SUB_2)
+DECLARE_INSN(ss_app_ind_siz_sub_3, MATCH_SS_APP_IND_SIZ_SUB_3, MASK_SS_APP_IND_SIZ_SUB_3)
+DECLARE_INSN(ss_app_ind_siz_sub_4, MATCH_SS_APP_IND_SIZ_SUB_4, MASK_SS_APP_IND_SIZ_SUB_4)
+DECLARE_INSN(ss_app_ind_siz_sub_5, MATCH_SS_APP_IND_SIZ_SUB_5, MASK_SS_APP_IND_SIZ_SUB_5)
+DECLARE_INSN(ss_app_ind_siz_sub_6, MATCH_SS_APP_IND_SIZ_SUB_6, MASK_SS_APP_IND_SIZ_SUB_6)
+DECLARE_INSN(ss_app_ind_siz_sub_7, MATCH_SS_APP_IND_SIZ_SUB_7, MASK_SS_APP_IND_SIZ_SUB_7)
+DECLARE_INSN(ss_app_ind_siz_sub_l, MATCH_SS_APP_IND_SIZ_SUB_L, MASK_SS_APP_IND_SIZ_SUB_L)
+DECLARE_INSN(ss_app_ind_str_add_1, MATCH_SS_APP_IND_STR_ADD_1, MASK_SS_APP_IND_STR_ADD_1)
+DECLARE_INSN(ss_app_ind_str_add_2, MATCH_SS_APP_IND_STR_ADD_2, MASK_SS_APP_IND_STR_ADD_2)
+DECLARE_INSN(ss_app_ind_str_add_3, MATCH_SS_APP_IND_STR_ADD_3, MASK_SS_APP_IND_STR_ADD_3)
+DECLARE_INSN(ss_app_ind_str_add_4, MATCH_SS_APP_IND_STR_ADD_4, MASK_SS_APP_IND_STR_ADD_4)
+DECLARE_INSN(ss_app_ind_str_add_5, MATCH_SS_APP_IND_STR_ADD_5, MASK_SS_APP_IND_STR_ADD_5)
+DECLARE_INSN(ss_app_ind_str_add_6, MATCH_SS_APP_IND_STR_ADD_6, MASK_SS_APP_IND_STR_ADD_6)
+DECLARE_INSN(ss_app_ind_str_add_7, MATCH_SS_APP_IND_STR_ADD_7, MASK_SS_APP_IND_STR_ADD_7)
+DECLARE_INSN(ss_app_ind_str_add_l, MATCH_SS_APP_IND_STR_ADD_L, MASK_SS_APP_IND_STR_ADD_L)
+DECLARE_INSN(ss_app_ind_str_dec_1, MATCH_SS_APP_IND_STR_DEC_1, MASK_SS_APP_IND_STR_DEC_1)
+DECLARE_INSN(ss_app_ind_str_dec_2, MATCH_SS_APP_IND_STR_DEC_2, MASK_SS_APP_IND_STR_DEC_2)
+DECLARE_INSN(ss_app_ind_str_dec_3, MATCH_SS_APP_IND_STR_DEC_3, MASK_SS_APP_IND_STR_DEC_3)
+DECLARE_INSN(ss_app_ind_str_dec_4, MATCH_SS_APP_IND_STR_DEC_4, MASK_SS_APP_IND_STR_DEC_4)
+DECLARE_INSN(ss_app_ind_str_dec_5, MATCH_SS_APP_IND_STR_DEC_5, MASK_SS_APP_IND_STR_DEC_5)
+DECLARE_INSN(ss_app_ind_str_dec_6, MATCH_SS_APP_IND_STR_DEC_6, MASK_SS_APP_IND_STR_DEC_6)
+DECLARE_INSN(ss_app_ind_str_dec_7, MATCH_SS_APP_IND_STR_DEC_7, MASK_SS_APP_IND_STR_DEC_7)
+DECLARE_INSN(ss_app_ind_str_dec_l, MATCH_SS_APP_IND_STR_DEC_L, MASK_SS_APP_IND_STR_DEC_L)
+DECLARE_INSN(ss_app_ind_str_inc_1, MATCH_SS_APP_IND_STR_INC_1, MASK_SS_APP_IND_STR_INC_1)
+DECLARE_INSN(ss_app_ind_str_inc_2, MATCH_SS_APP_IND_STR_INC_2, MASK_SS_APP_IND_STR_INC_2)
+DECLARE_INSN(ss_app_ind_str_inc_3, MATCH_SS_APP_IND_STR_INC_3, MASK_SS_APP_IND_STR_INC_3)
+DECLARE_INSN(ss_app_ind_str_inc_4, MATCH_SS_APP_IND_STR_INC_4, MASK_SS_APP_IND_STR_INC_4)
+DECLARE_INSN(ss_app_ind_str_inc_5, MATCH_SS_APP_IND_STR_INC_5, MASK_SS_APP_IND_STR_INC_5)
+DECLARE_INSN(ss_app_ind_str_inc_6, MATCH_SS_APP_IND_STR_INC_6, MASK_SS_APP_IND_STR_INC_6)
+DECLARE_INSN(ss_app_ind_str_inc_7, MATCH_SS_APP_IND_STR_INC_7, MASK_SS_APP_IND_STR_INC_7)
+DECLARE_INSN(ss_app_ind_str_inc_l, MATCH_SS_APP_IND_STR_INC_L, MASK_SS_APP_IND_STR_INC_L)
+DECLARE_INSN(ss_app_ind_str_set_1, MATCH_SS_APP_IND_STR_SET_1, MASK_SS_APP_IND_STR_SET_1)
+DECLARE_INSN(ss_app_ind_str_set_2, MATCH_SS_APP_IND_STR_SET_2, MASK_SS_APP_IND_STR_SET_2)
+DECLARE_INSN(ss_app_ind_str_set_3, MATCH_SS_APP_IND_STR_SET_3, MASK_SS_APP_IND_STR_SET_3)
+DECLARE_INSN(ss_app_ind_str_set_4, MATCH_SS_APP_IND_STR_SET_4, MASK_SS_APP_IND_STR_SET_4)
+DECLARE_INSN(ss_app_ind_str_set_5, MATCH_SS_APP_IND_STR_SET_5, MASK_SS_APP_IND_STR_SET_5)
+DECLARE_INSN(ss_app_ind_str_set_6, MATCH_SS_APP_IND_STR_SET_6, MASK_SS_APP_IND_STR_SET_6)
+DECLARE_INSN(ss_app_ind_str_set_7, MATCH_SS_APP_IND_STR_SET_7, MASK_SS_APP_IND_STR_SET_7)
+DECLARE_INSN(ss_app_ind_str_set_l, MATCH_SS_APP_IND_STR_SET_L, MASK_SS_APP_IND_STR_SET_L)
+DECLARE_INSN(ss_app_ind_str_sub_1, MATCH_SS_APP_IND_STR_SUB_1, MASK_SS_APP_IND_STR_SUB_1)
+DECLARE_INSN(ss_app_ind_str_sub_2, MATCH_SS_APP_IND_STR_SUB_2, MASK_SS_APP_IND_STR_SUB_2)
+DECLARE_INSN(ss_app_ind_str_sub_3, MATCH_SS_APP_IND_STR_SUB_3, MASK_SS_APP_IND_STR_SUB_3)
+DECLARE_INSN(ss_app_ind_str_sub_4, MATCH_SS_APP_IND_STR_SUB_4, MASK_SS_APP_IND_STR_SUB_4)
+DECLARE_INSN(ss_app_ind_str_sub_5, MATCH_SS_APP_IND_STR_SUB_5, MASK_SS_APP_IND_STR_SUB_5)
+DECLARE_INSN(ss_app_ind_str_sub_6, MATCH_SS_APP_IND_STR_SUB_6, MASK_SS_APP_IND_STR_SUB_6)
+DECLARE_INSN(ss_app_ind_str_sub_7, MATCH_SS_APP_IND_STR_SUB_7, MASK_SS_APP_IND_STR_SUB_7)
+DECLARE_INSN(ss_app_ind_str_sub_l, MATCH_SS_APP_IND_STR_SUB_L, MASK_SS_APP_IND_STR_SUB_L)
+DECLARE_INSN(ss_app_mod_ofs_dec_1, MATCH_SS_APP_MOD_OFS_DEC_1, MASK_SS_APP_MOD_OFS_DEC_1)
+DECLARE_INSN(ss_app_mod_ofs_dec_2, MATCH_SS_APP_MOD_OFS_DEC_2, MASK_SS_APP_MOD_OFS_DEC_2)
+DECLARE_INSN(ss_app_mod_ofs_dec_3, MATCH_SS_APP_MOD_OFS_DEC_3, MASK_SS_APP_MOD_OFS_DEC_3)
+DECLARE_INSN(ss_app_mod_ofs_dec_4, MATCH_SS_APP_MOD_OFS_DEC_4, MASK_SS_APP_MOD_OFS_DEC_4)
+DECLARE_INSN(ss_app_mod_ofs_dec_5, MATCH_SS_APP_MOD_OFS_DEC_5, MASK_SS_APP_MOD_OFS_DEC_5)
+DECLARE_INSN(ss_app_mod_ofs_dec_6, MATCH_SS_APP_MOD_OFS_DEC_6, MASK_SS_APP_MOD_OFS_DEC_6)
+DECLARE_INSN(ss_app_mod_ofs_dec_7, MATCH_SS_APP_MOD_OFS_DEC_7, MASK_SS_APP_MOD_OFS_DEC_7)
+DECLARE_INSN(ss_app_mod_ofs_dec_l, MATCH_SS_APP_MOD_OFS_DEC_L, MASK_SS_APP_MOD_OFS_DEC_L)
+DECLARE_INSN(ss_app_mod_ofs_inc_1, MATCH_SS_APP_MOD_OFS_INC_1, MASK_SS_APP_MOD_OFS_INC_1)
+DECLARE_INSN(ss_app_mod_ofs_inc_2, MATCH_SS_APP_MOD_OFS_INC_2, MASK_SS_APP_MOD_OFS_INC_2)
+DECLARE_INSN(ss_app_mod_ofs_inc_3, MATCH_SS_APP_MOD_OFS_INC_3, MASK_SS_APP_MOD_OFS_INC_3)
+DECLARE_INSN(ss_app_mod_ofs_inc_4, MATCH_SS_APP_MOD_OFS_INC_4, MASK_SS_APP_MOD_OFS_INC_4)
+DECLARE_INSN(ss_app_mod_ofs_inc_5, MATCH_SS_APP_MOD_OFS_INC_5, MASK_SS_APP_MOD_OFS_INC_5)
+DECLARE_INSN(ss_app_mod_ofs_inc_6, MATCH_SS_APP_MOD_OFS_INC_6, MASK_SS_APP_MOD_OFS_INC_6)
+DECLARE_INSN(ss_app_mod_ofs_inc_7, MATCH_SS_APP_MOD_OFS_INC_7, MASK_SS_APP_MOD_OFS_INC_7)
+DECLARE_INSN(ss_app_mod_ofs_inc_l, MATCH_SS_APP_MOD_OFS_INC_L, MASK_SS_APP_MOD_OFS_INC_L)
+DECLARE_INSN(ss_app_mod_siz_dec_1, MATCH_SS_APP_MOD_SIZ_DEC_1, MASK_SS_APP_MOD_SIZ_DEC_1)
+DECLARE_INSN(ss_app_mod_siz_dec_2, MATCH_SS_APP_MOD_SIZ_DEC_2, MASK_SS_APP_MOD_SIZ_DEC_2)
+DECLARE_INSN(ss_app_mod_siz_dec_3, MATCH_SS_APP_MOD_SIZ_DEC_3, MASK_SS_APP_MOD_SIZ_DEC_3)
+DECLARE_INSN(ss_app_mod_siz_dec_4, MATCH_SS_APP_MOD_SIZ_DEC_4, MASK_SS_APP_MOD_SIZ_DEC_4)
+DECLARE_INSN(ss_app_mod_siz_dec_5, MATCH_SS_APP_MOD_SIZ_DEC_5, MASK_SS_APP_MOD_SIZ_DEC_5)
+DECLARE_INSN(ss_app_mod_siz_dec_6, MATCH_SS_APP_MOD_SIZ_DEC_6, MASK_SS_APP_MOD_SIZ_DEC_6)
+DECLARE_INSN(ss_app_mod_siz_dec_7, MATCH_SS_APP_MOD_SIZ_DEC_7, MASK_SS_APP_MOD_SIZ_DEC_7)
+DECLARE_INSN(ss_app_mod_siz_dec_l, MATCH_SS_APP_MOD_SIZ_DEC_L, MASK_SS_APP_MOD_SIZ_DEC_L)
+DECLARE_INSN(ss_app_mod_siz_inc_1, MATCH_SS_APP_MOD_SIZ_INC_1, MASK_SS_APP_MOD_SIZ_INC_1)
+DECLARE_INSN(ss_app_mod_siz_inc_2, MATCH_SS_APP_MOD_SIZ_INC_2, MASK_SS_APP_MOD_SIZ_INC_2)
+DECLARE_INSN(ss_app_mod_siz_inc_3, MATCH_SS_APP_MOD_SIZ_INC_3, MASK_SS_APP_MOD_SIZ_INC_3)
+DECLARE_INSN(ss_app_mod_siz_inc_4, MATCH_SS_APP_MOD_SIZ_INC_4, MASK_SS_APP_MOD_SIZ_INC_4)
+DECLARE_INSN(ss_app_mod_siz_inc_5, MATCH_SS_APP_MOD_SIZ_INC_5, MASK_SS_APP_MOD_SIZ_INC_5)
+DECLARE_INSN(ss_app_mod_siz_inc_6, MATCH_SS_APP_MOD_SIZ_INC_6, MASK_SS_APP_MOD_SIZ_INC_6)
+DECLARE_INSN(ss_app_mod_siz_inc_7, MATCH_SS_APP_MOD_SIZ_INC_7, MASK_SS_APP_MOD_SIZ_INC_7)
+DECLARE_INSN(ss_app_mod_siz_inc_l, MATCH_SS_APP_MOD_SIZ_INC_L, MASK_SS_APP_MOD_SIZ_INC_L)
+DECLARE_INSN(ss_app_mod_str_dec_1, MATCH_SS_APP_MOD_STR_DEC_1, MASK_SS_APP_MOD_STR_DEC_1)
+DECLARE_INSN(ss_app_mod_str_dec_2, MATCH_SS_APP_MOD_STR_DEC_2, MASK_SS_APP_MOD_STR_DEC_2)
+DECLARE_INSN(ss_app_mod_str_dec_3, MATCH_SS_APP_MOD_STR_DEC_3, MASK_SS_APP_MOD_STR_DEC_3)
+DECLARE_INSN(ss_app_mod_str_dec_4, MATCH_SS_APP_MOD_STR_DEC_4, MASK_SS_APP_MOD_STR_DEC_4)
+DECLARE_INSN(ss_app_mod_str_dec_5, MATCH_SS_APP_MOD_STR_DEC_5, MASK_SS_APP_MOD_STR_DEC_5)
+DECLARE_INSN(ss_app_mod_str_dec_6, MATCH_SS_APP_MOD_STR_DEC_6, MASK_SS_APP_MOD_STR_DEC_6)
+DECLARE_INSN(ss_app_mod_str_dec_7, MATCH_SS_APP_MOD_STR_DEC_7, MASK_SS_APP_MOD_STR_DEC_7)
+DECLARE_INSN(ss_app_mod_str_dec_l, MATCH_SS_APP_MOD_STR_DEC_L, MASK_SS_APP_MOD_STR_DEC_L)
+DECLARE_INSN(ss_app_mod_str_inc_1, MATCH_SS_APP_MOD_STR_INC_1, MASK_SS_APP_MOD_STR_INC_1)
+DECLARE_INSN(ss_app_mod_str_inc_2, MATCH_SS_APP_MOD_STR_INC_2, MASK_SS_APP_MOD_STR_INC_2)
+DECLARE_INSN(ss_app_mod_str_inc_3, MATCH_SS_APP_MOD_STR_INC_3, MASK_SS_APP_MOD_STR_INC_3)
+DECLARE_INSN(ss_app_mod_str_inc_4, MATCH_SS_APP_MOD_STR_INC_4, MASK_SS_APP_MOD_STR_INC_4)
+DECLARE_INSN(ss_app_mod_str_inc_5, MATCH_SS_APP_MOD_STR_INC_5, MASK_SS_APP_MOD_STR_INC_5)
+DECLARE_INSN(ss_app_mod_str_inc_6, MATCH_SS_APP_MOD_STR_INC_6, MASK_SS_APP_MOD_STR_INC_6)
+DECLARE_INSN(ss_app_mod_str_inc_7, MATCH_SS_APP_MOD_STR_INC_7, MASK_SS_APP_MOD_STR_INC_7)
+DECLARE_INSN(ss_app_mod_str_inc_l, MATCH_SS_APP_MOD_STR_INC_L, MASK_SS_APP_MOD_STR_INC_L)
+DECLARE_INSN(ss_end, MATCH_SS_END, MASK_SS_END)
+DECLARE_INSN(ss_end_ind_ofs_sg_add, MATCH_SS_END_IND_OFS_SG_ADD, MASK_SS_END_IND_OFS_SG_ADD)
+DECLARE_INSN(ss_end_ind_ofs_sg_dec, MATCH_SS_END_IND_OFS_SG_DEC, MASK_SS_END_IND_OFS_SG_DEC)
+DECLARE_INSN(ss_end_ind_ofs_sg_inc, MATCH_SS_END_IND_OFS_SG_INC, MASK_SS_END_IND_OFS_SG_INC)
+DECLARE_INSN(ss_end_ind_ofs_sg_set, MATCH_SS_END_IND_OFS_SG_SET, MASK_SS_END_IND_OFS_SG_SET)
+DECLARE_INSN(ss_end_ind_ofs_sg_sub, MATCH_SS_END_IND_OFS_SG_SUB, MASK_SS_END_IND_OFS_SG_SUB)
+DECLARE_INSN(ss_sta_ld_b, MATCH_SS_STA_LD_B, MASK_SS_STA_LD_B)
+DECLARE_INSN(ss_sta_ld_b_inds, MATCH_SS_STA_LD_B_INDS, MASK_SS_STA_LD_B_INDS)
+DECLARE_INSN(ss_sta_ld_b_inds_mem1, MATCH_SS_STA_LD_B_INDS_MEM1, MASK_SS_STA_LD_B_INDS_MEM1)
+DECLARE_INSN(ss_sta_ld_b_inds_mem2, MATCH_SS_STA_LD_B_INDS_MEM2, MASK_SS_STA_LD_B_INDS_MEM2)
+DECLARE_INSN(ss_sta_ld_b_inds_mem3, MATCH_SS_STA_LD_B_INDS_MEM3, MASK_SS_STA_LD_B_INDS_MEM3)
+DECLARE_INSN(ss_sta_ld_b_m, MATCH_SS_STA_LD_B_M, MASK_SS_STA_LD_B_M)
+DECLARE_INSN(ss_sta_ld_b_m_inds, MATCH_SS_STA_LD_B_M_INDS, MASK_SS_STA_LD_B_M_INDS)
+DECLARE_INSN(ss_sta_ld_b_m_inds_mem1, MATCH_SS_STA_LD_B_M_INDS_MEM1, MASK_SS_STA_LD_B_M_INDS_MEM1)
+DECLARE_INSN(ss_sta_ld_b_m_inds_mem2, MATCH_SS_STA_LD_B_M_INDS_MEM2, MASK_SS_STA_LD_B_M_INDS_MEM2)
+DECLARE_INSN(ss_sta_ld_b_m_inds_mem3, MATCH_SS_STA_LD_B_M_INDS_MEM3, MASK_SS_STA_LD_B_M_INDS_MEM3)
+DECLARE_INSN(ss_sta_ld_b_m_mem1, MATCH_SS_STA_LD_B_M_MEM1, MASK_SS_STA_LD_B_M_MEM1)
+DECLARE_INSN(ss_sta_ld_b_m_mem2, MATCH_SS_STA_LD_B_M_MEM2, MASK_SS_STA_LD_B_M_MEM2)
+DECLARE_INSN(ss_sta_ld_b_m_mem3, MATCH_SS_STA_LD_B_M_MEM3, MASK_SS_STA_LD_B_M_MEM3)
+DECLARE_INSN(ss_sta_ld_b_mem1, MATCH_SS_STA_LD_B_MEM1, MASK_SS_STA_LD_B_MEM1)
+DECLARE_INSN(ss_sta_ld_b_mem2, MATCH_SS_STA_LD_B_MEM2, MASK_SS_STA_LD_B_MEM2)
+DECLARE_INSN(ss_sta_ld_b_mem3, MATCH_SS_STA_LD_B_MEM3, MASK_SS_STA_LD_B_MEM3)
+DECLARE_INSN(ss_sta_ld_b_v, MATCH_SS_STA_LD_B_V, MASK_SS_STA_LD_B_V)
+DECLARE_INSN(ss_sta_ld_b_v_1, MATCH_SS_STA_LD_B_V_1, MASK_SS_STA_LD_B_V_1)
+DECLARE_INSN(ss_sta_ld_b_v_1_m, MATCH_SS_STA_LD_B_V_1_M, MASK_SS_STA_LD_B_V_1_M)
+DECLARE_INSN(ss_sta_ld_b_v_1_m_mem1, MATCH_SS_STA_LD_B_V_1_M_MEM1, MASK_SS_STA_LD_B_V_1_M_MEM1)
+DECLARE_INSN(ss_sta_ld_b_v_1_m_mem2, MATCH_SS_STA_LD_B_V_1_M_MEM2, MASK_SS_STA_LD_B_V_1_M_MEM2)
+DECLARE_INSN(ss_sta_ld_b_v_1_m_mem3, MATCH_SS_STA_LD_B_V_1_M_MEM3, MASK_SS_STA_LD_B_V_1_M_MEM3)
+DECLARE_INSN(ss_sta_ld_b_v_1_mem1, MATCH_SS_STA_LD_B_V_1_MEM1, MASK_SS_STA_LD_B_V_1_MEM1)
+DECLARE_INSN(ss_sta_ld_b_v_1_mem2, MATCH_SS_STA_LD_B_V_1_MEM2, MASK_SS_STA_LD_B_V_1_MEM2)
+DECLARE_INSN(ss_sta_ld_b_v_1_mem3, MATCH_SS_STA_LD_B_V_1_MEM3, MASK_SS_STA_LD_B_V_1_MEM3)
+DECLARE_INSN(ss_sta_ld_b_v_2, MATCH_SS_STA_LD_B_V_2, MASK_SS_STA_LD_B_V_2)
+DECLARE_INSN(ss_sta_ld_b_v_2_m, MATCH_SS_STA_LD_B_V_2_M, MASK_SS_STA_LD_B_V_2_M)
+DECLARE_INSN(ss_sta_ld_b_v_2_m_mem1, MATCH_SS_STA_LD_B_V_2_M_MEM1, MASK_SS_STA_LD_B_V_2_M_MEM1)
+DECLARE_INSN(ss_sta_ld_b_v_2_m_mem2, MATCH_SS_STA_LD_B_V_2_M_MEM2, MASK_SS_STA_LD_B_V_2_M_MEM2)
+DECLARE_INSN(ss_sta_ld_b_v_2_m_mem3, MATCH_SS_STA_LD_B_V_2_M_MEM3, MASK_SS_STA_LD_B_V_2_M_MEM3)
+DECLARE_INSN(ss_sta_ld_b_v_2_mem1, MATCH_SS_STA_LD_B_V_2_MEM1, MASK_SS_STA_LD_B_V_2_MEM1)
+DECLARE_INSN(ss_sta_ld_b_v_2_mem2, MATCH_SS_STA_LD_B_V_2_MEM2, MASK_SS_STA_LD_B_V_2_MEM2)
+DECLARE_INSN(ss_sta_ld_b_v_2_mem3, MATCH_SS_STA_LD_B_V_2_MEM3, MASK_SS_STA_LD_B_V_2_MEM3)
+DECLARE_INSN(ss_sta_ld_b_v_3, MATCH_SS_STA_LD_B_V_3, MASK_SS_STA_LD_B_V_3)
+DECLARE_INSN(ss_sta_ld_b_v_3_m, MATCH_SS_STA_LD_B_V_3_M, MASK_SS_STA_LD_B_V_3_M)
+DECLARE_INSN(ss_sta_ld_b_v_3_m_mem1, MATCH_SS_STA_LD_B_V_3_M_MEM1, MASK_SS_STA_LD_B_V_3_M_MEM1)
+DECLARE_INSN(ss_sta_ld_b_v_3_m_mem2, MATCH_SS_STA_LD_B_V_3_M_MEM2, MASK_SS_STA_LD_B_V_3_M_MEM2)
+DECLARE_INSN(ss_sta_ld_b_v_3_m_mem3, MATCH_SS_STA_LD_B_V_3_M_MEM3, MASK_SS_STA_LD_B_V_3_M_MEM3)
+DECLARE_INSN(ss_sta_ld_b_v_3_mem1, MATCH_SS_STA_LD_B_V_3_MEM1, MASK_SS_STA_LD_B_V_3_MEM1)
+DECLARE_INSN(ss_sta_ld_b_v_3_mem2, MATCH_SS_STA_LD_B_V_3_MEM2, MASK_SS_STA_LD_B_V_3_MEM2)
+DECLARE_INSN(ss_sta_ld_b_v_3_mem3, MATCH_SS_STA_LD_B_V_3_MEM3, MASK_SS_STA_LD_B_V_3_MEM3)
+DECLARE_INSN(ss_sta_ld_b_v_4, MATCH_SS_STA_LD_B_V_4, MASK_SS_STA_LD_B_V_4)
+DECLARE_INSN(ss_sta_ld_b_v_4_m, MATCH_SS_STA_LD_B_V_4_M, MASK_SS_STA_LD_B_V_4_M)
+DECLARE_INSN(ss_sta_ld_b_v_4_m_mem1, MATCH_SS_STA_LD_B_V_4_M_MEM1, MASK_SS_STA_LD_B_V_4_M_MEM1)
+DECLARE_INSN(ss_sta_ld_b_v_4_m_mem2, MATCH_SS_STA_LD_B_V_4_M_MEM2, MASK_SS_STA_LD_B_V_4_M_MEM2)
+DECLARE_INSN(ss_sta_ld_b_v_4_m_mem3, MATCH_SS_STA_LD_B_V_4_M_MEM3, MASK_SS_STA_LD_B_V_4_M_MEM3)
+DECLARE_INSN(ss_sta_ld_b_v_4_mem1, MATCH_SS_STA_LD_B_V_4_MEM1, MASK_SS_STA_LD_B_V_4_MEM1)
+DECLARE_INSN(ss_sta_ld_b_v_4_mem2, MATCH_SS_STA_LD_B_V_4_MEM2, MASK_SS_STA_LD_B_V_4_MEM2)
+DECLARE_INSN(ss_sta_ld_b_v_4_mem3, MATCH_SS_STA_LD_B_V_4_MEM3, MASK_SS_STA_LD_B_V_4_MEM3)
+DECLARE_INSN(ss_sta_ld_b_v_5, MATCH_SS_STA_LD_B_V_5, MASK_SS_STA_LD_B_V_5)
+DECLARE_INSN(ss_sta_ld_b_v_5_m, MATCH_SS_STA_LD_B_V_5_M, MASK_SS_STA_LD_B_V_5_M)
+DECLARE_INSN(ss_sta_ld_b_v_5_m_mem1, MATCH_SS_STA_LD_B_V_5_M_MEM1, MASK_SS_STA_LD_B_V_5_M_MEM1)
+DECLARE_INSN(ss_sta_ld_b_v_5_m_mem2, MATCH_SS_STA_LD_B_V_5_M_MEM2, MASK_SS_STA_LD_B_V_5_M_MEM2)
+DECLARE_INSN(ss_sta_ld_b_v_5_m_mem3, MATCH_SS_STA_LD_B_V_5_M_MEM3, MASK_SS_STA_LD_B_V_5_M_MEM3)
+DECLARE_INSN(ss_sta_ld_b_v_5_mem1, MATCH_SS_STA_LD_B_V_5_MEM1, MASK_SS_STA_LD_B_V_5_MEM1)
+DECLARE_INSN(ss_sta_ld_b_v_5_mem2, MATCH_SS_STA_LD_B_V_5_MEM2, MASK_SS_STA_LD_B_V_5_MEM2)
+DECLARE_INSN(ss_sta_ld_b_v_5_mem3, MATCH_SS_STA_LD_B_V_5_MEM3, MASK_SS_STA_LD_B_V_5_MEM3)
+DECLARE_INSN(ss_sta_ld_b_v_6, MATCH_SS_STA_LD_B_V_6, MASK_SS_STA_LD_B_V_6)
+DECLARE_INSN(ss_sta_ld_b_v_6_m, MATCH_SS_STA_LD_B_V_6_M, MASK_SS_STA_LD_B_V_6_M)
+DECLARE_INSN(ss_sta_ld_b_v_6_m_mem1, MATCH_SS_STA_LD_B_V_6_M_MEM1, MASK_SS_STA_LD_B_V_6_M_MEM1)
+DECLARE_INSN(ss_sta_ld_b_v_6_m_mem2, MATCH_SS_STA_LD_B_V_6_M_MEM2, MASK_SS_STA_LD_B_V_6_M_MEM2)
+DECLARE_INSN(ss_sta_ld_b_v_6_m_mem3, MATCH_SS_STA_LD_B_V_6_M_MEM3, MASK_SS_STA_LD_B_V_6_M_MEM3)
+DECLARE_INSN(ss_sta_ld_b_v_6_mem1, MATCH_SS_STA_LD_B_V_6_MEM1, MASK_SS_STA_LD_B_V_6_MEM1)
+DECLARE_INSN(ss_sta_ld_b_v_6_mem2, MATCH_SS_STA_LD_B_V_6_MEM2, MASK_SS_STA_LD_B_V_6_MEM2)
+DECLARE_INSN(ss_sta_ld_b_v_6_mem3, MATCH_SS_STA_LD_B_V_6_MEM3, MASK_SS_STA_LD_B_V_6_MEM3)
+DECLARE_INSN(ss_sta_ld_b_v_7, MATCH_SS_STA_LD_B_V_7, MASK_SS_STA_LD_B_V_7)
+DECLARE_INSN(ss_sta_ld_b_v_7_m, MATCH_SS_STA_LD_B_V_7_M, MASK_SS_STA_LD_B_V_7_M)
+DECLARE_INSN(ss_sta_ld_b_v_7_m_mem1, MATCH_SS_STA_LD_B_V_7_M_MEM1, MASK_SS_STA_LD_B_V_7_M_MEM1)
+DECLARE_INSN(ss_sta_ld_b_v_7_m_mem2, MATCH_SS_STA_LD_B_V_7_M_MEM2, MASK_SS_STA_LD_B_V_7_M_MEM2)
+DECLARE_INSN(ss_sta_ld_b_v_7_m_mem3, MATCH_SS_STA_LD_B_V_7_M_MEM3, MASK_SS_STA_LD_B_V_7_M_MEM3)
+DECLARE_INSN(ss_sta_ld_b_v_7_mem1, MATCH_SS_STA_LD_B_V_7_MEM1, MASK_SS_STA_LD_B_V_7_MEM1)
+DECLARE_INSN(ss_sta_ld_b_v_7_mem2, MATCH_SS_STA_LD_B_V_7_MEM2, MASK_SS_STA_LD_B_V_7_MEM2)
+DECLARE_INSN(ss_sta_ld_b_v_7_mem3, MATCH_SS_STA_LD_B_V_7_MEM3, MASK_SS_STA_LD_B_V_7_MEM3)
+DECLARE_INSN(ss_sta_ld_b_v_m, MATCH_SS_STA_LD_B_V_M, MASK_SS_STA_LD_B_V_M)
+DECLARE_INSN(ss_sta_ld_b_v_m_mem1, MATCH_SS_STA_LD_B_V_M_MEM1, MASK_SS_STA_LD_B_V_M_MEM1)
+DECLARE_INSN(ss_sta_ld_b_v_m_mem2, MATCH_SS_STA_LD_B_V_M_MEM2, MASK_SS_STA_LD_B_V_M_MEM2)
+DECLARE_INSN(ss_sta_ld_b_v_m_mem3, MATCH_SS_STA_LD_B_V_M_MEM3, MASK_SS_STA_LD_B_V_M_MEM3)
+DECLARE_INSN(ss_sta_ld_b_v_mem1, MATCH_SS_STA_LD_B_V_MEM1, MASK_SS_STA_LD_B_V_MEM1)
+DECLARE_INSN(ss_sta_ld_b_v_mem2, MATCH_SS_STA_LD_B_V_MEM2, MASK_SS_STA_LD_B_V_MEM2)
+DECLARE_INSN(ss_sta_ld_b_v_mem3, MATCH_SS_STA_LD_B_V_MEM3, MASK_SS_STA_LD_B_V_MEM3)
+DECLARE_INSN(ss_sta_ld_d, MATCH_SS_STA_LD_D, MASK_SS_STA_LD_D)
+DECLARE_INSN(ss_sta_ld_d_inds, MATCH_SS_STA_LD_D_INDS, MASK_SS_STA_LD_D_INDS)
+DECLARE_INSN(ss_sta_ld_d_inds_mem1, MATCH_SS_STA_LD_D_INDS_MEM1, MASK_SS_STA_LD_D_INDS_MEM1)
+DECLARE_INSN(ss_sta_ld_d_inds_mem2, MATCH_SS_STA_LD_D_INDS_MEM2, MASK_SS_STA_LD_D_INDS_MEM2)
+DECLARE_INSN(ss_sta_ld_d_inds_mem3, MATCH_SS_STA_LD_D_INDS_MEM3, MASK_SS_STA_LD_D_INDS_MEM3)
+DECLARE_INSN(ss_sta_ld_d_m, MATCH_SS_STA_LD_D_M, MASK_SS_STA_LD_D_M)
+DECLARE_INSN(ss_sta_ld_d_m_inds, MATCH_SS_STA_LD_D_M_INDS, MASK_SS_STA_LD_D_M_INDS)
+DECLARE_INSN(ss_sta_ld_d_m_inds_mem1, MATCH_SS_STA_LD_D_M_INDS_MEM1, MASK_SS_STA_LD_D_M_INDS_MEM1)
+DECLARE_INSN(ss_sta_ld_d_m_inds_mem2, MATCH_SS_STA_LD_D_M_INDS_MEM2, MASK_SS_STA_LD_D_M_INDS_MEM2)
+DECLARE_INSN(ss_sta_ld_d_m_inds_mem3, MATCH_SS_STA_LD_D_M_INDS_MEM3, MASK_SS_STA_LD_D_M_INDS_MEM3)
+DECLARE_INSN(ss_sta_ld_d_m_mem1, MATCH_SS_STA_LD_D_M_MEM1, MASK_SS_STA_LD_D_M_MEM1)
+DECLARE_INSN(ss_sta_ld_d_m_mem2, MATCH_SS_STA_LD_D_M_MEM2, MASK_SS_STA_LD_D_M_MEM2)
+DECLARE_INSN(ss_sta_ld_d_m_mem3, MATCH_SS_STA_LD_D_M_MEM3, MASK_SS_STA_LD_D_M_MEM3)
+DECLARE_INSN(ss_sta_ld_d_mem1, MATCH_SS_STA_LD_D_MEM1, MASK_SS_STA_LD_D_MEM1)
+DECLARE_INSN(ss_sta_ld_d_mem2, MATCH_SS_STA_LD_D_MEM2, MASK_SS_STA_LD_D_MEM2)
+DECLARE_INSN(ss_sta_ld_d_mem3, MATCH_SS_STA_LD_D_MEM3, MASK_SS_STA_LD_D_MEM3)
+DECLARE_INSN(ss_sta_ld_d_v, MATCH_SS_STA_LD_D_V, MASK_SS_STA_LD_D_V)
+DECLARE_INSN(ss_sta_ld_d_v_1, MATCH_SS_STA_LD_D_V_1, MASK_SS_STA_LD_D_V_1)
+DECLARE_INSN(ss_sta_ld_d_v_1_m, MATCH_SS_STA_LD_D_V_1_M, MASK_SS_STA_LD_D_V_1_M)
+DECLARE_INSN(ss_sta_ld_d_v_1_m_mem1, MATCH_SS_STA_LD_D_V_1_M_MEM1, MASK_SS_STA_LD_D_V_1_M_MEM1)
+DECLARE_INSN(ss_sta_ld_d_v_1_m_mem2, MATCH_SS_STA_LD_D_V_1_M_MEM2, MASK_SS_STA_LD_D_V_1_M_MEM2)
+DECLARE_INSN(ss_sta_ld_d_v_1_m_mem3, MATCH_SS_STA_LD_D_V_1_M_MEM3, MASK_SS_STA_LD_D_V_1_M_MEM3)
+DECLARE_INSN(ss_sta_ld_d_v_1_mem1, MATCH_SS_STA_LD_D_V_1_MEM1, MASK_SS_STA_LD_D_V_1_MEM1)
+DECLARE_INSN(ss_sta_ld_d_v_1_mem2, MATCH_SS_STA_LD_D_V_1_MEM2, MASK_SS_STA_LD_D_V_1_MEM2)
+DECLARE_INSN(ss_sta_ld_d_v_1_mem3, MATCH_SS_STA_LD_D_V_1_MEM3, MASK_SS_STA_LD_D_V_1_MEM3)
+DECLARE_INSN(ss_sta_ld_d_v_2, MATCH_SS_STA_LD_D_V_2, MASK_SS_STA_LD_D_V_2)
+DECLARE_INSN(ss_sta_ld_d_v_2_m, MATCH_SS_STA_LD_D_V_2_M, MASK_SS_STA_LD_D_V_2_M)
+DECLARE_INSN(ss_sta_ld_d_v_2_m_mem1, MATCH_SS_STA_LD_D_V_2_M_MEM1, MASK_SS_STA_LD_D_V_2_M_MEM1)
+DECLARE_INSN(ss_sta_ld_d_v_2_m_mem2, MATCH_SS_STA_LD_D_V_2_M_MEM2, MASK_SS_STA_LD_D_V_2_M_MEM2)
+DECLARE_INSN(ss_sta_ld_d_v_2_m_mem3, MATCH_SS_STA_LD_D_V_2_M_MEM3, MASK_SS_STA_LD_D_V_2_M_MEM3)
+DECLARE_INSN(ss_sta_ld_d_v_2_mem1, MATCH_SS_STA_LD_D_V_2_MEM1, MASK_SS_STA_LD_D_V_2_MEM1)
+DECLARE_INSN(ss_sta_ld_d_v_2_mem2, MATCH_SS_STA_LD_D_V_2_MEM2, MASK_SS_STA_LD_D_V_2_MEM2)
+DECLARE_INSN(ss_sta_ld_d_v_2_mem3, MATCH_SS_STA_LD_D_V_2_MEM3, MASK_SS_STA_LD_D_V_2_MEM3)
+DECLARE_INSN(ss_sta_ld_d_v_3, MATCH_SS_STA_LD_D_V_3, MASK_SS_STA_LD_D_V_3)
+DECLARE_INSN(ss_sta_ld_d_v_3_m, MATCH_SS_STA_LD_D_V_3_M, MASK_SS_STA_LD_D_V_3_M)
+DECLARE_INSN(ss_sta_ld_d_v_3_m_mem1, MATCH_SS_STA_LD_D_V_3_M_MEM1, MASK_SS_STA_LD_D_V_3_M_MEM1)
+DECLARE_INSN(ss_sta_ld_d_v_3_m_mem2, MATCH_SS_STA_LD_D_V_3_M_MEM2, MASK_SS_STA_LD_D_V_3_M_MEM2)
+DECLARE_INSN(ss_sta_ld_d_v_3_m_mem3, MATCH_SS_STA_LD_D_V_3_M_MEM3, MASK_SS_STA_LD_D_V_3_M_MEM3)
+DECLARE_INSN(ss_sta_ld_d_v_3_mem1, MATCH_SS_STA_LD_D_V_3_MEM1, MASK_SS_STA_LD_D_V_3_MEM1)
+DECLARE_INSN(ss_sta_ld_d_v_3_mem2, MATCH_SS_STA_LD_D_V_3_MEM2, MASK_SS_STA_LD_D_V_3_MEM2)
+DECLARE_INSN(ss_sta_ld_d_v_3_mem3, MATCH_SS_STA_LD_D_V_3_MEM3, MASK_SS_STA_LD_D_V_3_MEM3)
+DECLARE_INSN(ss_sta_ld_d_v_4, MATCH_SS_STA_LD_D_V_4, MASK_SS_STA_LD_D_V_4)
+DECLARE_INSN(ss_sta_ld_d_v_4_m, MATCH_SS_STA_LD_D_V_4_M, MASK_SS_STA_LD_D_V_4_M)
+DECLARE_INSN(ss_sta_ld_d_v_4_m_mem1, MATCH_SS_STA_LD_D_V_4_M_MEM1, MASK_SS_STA_LD_D_V_4_M_MEM1)
+DECLARE_INSN(ss_sta_ld_d_v_4_m_mem2, MATCH_SS_STA_LD_D_V_4_M_MEM2, MASK_SS_STA_LD_D_V_4_M_MEM2)
+DECLARE_INSN(ss_sta_ld_d_v_4_m_mem3, MATCH_SS_STA_LD_D_V_4_M_MEM3, MASK_SS_STA_LD_D_V_4_M_MEM3)
+DECLARE_INSN(ss_sta_ld_d_v_4_mem1, MATCH_SS_STA_LD_D_V_4_MEM1, MASK_SS_STA_LD_D_V_4_MEM1)
+DECLARE_INSN(ss_sta_ld_d_v_4_mem2, MATCH_SS_STA_LD_D_V_4_MEM2, MASK_SS_STA_LD_D_V_4_MEM2)
+DECLARE_INSN(ss_sta_ld_d_v_4_mem3, MATCH_SS_STA_LD_D_V_4_MEM3, MASK_SS_STA_LD_D_V_4_MEM3)
+DECLARE_INSN(ss_sta_ld_d_v_5, MATCH_SS_STA_LD_D_V_5, MASK_SS_STA_LD_D_V_5)
+DECLARE_INSN(ss_sta_ld_d_v_5_m, MATCH_SS_STA_LD_D_V_5_M, MASK_SS_STA_LD_D_V_5_M)
+DECLARE_INSN(ss_sta_ld_d_v_5_m_mem1, MATCH_SS_STA_LD_D_V_5_M_MEM1, MASK_SS_STA_LD_D_V_5_M_MEM1)
+DECLARE_INSN(ss_sta_ld_d_v_5_m_mem2, MATCH_SS_STA_LD_D_V_5_M_MEM2, MASK_SS_STA_LD_D_V_5_M_MEM2)
+DECLARE_INSN(ss_sta_ld_d_v_5_m_mem3, MATCH_SS_STA_LD_D_V_5_M_MEM3, MASK_SS_STA_LD_D_V_5_M_MEM3)
+DECLARE_INSN(ss_sta_ld_d_v_5_mem1, MATCH_SS_STA_LD_D_V_5_MEM1, MASK_SS_STA_LD_D_V_5_MEM1)
+DECLARE_INSN(ss_sta_ld_d_v_5_mem2, MATCH_SS_STA_LD_D_V_5_MEM2, MASK_SS_STA_LD_D_V_5_MEM2)
+DECLARE_INSN(ss_sta_ld_d_v_5_mem3, MATCH_SS_STA_LD_D_V_5_MEM3, MASK_SS_STA_LD_D_V_5_MEM3)
+DECLARE_INSN(ss_sta_ld_d_v_6, MATCH_SS_STA_LD_D_V_6, MASK_SS_STA_LD_D_V_6)
+DECLARE_INSN(ss_sta_ld_d_v_6_m, MATCH_SS_STA_LD_D_V_6_M, MASK_SS_STA_LD_D_V_6_M)
+DECLARE_INSN(ss_sta_ld_d_v_6_m_mem1, MATCH_SS_STA_LD_D_V_6_M_MEM1, MASK_SS_STA_LD_D_V_6_M_MEM1)
+DECLARE_INSN(ss_sta_ld_d_v_6_m_mem2, MATCH_SS_STA_LD_D_V_6_M_MEM2, MASK_SS_STA_LD_D_V_6_M_MEM2)
+DECLARE_INSN(ss_sta_ld_d_v_6_m_mem3, MATCH_SS_STA_LD_D_V_6_M_MEM3, MASK_SS_STA_LD_D_V_6_M_MEM3)
+DECLARE_INSN(ss_sta_ld_d_v_6_mem1, MATCH_SS_STA_LD_D_V_6_MEM1, MASK_SS_STA_LD_D_V_6_MEM1)
+DECLARE_INSN(ss_sta_ld_d_v_6_mem2, MATCH_SS_STA_LD_D_V_6_MEM2, MASK_SS_STA_LD_D_V_6_MEM2)
+DECLARE_INSN(ss_sta_ld_d_v_6_mem3, MATCH_SS_STA_LD_D_V_6_MEM3, MASK_SS_STA_LD_D_V_6_MEM3)
+DECLARE_INSN(ss_sta_ld_d_v_7, MATCH_SS_STA_LD_D_V_7, MASK_SS_STA_LD_D_V_7)
+DECLARE_INSN(ss_sta_ld_d_v_7_m, MATCH_SS_STA_LD_D_V_7_M, MASK_SS_STA_LD_D_V_7_M)
+DECLARE_INSN(ss_sta_ld_d_v_7_m_mem1, MATCH_SS_STA_LD_D_V_7_M_MEM1, MASK_SS_STA_LD_D_V_7_M_MEM1)
+DECLARE_INSN(ss_sta_ld_d_v_7_m_mem2, MATCH_SS_STA_LD_D_V_7_M_MEM2, MASK_SS_STA_LD_D_V_7_M_MEM2)
+DECLARE_INSN(ss_sta_ld_d_v_7_m_mem3, MATCH_SS_STA_LD_D_V_7_M_MEM3, MASK_SS_STA_LD_D_V_7_M_MEM3)
+DECLARE_INSN(ss_sta_ld_d_v_7_mem1, MATCH_SS_STA_LD_D_V_7_MEM1, MASK_SS_STA_LD_D_V_7_MEM1)
+DECLARE_INSN(ss_sta_ld_d_v_7_mem2, MATCH_SS_STA_LD_D_V_7_MEM2, MASK_SS_STA_LD_D_V_7_MEM2)
+DECLARE_INSN(ss_sta_ld_d_v_7_mem3, MATCH_SS_STA_LD_D_V_7_MEM3, MASK_SS_STA_LD_D_V_7_MEM3)
+DECLARE_INSN(ss_sta_ld_d_v_m, MATCH_SS_STA_LD_D_V_M, MASK_SS_STA_LD_D_V_M)
+DECLARE_INSN(ss_sta_ld_d_v_m_mem1, MATCH_SS_STA_LD_D_V_M_MEM1, MASK_SS_STA_LD_D_V_M_MEM1)
+DECLARE_INSN(ss_sta_ld_d_v_m_mem2, MATCH_SS_STA_LD_D_V_M_MEM2, MASK_SS_STA_LD_D_V_M_MEM2)
+DECLARE_INSN(ss_sta_ld_d_v_m_mem3, MATCH_SS_STA_LD_D_V_M_MEM3, MASK_SS_STA_LD_D_V_M_MEM3)
+DECLARE_INSN(ss_sta_ld_d_v_mem1, MATCH_SS_STA_LD_D_V_MEM1, MASK_SS_STA_LD_D_V_MEM1)
+DECLARE_INSN(ss_sta_ld_d_v_mem2, MATCH_SS_STA_LD_D_V_MEM2, MASK_SS_STA_LD_D_V_MEM2)
+DECLARE_INSN(ss_sta_ld_d_v_mem3, MATCH_SS_STA_LD_D_V_MEM3, MASK_SS_STA_LD_D_V_MEM3)
+DECLARE_INSN(ss_sta_ld_h, MATCH_SS_STA_LD_H, MASK_SS_STA_LD_H)
+DECLARE_INSN(ss_sta_ld_h_inds, MATCH_SS_STA_LD_H_INDS, MASK_SS_STA_LD_H_INDS)
+DECLARE_INSN(ss_sta_ld_h_inds_mem1, MATCH_SS_STA_LD_H_INDS_MEM1, MASK_SS_STA_LD_H_INDS_MEM1)
+DECLARE_INSN(ss_sta_ld_h_inds_mem2, MATCH_SS_STA_LD_H_INDS_MEM2, MASK_SS_STA_LD_H_INDS_MEM2)
+DECLARE_INSN(ss_sta_ld_h_inds_mem3, MATCH_SS_STA_LD_H_INDS_MEM3, MASK_SS_STA_LD_H_INDS_MEM3)
+DECLARE_INSN(ss_sta_ld_h_m, MATCH_SS_STA_LD_H_M, MASK_SS_STA_LD_H_M)
+DECLARE_INSN(ss_sta_ld_h_m_inds, MATCH_SS_STA_LD_H_M_INDS, MASK_SS_STA_LD_H_M_INDS)
+DECLARE_INSN(ss_sta_ld_h_m_inds_mem1, MATCH_SS_STA_LD_H_M_INDS_MEM1, MASK_SS_STA_LD_H_M_INDS_MEM1)
+DECLARE_INSN(ss_sta_ld_h_m_inds_mem2, MATCH_SS_STA_LD_H_M_INDS_MEM2, MASK_SS_STA_LD_H_M_INDS_MEM2)
+DECLARE_INSN(ss_sta_ld_h_m_inds_mem3, MATCH_SS_STA_LD_H_M_INDS_MEM3, MASK_SS_STA_LD_H_M_INDS_MEM3)
+DECLARE_INSN(ss_sta_ld_h_m_mem1, MATCH_SS_STA_LD_H_M_MEM1, MASK_SS_STA_LD_H_M_MEM1)
+DECLARE_INSN(ss_sta_ld_h_m_mem2, MATCH_SS_STA_LD_H_M_MEM2, MASK_SS_STA_LD_H_M_MEM2)
+DECLARE_INSN(ss_sta_ld_h_m_mem3, MATCH_SS_STA_LD_H_M_MEM3, MASK_SS_STA_LD_H_M_MEM3)
+DECLARE_INSN(ss_sta_ld_h_mem1, MATCH_SS_STA_LD_H_MEM1, MASK_SS_STA_LD_H_MEM1)
+DECLARE_INSN(ss_sta_ld_h_mem2, MATCH_SS_STA_LD_H_MEM2, MASK_SS_STA_LD_H_MEM2)
+DECLARE_INSN(ss_sta_ld_h_mem3, MATCH_SS_STA_LD_H_MEM3, MASK_SS_STA_LD_H_MEM3)
+DECLARE_INSN(ss_sta_ld_h_v, MATCH_SS_STA_LD_H_V, MASK_SS_STA_LD_H_V)
+DECLARE_INSN(ss_sta_ld_h_v_1, MATCH_SS_STA_LD_H_V_1, MASK_SS_STA_LD_H_V_1)
+DECLARE_INSN(ss_sta_ld_h_v_1_m, MATCH_SS_STA_LD_H_V_1_M, MASK_SS_STA_LD_H_V_1_M)
+DECLARE_INSN(ss_sta_ld_h_v_1_m_mem1, MATCH_SS_STA_LD_H_V_1_M_MEM1, MASK_SS_STA_LD_H_V_1_M_MEM1)
+DECLARE_INSN(ss_sta_ld_h_v_1_m_mem2, MATCH_SS_STA_LD_H_V_1_M_MEM2, MASK_SS_STA_LD_H_V_1_M_MEM2)
+DECLARE_INSN(ss_sta_ld_h_v_1_m_mem3, MATCH_SS_STA_LD_H_V_1_M_MEM3, MASK_SS_STA_LD_H_V_1_M_MEM3)
+DECLARE_INSN(ss_sta_ld_h_v_1_mem1, MATCH_SS_STA_LD_H_V_1_MEM1, MASK_SS_STA_LD_H_V_1_MEM1)
+DECLARE_INSN(ss_sta_ld_h_v_1_mem2, MATCH_SS_STA_LD_H_V_1_MEM2, MASK_SS_STA_LD_H_V_1_MEM2)
+DECLARE_INSN(ss_sta_ld_h_v_1_mem3, MATCH_SS_STA_LD_H_V_1_MEM3, MASK_SS_STA_LD_H_V_1_MEM3)
+DECLARE_INSN(ss_sta_ld_h_v_2, MATCH_SS_STA_LD_H_V_2, MASK_SS_STA_LD_H_V_2)
+DECLARE_INSN(ss_sta_ld_h_v_2_m, MATCH_SS_STA_LD_H_V_2_M, MASK_SS_STA_LD_H_V_2_M)
+DECLARE_INSN(ss_sta_ld_h_v_2_m_mem1, MATCH_SS_STA_LD_H_V_2_M_MEM1, MASK_SS_STA_LD_H_V_2_M_MEM1)
+DECLARE_INSN(ss_sta_ld_h_v_2_m_mem2, MATCH_SS_STA_LD_H_V_2_M_MEM2, MASK_SS_STA_LD_H_V_2_M_MEM2)
+DECLARE_INSN(ss_sta_ld_h_v_2_m_mem3, MATCH_SS_STA_LD_H_V_2_M_MEM3, MASK_SS_STA_LD_H_V_2_M_MEM3)
+DECLARE_INSN(ss_sta_ld_h_v_2_mem1, MATCH_SS_STA_LD_H_V_2_MEM1, MASK_SS_STA_LD_H_V_2_MEM1)
+DECLARE_INSN(ss_sta_ld_h_v_2_mem2, MATCH_SS_STA_LD_H_V_2_MEM2, MASK_SS_STA_LD_H_V_2_MEM2)
+DECLARE_INSN(ss_sta_ld_h_v_2_mem3, MATCH_SS_STA_LD_H_V_2_MEM3, MASK_SS_STA_LD_H_V_2_MEM3)
+DECLARE_INSN(ss_sta_ld_h_v_3, MATCH_SS_STA_LD_H_V_3, MASK_SS_STA_LD_H_V_3)
+DECLARE_INSN(ss_sta_ld_h_v_3_m, MATCH_SS_STA_LD_H_V_3_M, MASK_SS_STA_LD_H_V_3_M)
+DECLARE_INSN(ss_sta_ld_h_v_3_m_mem1, MATCH_SS_STA_LD_H_V_3_M_MEM1, MASK_SS_STA_LD_H_V_3_M_MEM1)
+DECLARE_INSN(ss_sta_ld_h_v_3_m_mem2, MATCH_SS_STA_LD_H_V_3_M_MEM2, MASK_SS_STA_LD_H_V_3_M_MEM2)
+DECLARE_INSN(ss_sta_ld_h_v_3_m_mem3, MATCH_SS_STA_LD_H_V_3_M_MEM3, MASK_SS_STA_LD_H_V_3_M_MEM3)
+DECLARE_INSN(ss_sta_ld_h_v_3_mem1, MATCH_SS_STA_LD_H_V_3_MEM1, MASK_SS_STA_LD_H_V_3_MEM1)
+DECLARE_INSN(ss_sta_ld_h_v_3_mem2, MATCH_SS_STA_LD_H_V_3_MEM2, MASK_SS_STA_LD_H_V_3_MEM2)
+DECLARE_INSN(ss_sta_ld_h_v_3_mem3, MATCH_SS_STA_LD_H_V_3_MEM3, MASK_SS_STA_LD_H_V_3_MEM3)
+DECLARE_INSN(ss_sta_ld_h_v_4, MATCH_SS_STA_LD_H_V_4, MASK_SS_STA_LD_H_V_4)
+DECLARE_INSN(ss_sta_ld_h_v_4_m, MATCH_SS_STA_LD_H_V_4_M, MASK_SS_STA_LD_H_V_4_M)
+DECLARE_INSN(ss_sta_ld_h_v_4_m_mem1, MATCH_SS_STA_LD_H_V_4_M_MEM1, MASK_SS_STA_LD_H_V_4_M_MEM1)
+DECLARE_INSN(ss_sta_ld_h_v_4_m_mem2, MATCH_SS_STA_LD_H_V_4_M_MEM2, MASK_SS_STA_LD_H_V_4_M_MEM2)
+DECLARE_INSN(ss_sta_ld_h_v_4_m_mem3, MATCH_SS_STA_LD_H_V_4_M_MEM3, MASK_SS_STA_LD_H_V_4_M_MEM3)
+DECLARE_INSN(ss_sta_ld_h_v_4_mem1, MATCH_SS_STA_LD_H_V_4_MEM1, MASK_SS_STA_LD_H_V_4_MEM1)
+DECLARE_INSN(ss_sta_ld_h_v_4_mem2, MATCH_SS_STA_LD_H_V_4_MEM2, MASK_SS_STA_LD_H_V_4_MEM2)
+DECLARE_INSN(ss_sta_ld_h_v_4_mem3, MATCH_SS_STA_LD_H_V_4_MEM3, MASK_SS_STA_LD_H_V_4_MEM3)
+DECLARE_INSN(ss_sta_ld_h_v_5, MATCH_SS_STA_LD_H_V_5, MASK_SS_STA_LD_H_V_5)
+DECLARE_INSN(ss_sta_ld_h_v_5_m, MATCH_SS_STA_LD_H_V_5_M, MASK_SS_STA_LD_H_V_5_M)
+DECLARE_INSN(ss_sta_ld_h_v_5_m_mem1, MATCH_SS_STA_LD_H_V_5_M_MEM1, MASK_SS_STA_LD_H_V_5_M_MEM1)
+DECLARE_INSN(ss_sta_ld_h_v_5_m_mem2, MATCH_SS_STA_LD_H_V_5_M_MEM2, MASK_SS_STA_LD_H_V_5_M_MEM2)
+DECLARE_INSN(ss_sta_ld_h_v_5_m_mem3, MATCH_SS_STA_LD_H_V_5_M_MEM3, MASK_SS_STA_LD_H_V_5_M_MEM3)
+DECLARE_INSN(ss_sta_ld_h_v_5_mem1, MATCH_SS_STA_LD_H_V_5_MEM1, MASK_SS_STA_LD_H_V_5_MEM1)
+DECLARE_INSN(ss_sta_ld_h_v_5_mem2, MATCH_SS_STA_LD_H_V_5_MEM2, MASK_SS_STA_LD_H_V_5_MEM2)
+DECLARE_INSN(ss_sta_ld_h_v_5_mem3, MATCH_SS_STA_LD_H_V_5_MEM3, MASK_SS_STA_LD_H_V_5_MEM3)
+DECLARE_INSN(ss_sta_ld_h_v_6, MATCH_SS_STA_LD_H_V_6, MASK_SS_STA_LD_H_V_6)
+DECLARE_INSN(ss_sta_ld_h_v_6_m, MATCH_SS_STA_LD_H_V_6_M, MASK_SS_STA_LD_H_V_6_M)
+DECLARE_INSN(ss_sta_ld_h_v_6_m_mem1, MATCH_SS_STA_LD_H_V_6_M_MEM1, MASK_SS_STA_LD_H_V_6_M_MEM1)
+DECLARE_INSN(ss_sta_ld_h_v_6_m_mem2, MATCH_SS_STA_LD_H_V_6_M_MEM2, MASK_SS_STA_LD_H_V_6_M_MEM2)
+DECLARE_INSN(ss_sta_ld_h_v_6_m_mem3, MATCH_SS_STA_LD_H_V_6_M_MEM3, MASK_SS_STA_LD_H_V_6_M_MEM3)
+DECLARE_INSN(ss_sta_ld_h_v_6_mem1, MATCH_SS_STA_LD_H_V_6_MEM1, MASK_SS_STA_LD_H_V_6_MEM1)
+DECLARE_INSN(ss_sta_ld_h_v_6_mem2, MATCH_SS_STA_LD_H_V_6_MEM2, MASK_SS_STA_LD_H_V_6_MEM2)
+DECLARE_INSN(ss_sta_ld_h_v_6_mem3, MATCH_SS_STA_LD_H_V_6_MEM3, MASK_SS_STA_LD_H_V_6_MEM3)
+DECLARE_INSN(ss_sta_ld_h_v_7, MATCH_SS_STA_LD_H_V_7, MASK_SS_STA_LD_H_V_7)
+DECLARE_INSN(ss_sta_ld_h_v_7_m, MATCH_SS_STA_LD_H_V_7_M, MASK_SS_STA_LD_H_V_7_M)
+DECLARE_INSN(ss_sta_ld_h_v_7_m_mem1, MATCH_SS_STA_LD_H_V_7_M_MEM1, MASK_SS_STA_LD_H_V_7_M_MEM1)
+DECLARE_INSN(ss_sta_ld_h_v_7_m_mem2, MATCH_SS_STA_LD_H_V_7_M_MEM2, MASK_SS_STA_LD_H_V_7_M_MEM2)
+DECLARE_INSN(ss_sta_ld_h_v_7_m_mem3, MATCH_SS_STA_LD_H_V_7_M_MEM3, MASK_SS_STA_LD_H_V_7_M_MEM3)
+DECLARE_INSN(ss_sta_ld_h_v_7_mem1, MATCH_SS_STA_LD_H_V_7_MEM1, MASK_SS_STA_LD_H_V_7_MEM1)
+DECLARE_INSN(ss_sta_ld_h_v_7_mem2, MATCH_SS_STA_LD_H_V_7_MEM2, MASK_SS_STA_LD_H_V_7_MEM2)
+DECLARE_INSN(ss_sta_ld_h_v_7_mem3, MATCH_SS_STA_LD_H_V_7_MEM3, MASK_SS_STA_LD_H_V_7_MEM3)
+DECLARE_INSN(ss_sta_ld_h_v_m, MATCH_SS_STA_LD_H_V_M, MASK_SS_STA_LD_H_V_M)
+DECLARE_INSN(ss_sta_ld_h_v_m_mem1, MATCH_SS_STA_LD_H_V_M_MEM1, MASK_SS_STA_LD_H_V_M_MEM1)
+DECLARE_INSN(ss_sta_ld_h_v_m_mem2, MATCH_SS_STA_LD_H_V_M_MEM2, MASK_SS_STA_LD_H_V_M_MEM2)
+DECLARE_INSN(ss_sta_ld_h_v_m_mem3, MATCH_SS_STA_LD_H_V_M_MEM3, MASK_SS_STA_LD_H_V_M_MEM3)
+DECLARE_INSN(ss_sta_ld_h_v_mem1, MATCH_SS_STA_LD_H_V_MEM1, MASK_SS_STA_LD_H_V_MEM1)
+DECLARE_INSN(ss_sta_ld_h_v_mem2, MATCH_SS_STA_LD_H_V_MEM2, MASK_SS_STA_LD_H_V_MEM2)
+DECLARE_INSN(ss_sta_ld_h_v_mem3, MATCH_SS_STA_LD_H_V_MEM3, MASK_SS_STA_LD_H_V_MEM3)
+DECLARE_INSN(ss_sta_ld_w, MATCH_SS_STA_LD_W, MASK_SS_STA_LD_W)
+DECLARE_INSN(ss_sta_ld_w_inds, MATCH_SS_STA_LD_W_INDS, MASK_SS_STA_LD_W_INDS)
+DECLARE_INSN(ss_sta_ld_w_inds_mem1, MATCH_SS_STA_LD_W_INDS_MEM1, MASK_SS_STA_LD_W_INDS_MEM1)
+DECLARE_INSN(ss_sta_ld_w_inds_mem2, MATCH_SS_STA_LD_W_INDS_MEM2, MASK_SS_STA_LD_W_INDS_MEM2)
+DECLARE_INSN(ss_sta_ld_w_inds_mem3, MATCH_SS_STA_LD_W_INDS_MEM3, MASK_SS_STA_LD_W_INDS_MEM3)
+DECLARE_INSN(ss_sta_ld_w_m, MATCH_SS_STA_LD_W_M, MASK_SS_STA_LD_W_M)
+DECLARE_INSN(ss_sta_ld_w_m_inds, MATCH_SS_STA_LD_W_M_INDS, MASK_SS_STA_LD_W_M_INDS)
+DECLARE_INSN(ss_sta_ld_w_m_inds_mem1, MATCH_SS_STA_LD_W_M_INDS_MEM1, MASK_SS_STA_LD_W_M_INDS_MEM1)
+DECLARE_INSN(ss_sta_ld_w_m_inds_mem2, MATCH_SS_STA_LD_W_M_INDS_MEM2, MASK_SS_STA_LD_W_M_INDS_MEM2)
+DECLARE_INSN(ss_sta_ld_w_m_inds_mem3, MATCH_SS_STA_LD_W_M_INDS_MEM3, MASK_SS_STA_LD_W_M_INDS_MEM3)
+DECLARE_INSN(ss_sta_ld_w_m_mem1, MATCH_SS_STA_LD_W_M_MEM1, MASK_SS_STA_LD_W_M_MEM1)
+DECLARE_INSN(ss_sta_ld_w_m_mem2, MATCH_SS_STA_LD_W_M_MEM2, MASK_SS_STA_LD_W_M_MEM2)
+DECLARE_INSN(ss_sta_ld_w_m_mem3, MATCH_SS_STA_LD_W_M_MEM3, MASK_SS_STA_LD_W_M_MEM3)
+DECLARE_INSN(ss_sta_ld_w_mem1, MATCH_SS_STA_LD_W_MEM1, MASK_SS_STA_LD_W_MEM1)
+DECLARE_INSN(ss_sta_ld_w_mem2, MATCH_SS_STA_LD_W_MEM2, MASK_SS_STA_LD_W_MEM2)
+DECLARE_INSN(ss_sta_ld_w_mem3, MATCH_SS_STA_LD_W_MEM3, MASK_SS_STA_LD_W_MEM3)
+DECLARE_INSN(ss_sta_ld_w_v, MATCH_SS_STA_LD_W_V, MASK_SS_STA_LD_W_V)
+DECLARE_INSN(ss_sta_ld_w_v_1, MATCH_SS_STA_LD_W_V_1, MASK_SS_STA_LD_W_V_1)
+DECLARE_INSN(ss_sta_ld_w_v_1_m, MATCH_SS_STA_LD_W_V_1_M, MASK_SS_STA_LD_W_V_1_M)
+DECLARE_INSN(ss_sta_ld_w_v_1_m_mem1, MATCH_SS_STA_LD_W_V_1_M_MEM1, MASK_SS_STA_LD_W_V_1_M_MEM1)
+DECLARE_INSN(ss_sta_ld_w_v_1_m_mem2, MATCH_SS_STA_LD_W_V_1_M_MEM2, MASK_SS_STA_LD_W_V_1_M_MEM2)
+DECLARE_INSN(ss_sta_ld_w_v_1_m_mem3, MATCH_SS_STA_LD_W_V_1_M_MEM3, MASK_SS_STA_LD_W_V_1_M_MEM3)
+DECLARE_INSN(ss_sta_ld_w_v_1_mem1, MATCH_SS_STA_LD_W_V_1_MEM1, MASK_SS_STA_LD_W_V_1_MEM1)
+DECLARE_INSN(ss_sta_ld_w_v_1_mem2, MATCH_SS_STA_LD_W_V_1_MEM2, MASK_SS_STA_LD_W_V_1_MEM2)
+DECLARE_INSN(ss_sta_ld_w_v_1_mem3, MATCH_SS_STA_LD_W_V_1_MEM3, MASK_SS_STA_LD_W_V_1_MEM3)
+DECLARE_INSN(ss_sta_ld_w_v_2, MATCH_SS_STA_LD_W_V_2, MASK_SS_STA_LD_W_V_2)
+DECLARE_INSN(ss_sta_ld_w_v_2_m, MATCH_SS_STA_LD_W_V_2_M, MASK_SS_STA_LD_W_V_2_M)
+DECLARE_INSN(ss_sta_ld_w_v_2_m_mem1, MATCH_SS_STA_LD_W_V_2_M_MEM1, MASK_SS_STA_LD_W_V_2_M_MEM1)
+DECLARE_INSN(ss_sta_ld_w_v_2_m_mem2, MATCH_SS_STA_LD_W_V_2_M_MEM2, MASK_SS_STA_LD_W_V_2_M_MEM2)
+DECLARE_INSN(ss_sta_ld_w_v_2_m_mem3, MATCH_SS_STA_LD_W_V_2_M_MEM3, MASK_SS_STA_LD_W_V_2_M_MEM3)
+DECLARE_INSN(ss_sta_ld_w_v_2_mem1, MATCH_SS_STA_LD_W_V_2_MEM1, MASK_SS_STA_LD_W_V_2_MEM1)
+DECLARE_INSN(ss_sta_ld_w_v_2_mem2, MATCH_SS_STA_LD_W_V_2_MEM2, MASK_SS_STA_LD_W_V_2_MEM2)
+DECLARE_INSN(ss_sta_ld_w_v_2_mem3, MATCH_SS_STA_LD_W_V_2_MEM3, MASK_SS_STA_LD_W_V_2_MEM3)
+DECLARE_INSN(ss_sta_ld_w_v_3, MATCH_SS_STA_LD_W_V_3, MASK_SS_STA_LD_W_V_3)
+DECLARE_INSN(ss_sta_ld_w_v_3_m, MATCH_SS_STA_LD_W_V_3_M, MASK_SS_STA_LD_W_V_3_M)
+DECLARE_INSN(ss_sta_ld_w_v_3_m_mem1, MATCH_SS_STA_LD_W_V_3_M_MEM1, MASK_SS_STA_LD_W_V_3_M_MEM1)
+DECLARE_INSN(ss_sta_ld_w_v_3_m_mem2, MATCH_SS_STA_LD_W_V_3_M_MEM2, MASK_SS_STA_LD_W_V_3_M_MEM2)
+DECLARE_INSN(ss_sta_ld_w_v_3_m_mem3, MATCH_SS_STA_LD_W_V_3_M_MEM3, MASK_SS_STA_LD_W_V_3_M_MEM3)
+DECLARE_INSN(ss_sta_ld_w_v_3_mem1, MATCH_SS_STA_LD_W_V_3_MEM1, MASK_SS_STA_LD_W_V_3_MEM1)
+DECLARE_INSN(ss_sta_ld_w_v_3_mem2, MATCH_SS_STA_LD_W_V_3_MEM2, MASK_SS_STA_LD_W_V_3_MEM2)
+DECLARE_INSN(ss_sta_ld_w_v_3_mem3, MATCH_SS_STA_LD_W_V_3_MEM3, MASK_SS_STA_LD_W_V_3_MEM3)
+DECLARE_INSN(ss_sta_ld_w_v_4, MATCH_SS_STA_LD_W_V_4, MASK_SS_STA_LD_W_V_4)
+DECLARE_INSN(ss_sta_ld_w_v_4_m, MATCH_SS_STA_LD_W_V_4_M, MASK_SS_STA_LD_W_V_4_M)
+DECLARE_INSN(ss_sta_ld_w_v_4_m_mem1, MATCH_SS_STA_LD_W_V_4_M_MEM1, MASK_SS_STA_LD_W_V_4_M_MEM1)
+DECLARE_INSN(ss_sta_ld_w_v_4_m_mem2, MATCH_SS_STA_LD_W_V_4_M_MEM2, MASK_SS_STA_LD_W_V_4_M_MEM2)
+DECLARE_INSN(ss_sta_ld_w_v_4_m_mem3, MATCH_SS_STA_LD_W_V_4_M_MEM3, MASK_SS_STA_LD_W_V_4_M_MEM3)
+DECLARE_INSN(ss_sta_ld_w_v_4_mem1, MATCH_SS_STA_LD_W_V_4_MEM1, MASK_SS_STA_LD_W_V_4_MEM1)
+DECLARE_INSN(ss_sta_ld_w_v_4_mem2, MATCH_SS_STA_LD_W_V_4_MEM2, MASK_SS_STA_LD_W_V_4_MEM2)
+DECLARE_INSN(ss_sta_ld_w_v_4_mem3, MATCH_SS_STA_LD_W_V_4_MEM3, MASK_SS_STA_LD_W_V_4_MEM3)
+DECLARE_INSN(ss_sta_ld_w_v_5, MATCH_SS_STA_LD_W_V_5, MASK_SS_STA_LD_W_V_5)
+DECLARE_INSN(ss_sta_ld_w_v_5_m, MATCH_SS_STA_LD_W_V_5_M, MASK_SS_STA_LD_W_V_5_M)
+DECLARE_INSN(ss_sta_ld_w_v_5_m_mem1, MATCH_SS_STA_LD_W_V_5_M_MEM1, MASK_SS_STA_LD_W_V_5_M_MEM1)
+DECLARE_INSN(ss_sta_ld_w_v_5_m_mem2, MATCH_SS_STA_LD_W_V_5_M_MEM2, MASK_SS_STA_LD_W_V_5_M_MEM2)
+DECLARE_INSN(ss_sta_ld_w_v_5_m_mem3, MATCH_SS_STA_LD_W_V_5_M_MEM3, MASK_SS_STA_LD_W_V_5_M_MEM3)
+DECLARE_INSN(ss_sta_ld_w_v_5_mem1, MATCH_SS_STA_LD_W_V_5_MEM1, MASK_SS_STA_LD_W_V_5_MEM1)
+DECLARE_INSN(ss_sta_ld_w_v_5_mem2, MATCH_SS_STA_LD_W_V_5_MEM2, MASK_SS_STA_LD_W_V_5_MEM2)
+DECLARE_INSN(ss_sta_ld_w_v_5_mem3, MATCH_SS_STA_LD_W_V_5_MEM3, MASK_SS_STA_LD_W_V_5_MEM3)
+DECLARE_INSN(ss_sta_ld_w_v_6, MATCH_SS_STA_LD_W_V_6, MASK_SS_STA_LD_W_V_6)
+DECLARE_INSN(ss_sta_ld_w_v_6_m, MATCH_SS_STA_LD_W_V_6_M, MASK_SS_STA_LD_W_V_6_M)
+DECLARE_INSN(ss_sta_ld_w_v_6_m_mem1, MATCH_SS_STA_LD_W_V_6_M_MEM1, MASK_SS_STA_LD_W_V_6_M_MEM1)
+DECLARE_INSN(ss_sta_ld_w_v_6_m_mem2, MATCH_SS_STA_LD_W_V_6_M_MEM2, MASK_SS_STA_LD_W_V_6_M_MEM2)
+DECLARE_INSN(ss_sta_ld_w_v_6_m_mem3, MATCH_SS_STA_LD_W_V_6_M_MEM3, MASK_SS_STA_LD_W_V_6_M_MEM3)
+DECLARE_INSN(ss_sta_ld_w_v_6_mem1, MATCH_SS_STA_LD_W_V_6_MEM1, MASK_SS_STA_LD_W_V_6_MEM1)
+DECLARE_INSN(ss_sta_ld_w_v_6_mem2, MATCH_SS_STA_LD_W_V_6_MEM2, MASK_SS_STA_LD_W_V_6_MEM2)
+DECLARE_INSN(ss_sta_ld_w_v_6_mem3, MATCH_SS_STA_LD_W_V_6_MEM3, MASK_SS_STA_LD_W_V_6_MEM3)
+DECLARE_INSN(ss_sta_ld_w_v_7, MATCH_SS_STA_LD_W_V_7, MASK_SS_STA_LD_W_V_7)
+DECLARE_INSN(ss_sta_ld_w_v_7_m, MATCH_SS_STA_LD_W_V_7_M, MASK_SS_STA_LD_W_V_7_M)
+DECLARE_INSN(ss_sta_ld_w_v_7_m_mem1, MATCH_SS_STA_LD_W_V_7_M_MEM1, MASK_SS_STA_LD_W_V_7_M_MEM1)
+DECLARE_INSN(ss_sta_ld_w_v_7_m_mem2, MATCH_SS_STA_LD_W_V_7_M_MEM2, MASK_SS_STA_LD_W_V_7_M_MEM2)
+DECLARE_INSN(ss_sta_ld_w_v_7_m_mem3, MATCH_SS_STA_LD_W_V_7_M_MEM3, MASK_SS_STA_LD_W_V_7_M_MEM3)
+DECLARE_INSN(ss_sta_ld_w_v_7_mem1, MATCH_SS_STA_LD_W_V_7_MEM1, MASK_SS_STA_LD_W_V_7_MEM1)
+DECLARE_INSN(ss_sta_ld_w_v_7_mem2, MATCH_SS_STA_LD_W_V_7_MEM2, MASK_SS_STA_LD_W_V_7_MEM2)
+DECLARE_INSN(ss_sta_ld_w_v_7_mem3, MATCH_SS_STA_LD_W_V_7_MEM3, MASK_SS_STA_LD_W_V_7_MEM3)
+DECLARE_INSN(ss_sta_ld_w_v_m, MATCH_SS_STA_LD_W_V_M, MASK_SS_STA_LD_W_V_M)
+DECLARE_INSN(ss_sta_ld_w_v_m_mem1, MATCH_SS_STA_LD_W_V_M_MEM1, MASK_SS_STA_LD_W_V_M_MEM1)
+DECLARE_INSN(ss_sta_ld_w_v_m_mem2, MATCH_SS_STA_LD_W_V_M_MEM2, MASK_SS_STA_LD_W_V_M_MEM2)
+DECLARE_INSN(ss_sta_ld_w_v_m_mem3, MATCH_SS_STA_LD_W_V_M_MEM3, MASK_SS_STA_LD_W_V_M_MEM3)
+DECLARE_INSN(ss_sta_ld_w_v_mem1, MATCH_SS_STA_LD_W_V_MEM1, MASK_SS_STA_LD_W_V_MEM1)
+DECLARE_INSN(ss_sta_ld_w_v_mem2, MATCH_SS_STA_LD_W_V_MEM2, MASK_SS_STA_LD_W_V_MEM2)
+DECLARE_INSN(ss_sta_ld_w_v_mem3, MATCH_SS_STA_LD_W_V_MEM3, MASK_SS_STA_LD_W_V_MEM3)
+DECLARE_INSN(ss_sta_st_b, MATCH_SS_STA_ST_B, MASK_SS_STA_ST_B)
+DECLARE_INSN(ss_sta_st_b_m, MATCH_SS_STA_ST_B_M, MASK_SS_STA_ST_B_M)
+DECLARE_INSN(ss_sta_st_b_m_mem1, MATCH_SS_STA_ST_B_M_MEM1, MASK_SS_STA_ST_B_M_MEM1)
+DECLARE_INSN(ss_sta_st_b_m_mem2, MATCH_SS_STA_ST_B_M_MEM2, MASK_SS_STA_ST_B_M_MEM2)
+DECLARE_INSN(ss_sta_st_b_m_mem3, MATCH_SS_STA_ST_B_M_MEM3, MASK_SS_STA_ST_B_M_MEM3)
+DECLARE_INSN(ss_sta_st_b_mem1, MATCH_SS_STA_ST_B_MEM1, MASK_SS_STA_ST_B_MEM1)
+DECLARE_INSN(ss_sta_st_b_mem2, MATCH_SS_STA_ST_B_MEM2, MASK_SS_STA_ST_B_MEM2)
+DECLARE_INSN(ss_sta_st_b_mem3, MATCH_SS_STA_ST_B_MEM3, MASK_SS_STA_ST_B_MEM3)
+DECLARE_INSN(ss_sta_st_b_v, MATCH_SS_STA_ST_B_V, MASK_SS_STA_ST_B_V)
+DECLARE_INSN(ss_sta_st_b_v_1, MATCH_SS_STA_ST_B_V_1, MASK_SS_STA_ST_B_V_1)
+DECLARE_INSN(ss_sta_st_b_v_1_m, MATCH_SS_STA_ST_B_V_1_M, MASK_SS_STA_ST_B_V_1_M)
+DECLARE_INSN(ss_sta_st_b_v_1_m_mem1, MATCH_SS_STA_ST_B_V_1_M_MEM1, MASK_SS_STA_ST_B_V_1_M_MEM1)
+DECLARE_INSN(ss_sta_st_b_v_1_m_mem2, MATCH_SS_STA_ST_B_V_1_M_MEM2, MASK_SS_STA_ST_B_V_1_M_MEM2)
+DECLARE_INSN(ss_sta_st_b_v_1_m_mem3, MATCH_SS_STA_ST_B_V_1_M_MEM3, MASK_SS_STA_ST_B_V_1_M_MEM3)
+DECLARE_INSN(ss_sta_st_b_v_1_mem1, MATCH_SS_STA_ST_B_V_1_MEM1, MASK_SS_STA_ST_B_V_1_MEM1)
+DECLARE_INSN(ss_sta_st_b_v_1_mem2, MATCH_SS_STA_ST_B_V_1_MEM2, MASK_SS_STA_ST_B_V_1_MEM2)
+DECLARE_INSN(ss_sta_st_b_v_1_mem3, MATCH_SS_STA_ST_B_V_1_MEM3, MASK_SS_STA_ST_B_V_1_MEM3)
+DECLARE_INSN(ss_sta_st_b_v_2, MATCH_SS_STA_ST_B_V_2, MASK_SS_STA_ST_B_V_2)
+DECLARE_INSN(ss_sta_st_b_v_2_m, MATCH_SS_STA_ST_B_V_2_M, MASK_SS_STA_ST_B_V_2_M)
+DECLARE_INSN(ss_sta_st_b_v_2_m_mem1, MATCH_SS_STA_ST_B_V_2_M_MEM1, MASK_SS_STA_ST_B_V_2_M_MEM1)
+DECLARE_INSN(ss_sta_st_b_v_2_m_mem2, MATCH_SS_STA_ST_B_V_2_M_MEM2, MASK_SS_STA_ST_B_V_2_M_MEM2)
+DECLARE_INSN(ss_sta_st_b_v_2_m_mem3, MATCH_SS_STA_ST_B_V_2_M_MEM3, MASK_SS_STA_ST_B_V_2_M_MEM3)
+DECLARE_INSN(ss_sta_st_b_v_2_mem1, MATCH_SS_STA_ST_B_V_2_MEM1, MASK_SS_STA_ST_B_V_2_MEM1)
+DECLARE_INSN(ss_sta_st_b_v_2_mem2, MATCH_SS_STA_ST_B_V_2_MEM2, MASK_SS_STA_ST_B_V_2_MEM2)
+DECLARE_INSN(ss_sta_st_b_v_2_mem3, MATCH_SS_STA_ST_B_V_2_MEM3, MASK_SS_STA_ST_B_V_2_MEM3)
+DECLARE_INSN(ss_sta_st_b_v_3, MATCH_SS_STA_ST_B_V_3, MASK_SS_STA_ST_B_V_3)
+DECLARE_INSN(ss_sta_st_b_v_3_m, MATCH_SS_STA_ST_B_V_3_M, MASK_SS_STA_ST_B_V_3_M)
+DECLARE_INSN(ss_sta_st_b_v_3_m_mem1, MATCH_SS_STA_ST_B_V_3_M_MEM1, MASK_SS_STA_ST_B_V_3_M_MEM1)
+DECLARE_INSN(ss_sta_st_b_v_3_m_mem2, MATCH_SS_STA_ST_B_V_3_M_MEM2, MASK_SS_STA_ST_B_V_3_M_MEM2)
+DECLARE_INSN(ss_sta_st_b_v_3_m_mem3, MATCH_SS_STA_ST_B_V_3_M_MEM3, MASK_SS_STA_ST_B_V_3_M_MEM3)
+DECLARE_INSN(ss_sta_st_b_v_3_mem1, MATCH_SS_STA_ST_B_V_3_MEM1, MASK_SS_STA_ST_B_V_3_MEM1)
+DECLARE_INSN(ss_sta_st_b_v_3_mem2, MATCH_SS_STA_ST_B_V_3_MEM2, MASK_SS_STA_ST_B_V_3_MEM2)
+DECLARE_INSN(ss_sta_st_b_v_3_mem3, MATCH_SS_STA_ST_B_V_3_MEM3, MASK_SS_STA_ST_B_V_3_MEM3)
+DECLARE_INSN(ss_sta_st_b_v_4, MATCH_SS_STA_ST_B_V_4, MASK_SS_STA_ST_B_V_4)
+DECLARE_INSN(ss_sta_st_b_v_4_m, MATCH_SS_STA_ST_B_V_4_M, MASK_SS_STA_ST_B_V_4_M)
+DECLARE_INSN(ss_sta_st_b_v_4_m_mem1, MATCH_SS_STA_ST_B_V_4_M_MEM1, MASK_SS_STA_ST_B_V_4_M_MEM1)
+DECLARE_INSN(ss_sta_st_b_v_4_m_mem2, MATCH_SS_STA_ST_B_V_4_M_MEM2, MASK_SS_STA_ST_B_V_4_M_MEM2)
+DECLARE_INSN(ss_sta_st_b_v_4_m_mem3, MATCH_SS_STA_ST_B_V_4_M_MEM3, MASK_SS_STA_ST_B_V_4_M_MEM3)
+DECLARE_INSN(ss_sta_st_b_v_4_mem1, MATCH_SS_STA_ST_B_V_4_MEM1, MASK_SS_STA_ST_B_V_4_MEM1)
+DECLARE_INSN(ss_sta_st_b_v_4_mem2, MATCH_SS_STA_ST_B_V_4_MEM2, MASK_SS_STA_ST_B_V_4_MEM2)
+DECLARE_INSN(ss_sta_st_b_v_4_mem3, MATCH_SS_STA_ST_B_V_4_MEM3, MASK_SS_STA_ST_B_V_4_MEM3)
+DECLARE_INSN(ss_sta_st_b_v_5, MATCH_SS_STA_ST_B_V_5, MASK_SS_STA_ST_B_V_5)
+DECLARE_INSN(ss_sta_st_b_v_5_m, MATCH_SS_STA_ST_B_V_5_M, MASK_SS_STA_ST_B_V_5_M)
+DECLARE_INSN(ss_sta_st_b_v_5_m_mem1, MATCH_SS_STA_ST_B_V_5_M_MEM1, MASK_SS_STA_ST_B_V_5_M_MEM1)
+DECLARE_INSN(ss_sta_st_b_v_5_m_mem2, MATCH_SS_STA_ST_B_V_5_M_MEM2, MASK_SS_STA_ST_B_V_5_M_MEM2)
+DECLARE_INSN(ss_sta_st_b_v_5_m_mem3, MATCH_SS_STA_ST_B_V_5_M_MEM3, MASK_SS_STA_ST_B_V_5_M_MEM3)
+DECLARE_INSN(ss_sta_st_b_v_5_mem1, MATCH_SS_STA_ST_B_V_5_MEM1, MASK_SS_STA_ST_B_V_5_MEM1)
+DECLARE_INSN(ss_sta_st_b_v_5_mem2, MATCH_SS_STA_ST_B_V_5_MEM2, MASK_SS_STA_ST_B_V_5_MEM2)
+DECLARE_INSN(ss_sta_st_b_v_5_mem3, MATCH_SS_STA_ST_B_V_5_MEM3, MASK_SS_STA_ST_B_V_5_MEM3)
+DECLARE_INSN(ss_sta_st_b_v_6, MATCH_SS_STA_ST_B_V_6, MASK_SS_STA_ST_B_V_6)
+DECLARE_INSN(ss_sta_st_b_v_6_m, MATCH_SS_STA_ST_B_V_6_M, MASK_SS_STA_ST_B_V_6_M)
+DECLARE_INSN(ss_sta_st_b_v_6_m_mem1, MATCH_SS_STA_ST_B_V_6_M_MEM1, MASK_SS_STA_ST_B_V_6_M_MEM1)
+DECLARE_INSN(ss_sta_st_b_v_6_m_mem2, MATCH_SS_STA_ST_B_V_6_M_MEM2, MASK_SS_STA_ST_B_V_6_M_MEM2)
+DECLARE_INSN(ss_sta_st_b_v_6_m_mem3, MATCH_SS_STA_ST_B_V_6_M_MEM3, MASK_SS_STA_ST_B_V_6_M_MEM3)
+DECLARE_INSN(ss_sta_st_b_v_6_mem1, MATCH_SS_STA_ST_B_V_6_MEM1, MASK_SS_STA_ST_B_V_6_MEM1)
+DECLARE_INSN(ss_sta_st_b_v_6_mem2, MATCH_SS_STA_ST_B_V_6_MEM2, MASK_SS_STA_ST_B_V_6_MEM2)
+DECLARE_INSN(ss_sta_st_b_v_6_mem3, MATCH_SS_STA_ST_B_V_6_MEM3, MASK_SS_STA_ST_B_V_6_MEM3)
+DECLARE_INSN(ss_sta_st_b_v_7, MATCH_SS_STA_ST_B_V_7, MASK_SS_STA_ST_B_V_7)
+DECLARE_INSN(ss_sta_st_b_v_7_m, MATCH_SS_STA_ST_B_V_7_M, MASK_SS_STA_ST_B_V_7_M)
+DECLARE_INSN(ss_sta_st_b_v_7_m_mem1, MATCH_SS_STA_ST_B_V_7_M_MEM1, MASK_SS_STA_ST_B_V_7_M_MEM1)
+DECLARE_INSN(ss_sta_st_b_v_7_m_mem2, MATCH_SS_STA_ST_B_V_7_M_MEM2, MASK_SS_STA_ST_B_V_7_M_MEM2)
+DECLARE_INSN(ss_sta_st_b_v_7_m_mem3, MATCH_SS_STA_ST_B_V_7_M_MEM3, MASK_SS_STA_ST_B_V_7_M_MEM3)
+DECLARE_INSN(ss_sta_st_b_v_7_mem1, MATCH_SS_STA_ST_B_V_7_MEM1, MASK_SS_STA_ST_B_V_7_MEM1)
+DECLARE_INSN(ss_sta_st_b_v_7_mem2, MATCH_SS_STA_ST_B_V_7_MEM2, MASK_SS_STA_ST_B_V_7_MEM2)
+DECLARE_INSN(ss_sta_st_b_v_7_mem3, MATCH_SS_STA_ST_B_V_7_MEM3, MASK_SS_STA_ST_B_V_7_MEM3)
+DECLARE_INSN(ss_sta_st_b_v_m, MATCH_SS_STA_ST_B_V_M, MASK_SS_STA_ST_B_V_M)
+DECLARE_INSN(ss_sta_st_b_v_m_mem1, MATCH_SS_STA_ST_B_V_M_MEM1, MASK_SS_STA_ST_B_V_M_MEM1)
+DECLARE_INSN(ss_sta_st_b_v_m_mem2, MATCH_SS_STA_ST_B_V_M_MEM2, MASK_SS_STA_ST_B_V_M_MEM2)
+DECLARE_INSN(ss_sta_st_b_v_m_mem3, MATCH_SS_STA_ST_B_V_M_MEM3, MASK_SS_STA_ST_B_V_M_MEM3)
+DECLARE_INSN(ss_sta_st_b_v_mem1, MATCH_SS_STA_ST_B_V_MEM1, MASK_SS_STA_ST_B_V_MEM1)
+DECLARE_INSN(ss_sta_st_b_v_mem2, MATCH_SS_STA_ST_B_V_MEM2, MASK_SS_STA_ST_B_V_MEM2)
+DECLARE_INSN(ss_sta_st_b_v_mem3, MATCH_SS_STA_ST_B_V_MEM3, MASK_SS_STA_ST_B_V_MEM3)
+DECLARE_INSN(ss_sta_st_d, MATCH_SS_STA_ST_D, MASK_SS_STA_ST_D)
+DECLARE_INSN(ss_sta_st_d_m, MATCH_SS_STA_ST_D_M, MASK_SS_STA_ST_D_M)
+DECLARE_INSN(ss_sta_st_d_m_mem1, MATCH_SS_STA_ST_D_M_MEM1, MASK_SS_STA_ST_D_M_MEM1)
+DECLARE_INSN(ss_sta_st_d_m_mem2, MATCH_SS_STA_ST_D_M_MEM2, MASK_SS_STA_ST_D_M_MEM2)
+DECLARE_INSN(ss_sta_st_d_m_mem3, MATCH_SS_STA_ST_D_M_MEM3, MASK_SS_STA_ST_D_M_MEM3)
+DECLARE_INSN(ss_sta_st_d_mem1, MATCH_SS_STA_ST_D_MEM1, MASK_SS_STA_ST_D_MEM1)
+DECLARE_INSN(ss_sta_st_d_mem2, MATCH_SS_STA_ST_D_MEM2, MASK_SS_STA_ST_D_MEM2)
+DECLARE_INSN(ss_sta_st_d_mem3, MATCH_SS_STA_ST_D_MEM3, MASK_SS_STA_ST_D_MEM3)
+DECLARE_INSN(ss_sta_st_d_v, MATCH_SS_STA_ST_D_V, MASK_SS_STA_ST_D_V)
+DECLARE_INSN(ss_sta_st_d_v_1, MATCH_SS_STA_ST_D_V_1, MASK_SS_STA_ST_D_V_1)
+DECLARE_INSN(ss_sta_st_d_v_1_m, MATCH_SS_STA_ST_D_V_1_M, MASK_SS_STA_ST_D_V_1_M)
+DECLARE_INSN(ss_sta_st_d_v_1_m_mem1, MATCH_SS_STA_ST_D_V_1_M_MEM1, MASK_SS_STA_ST_D_V_1_M_MEM1)
+DECLARE_INSN(ss_sta_st_d_v_1_m_mem2, MATCH_SS_STA_ST_D_V_1_M_MEM2, MASK_SS_STA_ST_D_V_1_M_MEM2)
+DECLARE_INSN(ss_sta_st_d_v_1_m_mem3, MATCH_SS_STA_ST_D_V_1_M_MEM3, MASK_SS_STA_ST_D_V_1_M_MEM3)
+DECLARE_INSN(ss_sta_st_d_v_1_mem1, MATCH_SS_STA_ST_D_V_1_MEM1, MASK_SS_STA_ST_D_V_1_MEM1)
+DECLARE_INSN(ss_sta_st_d_v_1_mem2, MATCH_SS_STA_ST_D_V_1_MEM2, MASK_SS_STA_ST_D_V_1_MEM2)
+DECLARE_INSN(ss_sta_st_d_v_1_mem3, MATCH_SS_STA_ST_D_V_1_MEM3, MASK_SS_STA_ST_D_V_1_MEM3)
+DECLARE_INSN(ss_sta_st_d_v_2, MATCH_SS_STA_ST_D_V_2, MASK_SS_STA_ST_D_V_2)
+DECLARE_INSN(ss_sta_st_d_v_2_m, MATCH_SS_STA_ST_D_V_2_M, MASK_SS_STA_ST_D_V_2_M)
+DECLARE_INSN(ss_sta_st_d_v_2_m_mem1, MATCH_SS_STA_ST_D_V_2_M_MEM1, MASK_SS_STA_ST_D_V_2_M_MEM1)
+DECLARE_INSN(ss_sta_st_d_v_2_m_mem2, MATCH_SS_STA_ST_D_V_2_M_MEM2, MASK_SS_STA_ST_D_V_2_M_MEM2)
+DECLARE_INSN(ss_sta_st_d_v_2_m_mem3, MATCH_SS_STA_ST_D_V_2_M_MEM3, MASK_SS_STA_ST_D_V_2_M_MEM3)
+DECLARE_INSN(ss_sta_st_d_v_2_mem1, MATCH_SS_STA_ST_D_V_2_MEM1, MASK_SS_STA_ST_D_V_2_MEM1)
+DECLARE_INSN(ss_sta_st_d_v_2_mem2, MATCH_SS_STA_ST_D_V_2_MEM2, MASK_SS_STA_ST_D_V_2_MEM2)
+DECLARE_INSN(ss_sta_st_d_v_2_mem3, MATCH_SS_STA_ST_D_V_2_MEM3, MASK_SS_STA_ST_D_V_2_MEM3)
+DECLARE_INSN(ss_sta_st_d_v_3, MATCH_SS_STA_ST_D_V_3, MASK_SS_STA_ST_D_V_3)
+DECLARE_INSN(ss_sta_st_d_v_3_m, MATCH_SS_STA_ST_D_V_3_M, MASK_SS_STA_ST_D_V_3_M)
+DECLARE_INSN(ss_sta_st_d_v_3_m_mem1, MATCH_SS_STA_ST_D_V_3_M_MEM1, MASK_SS_STA_ST_D_V_3_M_MEM1)
+DECLARE_INSN(ss_sta_st_d_v_3_m_mem2, MATCH_SS_STA_ST_D_V_3_M_MEM2, MASK_SS_STA_ST_D_V_3_M_MEM2)
+DECLARE_INSN(ss_sta_st_d_v_3_m_mem3, MATCH_SS_STA_ST_D_V_3_M_MEM3, MASK_SS_STA_ST_D_V_3_M_MEM3)
+DECLARE_INSN(ss_sta_st_d_v_3_mem1, MATCH_SS_STA_ST_D_V_3_MEM1, MASK_SS_STA_ST_D_V_3_MEM1)
+DECLARE_INSN(ss_sta_st_d_v_3_mem2, MATCH_SS_STA_ST_D_V_3_MEM2, MASK_SS_STA_ST_D_V_3_MEM2)
+DECLARE_INSN(ss_sta_st_d_v_3_mem3, MATCH_SS_STA_ST_D_V_3_MEM3, MASK_SS_STA_ST_D_V_3_MEM3)
+DECLARE_INSN(ss_sta_st_d_v_4, MATCH_SS_STA_ST_D_V_4, MASK_SS_STA_ST_D_V_4)
+DECLARE_INSN(ss_sta_st_d_v_4_m, MATCH_SS_STA_ST_D_V_4_M, MASK_SS_STA_ST_D_V_4_M)
+DECLARE_INSN(ss_sta_st_d_v_4_m_mem1, MATCH_SS_STA_ST_D_V_4_M_MEM1, MASK_SS_STA_ST_D_V_4_M_MEM1)
+DECLARE_INSN(ss_sta_st_d_v_4_m_mem2, MATCH_SS_STA_ST_D_V_4_M_MEM2, MASK_SS_STA_ST_D_V_4_M_MEM2)
+DECLARE_INSN(ss_sta_st_d_v_4_m_mem3, MATCH_SS_STA_ST_D_V_4_M_MEM3, MASK_SS_STA_ST_D_V_4_M_MEM3)
+DECLARE_INSN(ss_sta_st_d_v_4_mem1, MATCH_SS_STA_ST_D_V_4_MEM1, MASK_SS_STA_ST_D_V_4_MEM1)
+DECLARE_INSN(ss_sta_st_d_v_4_mem2, MATCH_SS_STA_ST_D_V_4_MEM2, MASK_SS_STA_ST_D_V_4_MEM2)
+DECLARE_INSN(ss_sta_st_d_v_4_mem3, MATCH_SS_STA_ST_D_V_4_MEM3, MASK_SS_STA_ST_D_V_4_MEM3)
+DECLARE_INSN(ss_sta_st_d_v_5, MATCH_SS_STA_ST_D_V_5, MASK_SS_STA_ST_D_V_5)
+DECLARE_INSN(ss_sta_st_d_v_5_m, MATCH_SS_STA_ST_D_V_5_M, MASK_SS_STA_ST_D_V_5_M)
+DECLARE_INSN(ss_sta_st_d_v_5_m_mem1, MATCH_SS_STA_ST_D_V_5_M_MEM1, MASK_SS_STA_ST_D_V_5_M_MEM1)
+DECLARE_INSN(ss_sta_st_d_v_5_m_mem2, MATCH_SS_STA_ST_D_V_5_M_MEM2, MASK_SS_STA_ST_D_V_5_M_MEM2)
+DECLARE_INSN(ss_sta_st_d_v_5_m_mem3, MATCH_SS_STA_ST_D_V_5_M_MEM3, MASK_SS_STA_ST_D_V_5_M_MEM3)
+DECLARE_INSN(ss_sta_st_d_v_5_mem1, MATCH_SS_STA_ST_D_V_5_MEM1, MASK_SS_STA_ST_D_V_5_MEM1)
+DECLARE_INSN(ss_sta_st_d_v_5_mem2, MATCH_SS_STA_ST_D_V_5_MEM2, MASK_SS_STA_ST_D_V_5_MEM2)
+DECLARE_INSN(ss_sta_st_d_v_5_mem3, MATCH_SS_STA_ST_D_V_5_MEM3, MASK_SS_STA_ST_D_V_5_MEM3)
+DECLARE_INSN(ss_sta_st_d_v_6, MATCH_SS_STA_ST_D_V_6, MASK_SS_STA_ST_D_V_6)
+DECLARE_INSN(ss_sta_st_d_v_6_m, MATCH_SS_STA_ST_D_V_6_M, MASK_SS_STA_ST_D_V_6_M)
+DECLARE_INSN(ss_sta_st_d_v_6_m_mem1, MATCH_SS_STA_ST_D_V_6_M_MEM1, MASK_SS_STA_ST_D_V_6_M_MEM1)
+DECLARE_INSN(ss_sta_st_d_v_6_m_mem2, MATCH_SS_STA_ST_D_V_6_M_MEM2, MASK_SS_STA_ST_D_V_6_M_MEM2)
+DECLARE_INSN(ss_sta_st_d_v_6_m_mem3, MATCH_SS_STA_ST_D_V_6_M_MEM3, MASK_SS_STA_ST_D_V_6_M_MEM3)
+DECLARE_INSN(ss_sta_st_d_v_6_mem1, MATCH_SS_STA_ST_D_V_6_MEM1, MASK_SS_STA_ST_D_V_6_MEM1)
+DECLARE_INSN(ss_sta_st_d_v_6_mem2, MATCH_SS_STA_ST_D_V_6_MEM2, MASK_SS_STA_ST_D_V_6_MEM2)
+DECLARE_INSN(ss_sta_st_d_v_6_mem3, MATCH_SS_STA_ST_D_V_6_MEM3, MASK_SS_STA_ST_D_V_6_MEM3)
+DECLARE_INSN(ss_sta_st_d_v_7, MATCH_SS_STA_ST_D_V_7, MASK_SS_STA_ST_D_V_7)
+DECLARE_INSN(ss_sta_st_d_v_7_m, MATCH_SS_STA_ST_D_V_7_M, MASK_SS_STA_ST_D_V_7_M)
+DECLARE_INSN(ss_sta_st_d_v_7_m_mem1, MATCH_SS_STA_ST_D_V_7_M_MEM1, MASK_SS_STA_ST_D_V_7_M_MEM1)
+DECLARE_INSN(ss_sta_st_d_v_7_m_mem2, MATCH_SS_STA_ST_D_V_7_M_MEM2, MASK_SS_STA_ST_D_V_7_M_MEM2)
+DECLARE_INSN(ss_sta_st_d_v_7_m_mem3, MATCH_SS_STA_ST_D_V_7_M_MEM3, MASK_SS_STA_ST_D_V_7_M_MEM3)
+DECLARE_INSN(ss_sta_st_d_v_7_mem1, MATCH_SS_STA_ST_D_V_7_MEM1, MASK_SS_STA_ST_D_V_7_MEM1)
+DECLARE_INSN(ss_sta_st_d_v_7_mem2, MATCH_SS_STA_ST_D_V_7_MEM2, MASK_SS_STA_ST_D_V_7_MEM2)
+DECLARE_INSN(ss_sta_st_d_v_7_mem3, MATCH_SS_STA_ST_D_V_7_MEM3, MASK_SS_STA_ST_D_V_7_MEM3)
+DECLARE_INSN(ss_sta_st_d_v_m, MATCH_SS_STA_ST_D_V_M, MASK_SS_STA_ST_D_V_M)
+DECLARE_INSN(ss_sta_st_d_v_m_mem1, MATCH_SS_STA_ST_D_V_M_MEM1, MASK_SS_STA_ST_D_V_M_MEM1)
+DECLARE_INSN(ss_sta_st_d_v_m_mem2, MATCH_SS_STA_ST_D_V_M_MEM2, MASK_SS_STA_ST_D_V_M_MEM2)
+DECLARE_INSN(ss_sta_st_d_v_m_mem3, MATCH_SS_STA_ST_D_V_M_MEM3, MASK_SS_STA_ST_D_V_M_MEM3)
+DECLARE_INSN(ss_sta_st_d_v_mem1, MATCH_SS_STA_ST_D_V_MEM1, MASK_SS_STA_ST_D_V_MEM1)
+DECLARE_INSN(ss_sta_st_d_v_mem2, MATCH_SS_STA_ST_D_V_MEM2, MASK_SS_STA_ST_D_V_MEM2)
+DECLARE_INSN(ss_sta_st_d_v_mem3, MATCH_SS_STA_ST_D_V_MEM3, MASK_SS_STA_ST_D_V_MEM3)
+DECLARE_INSN(ss_sta_st_h, MATCH_SS_STA_ST_H, MASK_SS_STA_ST_H)
+DECLARE_INSN(ss_sta_st_h_m, MATCH_SS_STA_ST_H_M, MASK_SS_STA_ST_H_M)
+DECLARE_INSN(ss_sta_st_h_m_mem1, MATCH_SS_STA_ST_H_M_MEM1, MASK_SS_STA_ST_H_M_MEM1)
+DECLARE_INSN(ss_sta_st_h_m_mem2, MATCH_SS_STA_ST_H_M_MEM2, MASK_SS_STA_ST_H_M_MEM2)
+DECLARE_INSN(ss_sta_st_h_m_mem3, MATCH_SS_STA_ST_H_M_MEM3, MASK_SS_STA_ST_H_M_MEM3)
+DECLARE_INSN(ss_sta_st_h_mem1, MATCH_SS_STA_ST_H_MEM1, MASK_SS_STA_ST_H_MEM1)
+DECLARE_INSN(ss_sta_st_h_mem2, MATCH_SS_STA_ST_H_MEM2, MASK_SS_STA_ST_H_MEM2)
+DECLARE_INSN(ss_sta_st_h_mem3, MATCH_SS_STA_ST_H_MEM3, MASK_SS_STA_ST_H_MEM3)
+DECLARE_INSN(ss_sta_st_h_v, MATCH_SS_STA_ST_H_V, MASK_SS_STA_ST_H_V)
+DECLARE_INSN(ss_sta_st_h_v_1, MATCH_SS_STA_ST_H_V_1, MASK_SS_STA_ST_H_V_1)
+DECLARE_INSN(ss_sta_st_h_v_1_m, MATCH_SS_STA_ST_H_V_1_M, MASK_SS_STA_ST_H_V_1_M)
+DECLARE_INSN(ss_sta_st_h_v_1_m_mem1, MATCH_SS_STA_ST_H_V_1_M_MEM1, MASK_SS_STA_ST_H_V_1_M_MEM1)
+DECLARE_INSN(ss_sta_st_h_v_1_m_mem2, MATCH_SS_STA_ST_H_V_1_M_MEM2, MASK_SS_STA_ST_H_V_1_M_MEM2)
+DECLARE_INSN(ss_sta_st_h_v_1_m_mem3, MATCH_SS_STA_ST_H_V_1_M_MEM3, MASK_SS_STA_ST_H_V_1_M_MEM3)
+DECLARE_INSN(ss_sta_st_h_v_1_mem1, MATCH_SS_STA_ST_H_V_1_MEM1, MASK_SS_STA_ST_H_V_1_MEM1)
+DECLARE_INSN(ss_sta_st_h_v_1_mem2, MATCH_SS_STA_ST_H_V_1_MEM2, MASK_SS_STA_ST_H_V_1_MEM2)
+DECLARE_INSN(ss_sta_st_h_v_1_mem3, MATCH_SS_STA_ST_H_V_1_MEM3, MASK_SS_STA_ST_H_V_1_MEM3)
+DECLARE_INSN(ss_sta_st_h_v_2, MATCH_SS_STA_ST_H_V_2, MASK_SS_STA_ST_H_V_2)
+DECLARE_INSN(ss_sta_st_h_v_2_m, MATCH_SS_STA_ST_H_V_2_M, MASK_SS_STA_ST_H_V_2_M)
+DECLARE_INSN(ss_sta_st_h_v_2_m_mem1, MATCH_SS_STA_ST_H_V_2_M_MEM1, MASK_SS_STA_ST_H_V_2_M_MEM1)
+DECLARE_INSN(ss_sta_st_h_v_2_m_mem2, MATCH_SS_STA_ST_H_V_2_M_MEM2, MASK_SS_STA_ST_H_V_2_M_MEM2)
+DECLARE_INSN(ss_sta_st_h_v_2_m_mem3, MATCH_SS_STA_ST_H_V_2_M_MEM3, MASK_SS_STA_ST_H_V_2_M_MEM3)
+DECLARE_INSN(ss_sta_st_h_v_2_mem1, MATCH_SS_STA_ST_H_V_2_MEM1, MASK_SS_STA_ST_H_V_2_MEM1)
+DECLARE_INSN(ss_sta_st_h_v_2_mem2, MATCH_SS_STA_ST_H_V_2_MEM2, MASK_SS_STA_ST_H_V_2_MEM2)
+DECLARE_INSN(ss_sta_st_h_v_2_mem3, MATCH_SS_STA_ST_H_V_2_MEM3, MASK_SS_STA_ST_H_V_2_MEM3)
+DECLARE_INSN(ss_sta_st_h_v_3, MATCH_SS_STA_ST_H_V_3, MASK_SS_STA_ST_H_V_3)
+DECLARE_INSN(ss_sta_st_h_v_3_m, MATCH_SS_STA_ST_H_V_3_M, MASK_SS_STA_ST_H_V_3_M)
+DECLARE_INSN(ss_sta_st_h_v_3_m_mem1, MATCH_SS_STA_ST_H_V_3_M_MEM1, MASK_SS_STA_ST_H_V_3_M_MEM1)
+DECLARE_INSN(ss_sta_st_h_v_3_m_mem2, MATCH_SS_STA_ST_H_V_3_M_MEM2, MASK_SS_STA_ST_H_V_3_M_MEM2)
+DECLARE_INSN(ss_sta_st_h_v_3_m_mem3, MATCH_SS_STA_ST_H_V_3_M_MEM3, MASK_SS_STA_ST_H_V_3_M_MEM3)
+DECLARE_INSN(ss_sta_st_h_v_3_mem1, MATCH_SS_STA_ST_H_V_3_MEM1, MASK_SS_STA_ST_H_V_3_MEM1)
+DECLARE_INSN(ss_sta_st_h_v_3_mem2, MATCH_SS_STA_ST_H_V_3_MEM2, MASK_SS_STA_ST_H_V_3_MEM2)
+DECLARE_INSN(ss_sta_st_h_v_3_mem3, MATCH_SS_STA_ST_H_V_3_MEM3, MASK_SS_STA_ST_H_V_3_MEM3)
+DECLARE_INSN(ss_sta_st_h_v_4, MATCH_SS_STA_ST_H_V_4, MASK_SS_STA_ST_H_V_4)
+DECLARE_INSN(ss_sta_st_h_v_4_m, MATCH_SS_STA_ST_H_V_4_M, MASK_SS_STA_ST_H_V_4_M)
+DECLARE_INSN(ss_sta_st_h_v_4_m_mem1, MATCH_SS_STA_ST_H_V_4_M_MEM1, MASK_SS_STA_ST_H_V_4_M_MEM1)
+DECLARE_INSN(ss_sta_st_h_v_4_m_mem2, MATCH_SS_STA_ST_H_V_4_M_MEM2, MASK_SS_STA_ST_H_V_4_M_MEM2)
+DECLARE_INSN(ss_sta_st_h_v_4_m_mem3, MATCH_SS_STA_ST_H_V_4_M_MEM3, MASK_SS_STA_ST_H_V_4_M_MEM3)
+DECLARE_INSN(ss_sta_st_h_v_4_mem1, MATCH_SS_STA_ST_H_V_4_MEM1, MASK_SS_STA_ST_H_V_4_MEM1)
+DECLARE_INSN(ss_sta_st_h_v_4_mem2, MATCH_SS_STA_ST_H_V_4_MEM2, MASK_SS_STA_ST_H_V_4_MEM2)
+DECLARE_INSN(ss_sta_st_h_v_4_mem3, MATCH_SS_STA_ST_H_V_4_MEM3, MASK_SS_STA_ST_H_V_4_MEM3)
+DECLARE_INSN(ss_sta_st_h_v_5, MATCH_SS_STA_ST_H_V_5, MASK_SS_STA_ST_H_V_5)
+DECLARE_INSN(ss_sta_st_h_v_5_m, MATCH_SS_STA_ST_H_V_5_M, MASK_SS_STA_ST_H_V_5_M)
+DECLARE_INSN(ss_sta_st_h_v_5_m_mem1, MATCH_SS_STA_ST_H_V_5_M_MEM1, MASK_SS_STA_ST_H_V_5_M_MEM1)
+DECLARE_INSN(ss_sta_st_h_v_5_m_mem2, MATCH_SS_STA_ST_H_V_5_M_MEM2, MASK_SS_STA_ST_H_V_5_M_MEM2)
+DECLARE_INSN(ss_sta_st_h_v_5_m_mem3, MATCH_SS_STA_ST_H_V_5_M_MEM3, MASK_SS_STA_ST_H_V_5_M_MEM3)
+DECLARE_INSN(ss_sta_st_h_v_5_mem1, MATCH_SS_STA_ST_H_V_5_MEM1, MASK_SS_STA_ST_H_V_5_MEM1)
+DECLARE_INSN(ss_sta_st_h_v_5_mem2, MATCH_SS_STA_ST_H_V_5_MEM2, MASK_SS_STA_ST_H_V_5_MEM2)
+DECLARE_INSN(ss_sta_st_h_v_5_mem3, MATCH_SS_STA_ST_H_V_5_MEM3, MASK_SS_STA_ST_H_V_5_MEM3)
+DECLARE_INSN(ss_sta_st_h_v_6, MATCH_SS_STA_ST_H_V_6, MASK_SS_STA_ST_H_V_6)
+DECLARE_INSN(ss_sta_st_h_v_6_m, MATCH_SS_STA_ST_H_V_6_M, MASK_SS_STA_ST_H_V_6_M)
+DECLARE_INSN(ss_sta_st_h_v_6_m_mem1, MATCH_SS_STA_ST_H_V_6_M_MEM1, MASK_SS_STA_ST_H_V_6_M_MEM1)
+DECLARE_INSN(ss_sta_st_h_v_6_m_mem2, MATCH_SS_STA_ST_H_V_6_M_MEM2, MASK_SS_STA_ST_H_V_6_M_MEM2)
+DECLARE_INSN(ss_sta_st_h_v_6_m_mem3, MATCH_SS_STA_ST_H_V_6_M_MEM3, MASK_SS_STA_ST_H_V_6_M_MEM3)
+DECLARE_INSN(ss_sta_st_h_v_6_mem1, MATCH_SS_STA_ST_H_V_6_MEM1, MASK_SS_STA_ST_H_V_6_MEM1)
+DECLARE_INSN(ss_sta_st_h_v_6_mem2, MATCH_SS_STA_ST_H_V_6_MEM2, MASK_SS_STA_ST_H_V_6_MEM2)
+DECLARE_INSN(ss_sta_st_h_v_6_mem3, MATCH_SS_STA_ST_H_V_6_MEM3, MASK_SS_STA_ST_H_V_6_MEM3)
+DECLARE_INSN(ss_sta_st_h_v_7, MATCH_SS_STA_ST_H_V_7, MASK_SS_STA_ST_H_V_7)
+DECLARE_INSN(ss_sta_st_h_v_7_m, MATCH_SS_STA_ST_H_V_7_M, MASK_SS_STA_ST_H_V_7_M)
+DECLARE_INSN(ss_sta_st_h_v_7_m_mem1, MATCH_SS_STA_ST_H_V_7_M_MEM1, MASK_SS_STA_ST_H_V_7_M_MEM1)
+DECLARE_INSN(ss_sta_st_h_v_7_m_mem2, MATCH_SS_STA_ST_H_V_7_M_MEM2, MASK_SS_STA_ST_H_V_7_M_MEM2)
+DECLARE_INSN(ss_sta_st_h_v_7_m_mem3, MATCH_SS_STA_ST_H_V_7_M_MEM3, MASK_SS_STA_ST_H_V_7_M_MEM3)
+DECLARE_INSN(ss_sta_st_h_v_7_mem1, MATCH_SS_STA_ST_H_V_7_MEM1, MASK_SS_STA_ST_H_V_7_MEM1)
+DECLARE_INSN(ss_sta_st_h_v_7_mem2, MATCH_SS_STA_ST_H_V_7_MEM2, MASK_SS_STA_ST_H_V_7_MEM2)
+DECLARE_INSN(ss_sta_st_h_v_7_mem3, MATCH_SS_STA_ST_H_V_7_MEM3, MASK_SS_STA_ST_H_V_7_MEM3)
+DECLARE_INSN(ss_sta_st_h_v_m, MATCH_SS_STA_ST_H_V_M, MASK_SS_STA_ST_H_V_M)
+DECLARE_INSN(ss_sta_st_h_v_m_mem1, MATCH_SS_STA_ST_H_V_M_MEM1, MASK_SS_STA_ST_H_V_M_MEM1)
+DECLARE_INSN(ss_sta_st_h_v_m_mem2, MATCH_SS_STA_ST_H_V_M_MEM2, MASK_SS_STA_ST_H_V_M_MEM2)
+DECLARE_INSN(ss_sta_st_h_v_m_mem3, MATCH_SS_STA_ST_H_V_M_MEM3, MASK_SS_STA_ST_H_V_M_MEM3)
+DECLARE_INSN(ss_sta_st_h_v_mem1, MATCH_SS_STA_ST_H_V_MEM1, MASK_SS_STA_ST_H_V_MEM1)
+DECLARE_INSN(ss_sta_st_h_v_mem2, MATCH_SS_STA_ST_H_V_MEM2, MASK_SS_STA_ST_H_V_MEM2)
+DECLARE_INSN(ss_sta_st_h_v_mem3, MATCH_SS_STA_ST_H_V_MEM3, MASK_SS_STA_ST_H_V_MEM3)
+DECLARE_INSN(ss_sta_st_w, MATCH_SS_STA_ST_W, MASK_SS_STA_ST_W)
+DECLARE_INSN(ss_sta_st_w_m, MATCH_SS_STA_ST_W_M, MASK_SS_STA_ST_W_M)
+DECLARE_INSN(ss_sta_st_w_m_mem1, MATCH_SS_STA_ST_W_M_MEM1, MASK_SS_STA_ST_W_M_MEM1)
+DECLARE_INSN(ss_sta_st_w_m_mem2, MATCH_SS_STA_ST_W_M_MEM2, MASK_SS_STA_ST_W_M_MEM2)
+DECLARE_INSN(ss_sta_st_w_m_mem3, MATCH_SS_STA_ST_W_M_MEM3, MASK_SS_STA_ST_W_M_MEM3)
+DECLARE_INSN(ss_sta_st_w_mem1, MATCH_SS_STA_ST_W_MEM1, MASK_SS_STA_ST_W_MEM1)
+DECLARE_INSN(ss_sta_st_w_mem2, MATCH_SS_STA_ST_W_MEM2, MASK_SS_STA_ST_W_MEM2)
+DECLARE_INSN(ss_sta_st_w_mem3, MATCH_SS_STA_ST_W_MEM3, MASK_SS_STA_ST_W_MEM3)
+DECLARE_INSN(ss_sta_st_w_v, MATCH_SS_STA_ST_W_V, MASK_SS_STA_ST_W_V)
+DECLARE_INSN(ss_sta_st_w_v_1, MATCH_SS_STA_ST_W_V_1, MASK_SS_STA_ST_W_V_1)
+DECLARE_INSN(ss_sta_st_w_v_1_m, MATCH_SS_STA_ST_W_V_1_M, MASK_SS_STA_ST_W_V_1_M)
+DECLARE_INSN(ss_sta_st_w_v_1_m_mem1, MATCH_SS_STA_ST_W_V_1_M_MEM1, MASK_SS_STA_ST_W_V_1_M_MEM1)
+DECLARE_INSN(ss_sta_st_w_v_1_m_mem2, MATCH_SS_STA_ST_W_V_1_M_MEM2, MASK_SS_STA_ST_W_V_1_M_MEM2)
+DECLARE_INSN(ss_sta_st_w_v_1_m_mem3, MATCH_SS_STA_ST_W_V_1_M_MEM3, MASK_SS_STA_ST_W_V_1_M_MEM3)
+DECLARE_INSN(ss_sta_st_w_v_1_mem1, MATCH_SS_STA_ST_W_V_1_MEM1, MASK_SS_STA_ST_W_V_1_MEM1)
+DECLARE_INSN(ss_sta_st_w_v_1_mem2, MATCH_SS_STA_ST_W_V_1_MEM2, MASK_SS_STA_ST_W_V_1_MEM2)
+DECLARE_INSN(ss_sta_st_w_v_1_mem3, MATCH_SS_STA_ST_W_V_1_MEM3, MASK_SS_STA_ST_W_V_1_MEM3)
+DECLARE_INSN(ss_sta_st_w_v_2, MATCH_SS_STA_ST_W_V_2, MASK_SS_STA_ST_W_V_2)
+DECLARE_INSN(ss_sta_st_w_v_2_m, MATCH_SS_STA_ST_W_V_2_M, MASK_SS_STA_ST_W_V_2_M)
+DECLARE_INSN(ss_sta_st_w_v_2_m_mem1, MATCH_SS_STA_ST_W_V_2_M_MEM1, MASK_SS_STA_ST_W_V_2_M_MEM1)
+DECLARE_INSN(ss_sta_st_w_v_2_m_mem2, MATCH_SS_STA_ST_W_V_2_M_MEM2, MASK_SS_STA_ST_W_V_2_M_MEM2)
+DECLARE_INSN(ss_sta_st_w_v_2_m_mem3, MATCH_SS_STA_ST_W_V_2_M_MEM3, MASK_SS_STA_ST_W_V_2_M_MEM3)
+DECLARE_INSN(ss_sta_st_w_v_2_mem1, MATCH_SS_STA_ST_W_V_2_MEM1, MASK_SS_STA_ST_W_V_2_MEM1)
+DECLARE_INSN(ss_sta_st_w_v_2_mem2, MATCH_SS_STA_ST_W_V_2_MEM2, MASK_SS_STA_ST_W_V_2_MEM2)
+DECLARE_INSN(ss_sta_st_w_v_2_mem3, MATCH_SS_STA_ST_W_V_2_MEM3, MASK_SS_STA_ST_W_V_2_MEM3)
+DECLARE_INSN(ss_sta_st_w_v_3, MATCH_SS_STA_ST_W_V_3, MASK_SS_STA_ST_W_V_3)
+DECLARE_INSN(ss_sta_st_w_v_3_m, MATCH_SS_STA_ST_W_V_3_M, MASK_SS_STA_ST_W_V_3_M)
+DECLARE_INSN(ss_sta_st_w_v_3_m_mem1, MATCH_SS_STA_ST_W_V_3_M_MEM1, MASK_SS_STA_ST_W_V_3_M_MEM1)
+DECLARE_INSN(ss_sta_st_w_v_3_m_mem2, MATCH_SS_STA_ST_W_V_3_M_MEM2, MASK_SS_STA_ST_W_V_3_M_MEM2)
+DECLARE_INSN(ss_sta_st_w_v_3_m_mem3, MATCH_SS_STA_ST_W_V_3_M_MEM3, MASK_SS_STA_ST_W_V_3_M_MEM3)
+DECLARE_INSN(ss_sta_st_w_v_3_mem1, MATCH_SS_STA_ST_W_V_3_MEM1, MASK_SS_STA_ST_W_V_3_MEM1)
+DECLARE_INSN(ss_sta_st_w_v_3_mem2, MATCH_SS_STA_ST_W_V_3_MEM2, MASK_SS_STA_ST_W_V_3_MEM2)
+DECLARE_INSN(ss_sta_st_w_v_3_mem3, MATCH_SS_STA_ST_W_V_3_MEM3, MASK_SS_STA_ST_W_V_3_MEM3)
+DECLARE_INSN(ss_sta_st_w_v_4, MATCH_SS_STA_ST_W_V_4, MASK_SS_STA_ST_W_V_4)
+DECLARE_INSN(ss_sta_st_w_v_4_m, MATCH_SS_STA_ST_W_V_4_M, MASK_SS_STA_ST_W_V_4_M)
+DECLARE_INSN(ss_sta_st_w_v_4_m_mem1, MATCH_SS_STA_ST_W_V_4_M_MEM1, MASK_SS_STA_ST_W_V_4_M_MEM1)
+DECLARE_INSN(ss_sta_st_w_v_4_m_mem2, MATCH_SS_STA_ST_W_V_4_M_MEM2, MASK_SS_STA_ST_W_V_4_M_MEM2)
+DECLARE_INSN(ss_sta_st_w_v_4_m_mem3, MATCH_SS_STA_ST_W_V_4_M_MEM3, MASK_SS_STA_ST_W_V_4_M_MEM3)
+DECLARE_INSN(ss_sta_st_w_v_4_mem1, MATCH_SS_STA_ST_W_V_4_MEM1, MASK_SS_STA_ST_W_V_4_MEM1)
+DECLARE_INSN(ss_sta_st_w_v_4_mem2, MATCH_SS_STA_ST_W_V_4_MEM2, MASK_SS_STA_ST_W_V_4_MEM2)
+DECLARE_INSN(ss_sta_st_w_v_4_mem3, MATCH_SS_STA_ST_W_V_4_MEM3, MASK_SS_STA_ST_W_V_4_MEM3)
+DECLARE_INSN(ss_sta_st_w_v_5, MATCH_SS_STA_ST_W_V_5, MASK_SS_STA_ST_W_V_5)
+DECLARE_INSN(ss_sta_st_w_v_5_m, MATCH_SS_STA_ST_W_V_5_M, MASK_SS_STA_ST_W_V_5_M)
+DECLARE_INSN(ss_sta_st_w_v_5_m_mem1, MATCH_SS_STA_ST_W_V_5_M_MEM1, MASK_SS_STA_ST_W_V_5_M_MEM1)
+DECLARE_INSN(ss_sta_st_w_v_5_m_mem2, MATCH_SS_STA_ST_W_V_5_M_MEM2, MASK_SS_STA_ST_W_V_5_M_MEM2)
+DECLARE_INSN(ss_sta_st_w_v_5_m_mem3, MATCH_SS_STA_ST_W_V_5_M_MEM3, MASK_SS_STA_ST_W_V_5_M_MEM3)
+DECLARE_INSN(ss_sta_st_w_v_5_mem1, MATCH_SS_STA_ST_W_V_5_MEM1, MASK_SS_STA_ST_W_V_5_MEM1)
+DECLARE_INSN(ss_sta_st_w_v_5_mem2, MATCH_SS_STA_ST_W_V_5_MEM2, MASK_SS_STA_ST_W_V_5_MEM2)
+DECLARE_INSN(ss_sta_st_w_v_5_mem3, MATCH_SS_STA_ST_W_V_5_MEM3, MASK_SS_STA_ST_W_V_5_MEM3)
+DECLARE_INSN(ss_sta_st_w_v_6, MATCH_SS_STA_ST_W_V_6, MASK_SS_STA_ST_W_V_6)
+DECLARE_INSN(ss_sta_st_w_v_6_m, MATCH_SS_STA_ST_W_V_6_M, MASK_SS_STA_ST_W_V_6_M)
+DECLARE_INSN(ss_sta_st_w_v_6_m_mem1, MATCH_SS_STA_ST_W_V_6_M_MEM1, MASK_SS_STA_ST_W_V_6_M_MEM1)
+DECLARE_INSN(ss_sta_st_w_v_6_m_mem2, MATCH_SS_STA_ST_W_V_6_M_MEM2, MASK_SS_STA_ST_W_V_6_M_MEM2)
+DECLARE_INSN(ss_sta_st_w_v_6_m_mem3, MATCH_SS_STA_ST_W_V_6_M_MEM3, MASK_SS_STA_ST_W_V_6_M_MEM3)
+DECLARE_INSN(ss_sta_st_w_v_6_mem1, MATCH_SS_STA_ST_W_V_6_MEM1, MASK_SS_STA_ST_W_V_6_MEM1)
+DECLARE_INSN(ss_sta_st_w_v_6_mem2, MATCH_SS_STA_ST_W_V_6_MEM2, MASK_SS_STA_ST_W_V_6_MEM2)
+DECLARE_INSN(ss_sta_st_w_v_6_mem3, MATCH_SS_STA_ST_W_V_6_MEM3, MASK_SS_STA_ST_W_V_6_MEM3)
+DECLARE_INSN(ss_sta_st_w_v_7, MATCH_SS_STA_ST_W_V_7, MASK_SS_STA_ST_W_V_7)
+DECLARE_INSN(ss_sta_st_w_v_7_m, MATCH_SS_STA_ST_W_V_7_M, MASK_SS_STA_ST_W_V_7_M)
+DECLARE_INSN(ss_sta_st_w_v_7_m_mem1, MATCH_SS_STA_ST_W_V_7_M_MEM1, MASK_SS_STA_ST_W_V_7_M_MEM1)
+DECLARE_INSN(ss_sta_st_w_v_7_m_mem2, MATCH_SS_STA_ST_W_V_7_M_MEM2, MASK_SS_STA_ST_W_V_7_M_MEM2)
+DECLARE_INSN(ss_sta_st_w_v_7_m_mem3, MATCH_SS_STA_ST_W_V_7_M_MEM3, MASK_SS_STA_ST_W_V_7_M_MEM3)
+DECLARE_INSN(ss_sta_st_w_v_7_mem1, MATCH_SS_STA_ST_W_V_7_MEM1, MASK_SS_STA_ST_W_V_7_MEM1)
+DECLARE_INSN(ss_sta_st_w_v_7_mem2, MATCH_SS_STA_ST_W_V_7_MEM2, MASK_SS_STA_ST_W_V_7_MEM2)
+DECLARE_INSN(ss_sta_st_w_v_7_mem3, MATCH_SS_STA_ST_W_V_7_MEM3, MASK_SS_STA_ST_W_V_7_MEM3)
+DECLARE_INSN(ss_sta_st_w_v_m, MATCH_SS_STA_ST_W_V_M, MASK_SS_STA_ST_W_V_M)
+DECLARE_INSN(ss_sta_st_w_v_m_mem1, MATCH_SS_STA_ST_W_V_M_MEM1, MASK_SS_STA_ST_W_V_M_MEM1)
+DECLARE_INSN(ss_sta_st_w_v_m_mem2, MATCH_SS_STA_ST_W_V_M_MEM2, MASK_SS_STA_ST_W_V_M_MEM2)
+DECLARE_INSN(ss_sta_st_w_v_m_mem3, MATCH_SS_STA_ST_W_V_M_MEM3, MASK_SS_STA_ST_W_V_M_MEM3)
+DECLARE_INSN(ss_sta_st_w_v_mem1, MATCH_SS_STA_ST_W_V_MEM1, MASK_SS_STA_ST_W_V_MEM1)
+DECLARE_INSN(ss_sta_st_w_v_mem2, MATCH_SS_STA_ST_W_V_MEM2, MASK_SS_STA_ST_W_V_MEM2)
+DECLARE_INSN(ss_sta_st_w_v_mem3, MATCH_SS_STA_ST_W_V_MEM3, MASK_SS_STA_ST_W_V_MEM3)
 DECLARE_INSN(ssamoswap_d, MATCH_SSAMOSWAP_D, MASK_SSAMOSWAP_D)
 DECLARE_INSN(ssamoswap_w, MATCH_SSAMOSWAP_W, MASK_SSAMOSWAP_W)
 DECLARE_INSN(sspopchk_x1, MATCH_SSPOPCHK_X1, MASK_SSPOPCHK_X1)
@@ -3559,23 +6337,10 @@ DECLARE_INSN(sspush_x1, MATCH_SSPUSH_X1, MASK_SSPUSH_X1)
 DECLARE_INSN(sspush_x5, MATCH_SSPUSH_X5, MASK_SSPUSH_X5)
 DECLARE_INSN(ssrdp, MATCH_SSRDP, MASK_SSRDP)
 DECLARE_INSN(sub, MATCH_SUB, MASK_SUB)
-DECLARE_INSN(sub64, MATCH_SUB64, MASK_SUB64)
 DECLARE_INSN(subw, MATCH_SUBW, MASK_SUBW)
 DECLARE_INSN(sw, MATCH_SW, MASK_SW)
 DECLARE_INSN(sw_rl, MATCH_SW_RL, MASK_SW_RL)
-DECLARE_INSN(ukadd64, MATCH_UKADD64, MASK_UKADD64)
-DECLARE_INSN(ukmar64, MATCH_UKMAR64, MASK_UKMAR64)
-DECLARE_INSN(ukmsr64, MATCH_UKMSR64, MASK_UKMSR64)
-DECLARE_INSN(uksub64, MATCH_UKSUB64, MASK_UKSUB64)
-DECLARE_INSN(umar64, MATCH_UMAR64, MASK_UMAR64)
-DECLARE_INSN(umsr64, MATCH_UMSR64, MASK_UMSR64)
-DECLARE_INSN(umul16, MATCH_UMUL16, MASK_UMUL16)
-DECLARE_INSN(umul8, MATCH_UMUL8, MASK_UMUL8)
-DECLARE_INSN(umulx16, MATCH_UMULX16, MASK_UMULX16)
-DECLARE_INSN(umulx8, MATCH_UMULX8, MASK_UMULX8)
 DECLARE_INSN(unshfli, MATCH_UNSHFLI, MASK_UNSHFLI)
-DECLARE_INSN(uradd64, MATCH_URADD64, MASK_URADD64)
-DECLARE_INSN(ursub64, MATCH_URSUB64, MASK_URSUB64)
 DECLARE_INSN(vaadd_vv, MATCH_VAADD_VV, MASK_VAADD_VV)
 DECLARE_INSN(vaadd_vx, MATCH_VAADD_VX, MASK_VAADD_VX)
 DECLARE_INSN(vaaddu_vv, MATCH_VAADDU_VV, MASK_VAADDU_VV)
@@ -4071,6 +6836,8 @@ DECLARE_CSR(scause, CSR_SCAUSE)
 DECLARE_CSR(stval, CSR_STVAL)
 DECLARE_CSR(sip, CSR_SIP)
 DECLARE_CSR(stimecmp, CSR_STIMECMP)
+DECLARE_CSR(sctrctl, CSR_SCTRCTL)
+DECLARE_CSR(sctrstatus, CSR_SCTRSTATUS)
 DECLARE_CSR(siselect, CSR_SISELECT)
 DECLARE_CSR(sireg, CSR_SIREG)
 DECLARE_CSR(sireg2, CSR_SIREG2)
@@ -4079,6 +6846,7 @@ DECLARE_CSR(sireg4, CSR_SIREG4)
 DECLARE_CSR(sireg5, CSR_SIREG5)
 DECLARE_CSR(sireg6, CSR_SIREG6)
 DECLARE_CSR(stopei, CSR_STOPEI)
+DECLARE_CSR(sctrdepth, CSR_SCTRDEPTH)
 DECLARE_CSR(satp, CSR_SATP)
 DECLARE_CSR(srmcfg, CSR_SRMCFG)
 DECLARE_CSR(scontext, CSR_SCONTEXT)
@@ -4091,6 +6859,7 @@ DECLARE_CSR(vscause, CSR_VSCAUSE)
 DECLARE_CSR(vstval, CSR_VSTVAL)
 DECLARE_CSR(vsip, CSR_VSIP)
 DECLARE_CSR(vstimecmp, CSR_VSTIMECMP)
+DECLARE_CSR(vsctrctl, CSR_VSCTRCTL)
 DECLARE_CSR(vsiselect, CSR_VSISELECT)
 DECLARE_CSR(vsireg, CSR_VSIREG)
 DECLARE_CSR(vsireg2, CSR_VSIREG2)
@@ -4163,6 +6932,7 @@ DECLARE_CSR(mtval, CSR_MTVAL)
 DECLARE_CSR(mip, CSR_MIP)
 DECLARE_CSR(mtinst, CSR_MTINST)
 DECLARE_CSR(mtval2, CSR_MTVAL2)
+DECLARE_CSR(mctrctl, CSR_MCTRCTL)
 DECLARE_CSR(miselect, CSR_MISELECT)
 DECLARE_CSR(mireg, CSR_MIREG)
 DECLARE_CSR(mireg2, CSR_MIREG2)
diff --git a/riscv/helpers.h b/riscv/helpers.h
new file mode 100644
index 00000000..4403db4f
--- /dev/null
+++ b/riscv/helpers.h
@@ -0,0 +1,76 @@
+#ifndef HELPERS_HPP
+#define HELPERS_HPP
+
+//#include <bit> C++ 20 :(
+#include <cassert>
+#include <cstdint>
+#include <cstring>  // Include the header for std::memcpy
+#include <type_traits>
+
+#include <algorithm>
+#include <array>
+#include <cstddef> // size_t
+#include <deque>
+#include <iostream>
+#include <memory>
+#include <numeric>
+#include <unordered_map>
+#include <variant>
+#include <vector>
+
+/* Helper to make assert throwing contain a message. Value cond
+  is expected to be an invariant. If it fails, the assert fails */
+#define assert_msg(msg, cond) assert(((void)msg, cond))
+
+template <class>
+inline constexpr bool always_false_v = false;
+
+/* This function helps cast a storage type to a computation type
+  and vice-versa. */
+template <typename Out, typename In>
+Out readAS(In src) {
+    assert_msg("Size mismatch between Out and In types", sizeof(In) == sizeof(Out));
+    // return *reinterpret_cast<Out *>(&src);
+    // return std::bit_cast<Out>(src); C++ 20 :(
+    Out result;
+    std::memcpy(&result, &src, sizeof(Out));
+    return result;
+}
+
+/* The following helpers map the unsigned storage types to the corresponding
+  computation type.
+  WARNING: After many tries and a lot of time spent here, I wasn't able to cause
+  a compilation error if a non supported storage type was given. My implementation
+  was to test each supported case and return a void in other instances; however this
+  helper is used inside a lambda given to a std::visit on a std::variant. As such, I
+  *believe* all possibilities of the helper must be able to instanciante for the
+  code to compile. As defining a variable with type void is impossible the compilation
+  always failed, even with a valid storage type. The final implemantation was to
+  DEFAULT THE COMPUTATION TYPE OF UNTESTED TYPES TO A SINGLE ONE. As such, it is up
+  to the caller to insure only valid and expected types are given */
+template <typename Storage>
+using ComputationTypeFp =
+    std::conditional_t<std::is_same_v<Storage, std::uint32_t>, float,
+                       double>;
+
+template <typename Storage>
+using ComputationTypeSg = std::conditional_t<
+    std::is_same_v<std::uint8_t, Storage>, std::int8_t,
+    std::conditional_t<
+        std::is_same_v<std::uint16_t, Storage>, std::int16_t,
+        std::conditional_t<std::is_same_v<std::uint32_t, Storage>,
+                           std::int32_t, std::int64_t>>>;
+
+template <typename Storage>
+using ComputationTypeUs = Storage;
+
+/* Copied from cppreference as it provides a generic overloaded visitor implementation  */
+template <class... Ts>
+struct overloaded : Ts... {
+    using Ts::operator()...;
+};
+// explicit deduction guide (not needed as of C++20)
+template <class... Ts>
+overloaded(Ts...) -> overloaded<Ts...>;
+
+#endif // HELPERS_HPP
\ No newline at end of file
diff --git a/riscv/insns/so_a_abs_fp.h b/riscv/insns/so_a_abs_fp.h
new file mode 100644
index 00000000..303b39e9
--- /dev/null
+++ b/riscv/insns/so_a_abs_fp.h
@@ -0,0 +1,50 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred, auto extra) {
+    auto vLen = src.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src.getType() == RegisterConfig::Load;
+
+    auto elements = src.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = src.getValidElements();
+
+    auto pi = pred.getPredicate();
+
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i+1)*sizeof(OperationType)-1))
+                out.at(i) = readAS<StorageType>(std::abs(readAS<OperationType>(elements.at(i))));
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+// If the destination register is not configured, we have to build it before the operation so that its element size matches before any calculations are done
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.abs.fp with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+    [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg, double{}); },
+    [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg, float{}); },
+    [&](auto &dest, auto &src) { assert_msg("Invoking so.a.abs.fp with invalid parameter sizes", false); }
+}, destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_abs_sg.h b/riscv/insns/so_a_abs_sg.h
new file mode 100644
index 00000000..7ddfa15d
--- /dev/null
+++ b/riscv/insns/so_a_abs_sg.h
@@ -0,0 +1,58 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred, auto extra) {
+    auto vLen = src.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src.getType() == RegisterConfig::Load;
+
+    auto elements = src.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = src.getValidElements();
+
+    auto pi = pred.getPredicate();
+
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i+1)*sizeof(OperationType)-1))
+                out.at(i) = readAS<StorageType>(std::abs(readAS<OperationType>(elements.at(i))));
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+// If the destination register is not configured, we have to build it before the operation so that its element size matches before any calculations are done
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.abs.sg with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+    [&](StreamReg8 &dest, StreamReg8 &src) { baseBehaviour(dest, src, predReg, (signed char){}); },
+    [&](StreamReg16 &dest, StreamReg16 &src) { baseBehaviour(dest, src, predReg, (short int){}); },
+    [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg, int{}); },
+    [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg, (long int){}); },
+    [&](auto &dest, auto &src) { assert_msg("Invoking so.a.abs.sg with invalid parameter sizes", false); }
+}, destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_add_fp.h b/riscv/insns/so_a_add_fp.h
new file mode 100644
index 00000000..705de697
--- /dev/null
+++ b/riscv/insns/so_a_add_fp.h
@@ -0,0 +1,71 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar || src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = dest.getElements(false); // for merging predication
+
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                out.at(i) = readAS<StorageType>(OperationType(e1 + e2));
+                //std::cout << "ADD   " << e1 << " + " << e2 << " = " << readAS<OperationType>(out.at(i)) << "\n";
+                /* create string  object with the values of the elements
+                std::string str = "ADD  " + std::to_string(e1) + " + " + std::to_string(e2) + " = " + std::to_string(readAS<OperationType>(out.at(i))) + "\n";
+                // to char array
+                char char_array[str.length() + 1];
+                strcpy(char_array, str.c_str());
+                dest.printRegN(char_array);*/
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //std::cout << "ADD END\n\n";
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.add.fp with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, double{}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, float{}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.add.fp with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_add_sg.h b/riscv/insns/so_a_add_sg.h
new file mode 100644
index 00000000..ffb0e3ab
--- /dev/null
+++ b/riscv/insns/so_a_add_sg.h
@@ -0,0 +1,72 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = dest.getElements(false); // for merging predication
+
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                out.at(i) = readAS<StorageType>(OperationType(e1 + e2));
+                //std::cout << "ADD   " << e1 << " + " << e2 << " = " << readAS<OperationType>(out.at(i)) << "\n";
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.add.sg with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src1, StreamReg8 &src2) { baseBehaviour(dest, src1, src2, predReg, (signed char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src1, StreamReg16 &src2) { baseBehaviour(dest, src1, src2, predReg, (short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, int{}); },
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, (long int){}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.add.sg with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_add_us.h b/riscv/insns/so_a_add_us.h
new file mode 100644
index 00000000..18405dcc
--- /dev/null
+++ b/riscv/insns/so_a_add_us.h
@@ -0,0 +1,72 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = dest.getElements(false); // for merging predication
+
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                out.at(i) = readAS<StorageType>(OperationType(e1 + e2));
+                //std::cout << "ADD   " << e1 << " + " << e2 << " = " << readAS<OperationType>(out.at(i)) << "\n";
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.add.us with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src1, StreamReg8 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src1, StreamReg16 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned int){}); },
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned long int){}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.add.us with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_adde_acc_fp.h b/riscv/insns/so_a_adde_acc_fp.h
new file mode 100644
index 00000000..880a7a45
--- /dev/null
+++ b/riscv/insns/so_a_adde_acc_fp.h
@@ -0,0 +1,51 @@
+// std::cout << "\n---ADDE---" << "\n";
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred, auto extra) {
+    auto elements = src.getElements();
+    auto destElements = dest.getElements(false);
+    auto pi = pred.getPredicate();
+    auto validElementsIndex = src.getValidElements();
+
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+
+    OperationType value = readAS<OperationType>(destElements.at(0));
+
+    //std::cout << "ADDE dest: " << (double)(destElements.at(0)) << "\n";
+
+    std::vector<StorageType> out = destElements; // ??
+
+    for (size_t i = 0; i < validElementsIndex; i++) {
+        if (pi.at((i+1)*sizeof(OperationType)-1))
+            value += readAS<OperationType>(elements.at(i));
+    }
+    //std::cout << "ADDE   " << value << "\n";
+    out.at(0) = readAS<StorageType>(value);
+    dest.setMode(RegisterMode::Scalar);
+    dest.setElements(out);
+};
+
+// If the destination register is not configured, we have to build it before the operation so that its element size matches before any calculations are done
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.adde.acc.fp with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+    [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg, double{}); },
+    [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg, float{}); },
+    [&](auto &dest, auto &src) { assert_msg("Invoking so.a.adde.acc.fp with invalid parameter sizes", false); }
+}, destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_adde_acc_sg.h b/riscv/insns/so_a_adde_acc_sg.h
new file mode 100644
index 00000000..100ba192
--- /dev/null
+++ b/riscv/insns/so_a_adde_acc_sg.h
@@ -0,0 +1,57 @@
+// std::cout << "\n---ADDE---" << "\n";
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred, auto extra) {
+    auto elements = src.getElements();
+    auto destElements = dest.getElements(false);
+    auto pi = pred.getPredicate();
+    auto validElementsIndex = src.getValidElements();
+
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+
+    OperationType value = readAS<OperationType>(destElements.at(0));
+
+    std::vector<StorageType> out = destElements; // ??
+
+    for (size_t i = 0; i < validElementsIndex; i++) {
+        if (pi.at((i+1)*sizeof(OperationType)-1))
+            value += readAS<OperationType>(elements.at(i));
+    }
+    //std::cout << "ADDE   " << value << "\n";
+    out.at(0) = readAS<StorageType>(value);
+    dest.setMode(RegisterMode::Scalar);
+    dest.setElements(out);
+};
+
+// If the destination register is not configured, we have to build it before the operation so that its element size matches before any calculations are done
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.adde.acc.sg with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+    [&](StreamReg8 &dest, StreamReg8 &src) { baseBehaviour(dest, src, predReg, (signed char){}); },
+    [&](StreamReg16 &dest, StreamReg16 &src) { baseBehaviour(dest, src, predReg, (short int){}); },
+    [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg, int{}); },
+    [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg, (long int){}); },
+    [&](auto &dest, auto &src) { assert_msg("Invoking so.a.adde.acc.sg with invalid parameter sizes", false); }
+}, destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_adde_acc_us.h b/riscv/insns/so_a_adde_acc_us.h
new file mode 100644
index 00000000..9ae9bbcb
--- /dev/null
+++ b/riscv/insns/so_a_adde_acc_us.h
@@ -0,0 +1,56 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred, auto extra) {
+    auto elements = src.getElements();
+    auto destElements = dest.getElements(false);
+    auto pi = pred.getPredicate();
+    auto validElementsIndex = src.getValidElements();
+
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+
+    OperationType value = readAS<OperationType>(destElements.at(0));
+
+    std::vector<StorageType> out = destElements; // ??
+
+    for (size_t i = 0; i < validElementsIndex; i++) {
+        if (pi.at((i+1)*sizeof(OperationType)-1))
+            value += readAS<OperationType>(elements.at(i));
+    }
+    //std::cout << "ADDE   " << value << "\n";
+    out.at(0) = readAS<StorageType>(value);
+    dest.setMode(RegisterMode::Scalar);
+    dest.setElements(out);
+};
+
+// If the destination register is not configured, we have to build it before the operation so that its element size matches before any calculations are done
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.adde.acc.us with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+    [&](StreamReg8 &dest, StreamReg8 &src) { baseBehaviour(dest, src, predReg, (unsigned char){}); },
+    [&](StreamReg16 &dest, StreamReg16 &src) { baseBehaviour(dest, src, predReg, (unsigned short int){}); },
+    [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg, (unsigned int){}); },
+    [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg, (unsigned long int){}); },
+    [&](auto &dest, auto &src) { assert_msg("Invoking so.a.adde.acc.us with invalid parameter sizes", false); }
+}, destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_adde_fp.h b/riscv/insns/so_a_adde_fp.h
new file mode 100644
index 00000000..fef53cb8
--- /dev/null
+++ b/riscv/insns/so_a_adde_fp.h
@@ -0,0 +1,49 @@
+// std::cout << "\n---ADDE---" << "\n";
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred, auto extra) {
+    auto elements = src.getElements();
+    auto destElements = dest.getElements(false);
+    auto pi = pred.getPredicate();
+    auto validElementsIndex = src.getValidElements();
+
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+
+    OperationType value = 0;
+
+    std::vector<StorageType> out = destElements; // ??
+
+    for (size_t i = 0; i < validElementsIndex; i++) {
+        if (pi.at((i+1)*sizeof(OperationType)-1))
+            value += readAS<OperationType>(elements.at(i));
+    }
+    //std::cout << "ADDE  " << value << "\n";
+    out.at(0) = readAS<StorageType>(value);
+    dest.setMode(RegisterMode::Scalar);
+    dest.setElements(out);
+};
+
+// If the destination register is not configured, we have to build it before the operation so that its element size matches before any calculations are done
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.adde.fp with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+    [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg, double{}); },
+    [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg, float{}); },
+    [&](auto &dest, auto &src) { assert_msg("Invoking so.a.adde.fp with invalid parameter sizes", false); }
+}, destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_adde_sg.h b/riscv/insns/so_a_adde_sg.h
new file mode 100644
index 00000000..47a753c8
--- /dev/null
+++ b/riscv/insns/so_a_adde_sg.h
@@ -0,0 +1,57 @@
+// std::cout << "\n---ADDE---" << "\n";
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred, auto extra) {
+    auto elements = src.getElements();
+    auto destElements = dest.getElements(false);
+    auto pi = pred.getPredicate();
+    auto validElementsIndex = src.getValidElements();
+
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+
+    OperationType value = 0;
+
+    std::vector<StorageType> out = destElements; // ??
+
+    for (size_t i = 0; i < validElementsIndex; i++) {
+        if (pi.at((i+1)*sizeof(OperationType)-1))
+            value += readAS<OperationType>(elements.at(i));
+    }
+    //std::cout << "ADDE   " << value << "\n";
+    out.at(0) = readAS<StorageType>(value);
+    dest.setMode(RegisterMode::Scalar);
+    dest.setElements(out);
+};
+
+// If the destination register is not configured, we have to build it before the operation so that its element size matches before any calculations are done
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.adde.sg with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+    [&](StreamReg8 &dest, StreamReg8 &src) { baseBehaviour(dest, src, predReg, (signed char){}); },
+    [&](StreamReg16 &dest, StreamReg16 &src) { baseBehaviour(dest, src, predReg, (short int){}); },
+    [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg, int{}); },
+    [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg, (long int){}); },
+    [&](auto &dest, auto &src) { assert_msg("Invoking so.a.adde.sg with invalid parameter sizes", false); }
+}, destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_adde_us.h b/riscv/insns/so_a_adde_us.h
new file mode 100644
index 00000000..4a4414f3
--- /dev/null
+++ b/riscv/insns/so_a_adde_us.h
@@ -0,0 +1,56 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred, auto extra) {
+    auto elements = src.getElements();
+    auto destElements = dest.getElements(false);
+    auto pi = pred.getPredicate();
+    auto validElementsIndex = src.getValidElements();
+
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+
+    OperationType value = 0;
+
+    std::vector<StorageType> out = destElements; // ??
+
+    for (size_t i = 0; i < validElementsIndex; i++) {
+        if (pi.at((i+1)*sizeof(OperationType)-1))
+            value += readAS<OperationType>(elements.at(i));
+    }
+    //std::cout << "ADDE   " << value << "\n";
+    out.at(0) = readAS<StorageType>(value);
+    dest.setMode(RegisterMode::Scalar);
+    dest.setElements(out);
+};
+
+// If the destination register is not configured, we have to build it before the operation so that its element size matches before any calculations are done
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.adde.us with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+    [&](StreamReg8 &dest, StreamReg8 &src) { baseBehaviour(dest, src, predReg, (unsigned char){}); },
+    [&](StreamReg16 &dest, StreamReg16 &src) { baseBehaviour(dest, src, predReg, (unsigned short int){}); },
+    [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg, (unsigned int){}); },
+    [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg, (unsigned long int){}); },
+    [&](auto &dest, auto &src) { assert_msg("Invoking so.a.adde.us with invalid parameter sizes", false); }
+}, destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_adds_acc_fp.h b/riscv/insns/so_a_adds_acc_fp.h
new file mode 100644
index 00000000..1db18014
--- /dev/null
+++ b/riscv/insns/so_a_adds_acc_fp.h
@@ -0,0 +1,29 @@
+auto destReg = insn.uve_rd();
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &value, auto &src, auto &pred, auto extra) {
+    auto elements = src.getElements();
+    auto pi = pred.getPredicate();
+    auto validElementsIndex = src.getValidElements();
+
+    using OperationType = decltype(extra);
+    using StorageType = typename std::remove_reference_t<decltype(value)>;
+
+    OperationType acc = readAS<OperationType>(value);
+
+    for (size_t i = 0; i < validElementsIndex; i++) {
+        if (pi.at((i+1)*sizeof(OperationType)-1)){
+            acc += readAS<OperationType>(elements.at(i));
+        }
+    }
+
+    value = readAS<StorageType>(acc);
+};
+
+std::visit(overloaded{
+    [&](StreamReg64 &src) { auto value = READ_FREG_D(destReg); baseBehaviour(value, src, predReg, double{}); WRITE_FREG(destReg, value); },
+    [&](StreamReg32 &src) { auto value = READ_FREG_F(destReg); baseBehaviour(value, src, predReg, float{}); WRITE_FREG(destReg, value);},
+    [&](auto &src) { assert_msg("Invoking so.a.adds.acc.fp with invalid parameter sizes", false); }
+}, srcReg);
diff --git a/riscv/insns/so_a_adds_acc_sg.h b/riscv/insns/so_a_adds_acc_sg.h
new file mode 100644
index 00000000..e51a99cb
--- /dev/null
+++ b/riscv/insns/so_a_adds_acc_sg.h
@@ -0,0 +1,30 @@
+auto destReg = insn.uve_rd();
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &value, auto &src, auto &pred, auto extra) {
+    auto elements = src.getElements();
+    auto pi = pred.getPredicate();
+    auto validElementsIndex = src.getValidElements();
+
+    using OperationType = decltype(extra);
+    using StorageType = typename std::remove_reference_t<decltype(value)>;
+
+    OperationType acc = readAS<OperationType>(value);
+
+    for (size_t i = 0; i < validElementsIndex; i++) {
+        if (pi.at((i+1)*sizeof(OperationType)-1))
+            acc += readAS<OperationType>(elements.at(i));
+    }
+
+    value = readAS<StorageType>(acc);
+};
+
+std::visit(overloaded{
+    [&](StreamReg8 &src) { uint8_t value = READ_REG(destReg); baseBehaviour(value, src, predReg, (signed char){}); WRITE_REG(destReg, value); },
+    [&](StreamReg16 &src) { uint16_t value = READ_REG(destReg); baseBehaviour(value, src, predReg, (short int){}); WRITE_REG(destReg, value); },
+    [&](StreamReg32 &src) { uint32_t value = READ_REG(destReg); baseBehaviour(value, src, predReg, int{}); WRITE_REG(destReg, value); },
+    [&](StreamReg64 &src) { uint64_t value = READ_REG(destReg); baseBehaviour(value, src, predReg, (long int){}); WRITE_REG(destReg, value); },
+    [&](auto &src) { assert_msg("Invoking so.a.adds.acc.sg with invalid parameter sizes", false); }
+}, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_adds_acc_us.h b/riscv/insns/so_a_adds_acc_us.h
new file mode 100644
index 00000000..f7a9d563
--- /dev/null
+++ b/riscv/insns/so_a_adds_acc_us.h
@@ -0,0 +1,30 @@
+auto destReg = insn.uve_rd();
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &value, auto &src, auto &pred, auto extra) {
+    auto elements = src.getElements();
+    auto pi = pred.getPredicate();
+    auto validElementsIndex = src.getValidElements();
+
+    using OperationType = decltype(extra);
+    using StorageType = typename std::remove_reference_t<decltype(value)>;
+
+    OperationType acc = readAS<OperationType>(value);
+
+    for (size_t i = 0; i < validElementsIndex; i++) {
+        if (pi.at((i+1)*sizeof(OperationType)-1))
+            acc += readAS<OperationType>(elements.at(i));
+    }
+
+    value = readAS<StorageType>(acc);
+};
+
+std::visit(overloaded{
+    [&](StreamReg8 &src) { uint8_t value = READ_REG(destReg); baseBehaviour(value, src, predReg, (unsigned char){}); WRITE_REG(destReg, value); },
+    [&](StreamReg16 &src) { uint16_t value = READ_REG(destReg); baseBehaviour(value, src, predReg, (unsigned short int){}); WRITE_REG(destReg, value); },
+    [&](StreamReg32 &src) { uint32_t value = READ_REG(destReg); baseBehaviour(value, src, predReg, (unsigned int){}); WRITE_REG(destReg, value); },
+    [&](StreamReg64 &src) { uint64_t value = READ_REG(destReg); baseBehaviour(value, src, predReg, (unsigned long int){}); WRITE_REG(destReg, value); },
+    [&](auto &src) { assert_msg("Invoking so.a.adds.acc.us with invalid parameter sizes", false); }
+}, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_adds_fp.h b/riscv/insns/so_a_adds_fp.h
new file mode 100644
index 00000000..d488730a
--- /dev/null
+++ b/riscv/insns/so_a_adds_fp.h
@@ -0,0 +1,27 @@
+auto destReg = insn.uve_rd();
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &value, auto &src, auto &pred, auto extra) {
+    auto elements = src.getElements();
+    auto pi = pred.getPredicate();
+    auto validElementsIndex = src.getValidElements();
+
+    using OperationType = decltype(extra);
+    using StorageType = typename std::remove_reference_t<decltype(src)>::ElementsType;
+
+    OperationType acc = 0;
+
+    for (size_t i = 0; i < validElementsIndex; i++)
+        if (pi.at((i+1)*sizeof(OperationType)-1))
+            acc += readAS<OperationType>(elements.at(i));
+
+    value = readAS<StorageType>(acc);
+};
+
+std::visit(overloaded{
+    [&](StreamReg64 &src) { uint64_t value = 0; baseBehaviour(value, src, predReg, double{}); WRITE_REG(destReg, value); },
+    [&](StreamReg32 &src) { uint32_t value = 0; baseBehaviour(value, src, predReg, float{}); WRITE_REG(destReg, value);},
+    [&](auto &src) { assert_msg("Invoking so.a.adds.fp with invalid parameter sizes", false); }
+}, srcReg);
diff --git a/riscv/insns/so_a_adds_sg.h b/riscv/insns/so_a_adds_sg.h
new file mode 100644
index 00000000..bb915218
--- /dev/null
+++ b/riscv/insns/so_a_adds_sg.h
@@ -0,0 +1,30 @@
+auto destReg = insn.uve_rd();
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &value, auto &src, auto &pred, auto extra) {
+    auto elements = src.getElements();
+    auto pi = pred.getPredicate();
+    auto validElementsIndex = src.getValidElements();
+
+    using OperationType = decltype(extra);
+    using StorageType = typename std::remove_reference_t<decltype(src)>::ElementsType;
+
+    OperationType acc = 0;
+
+    for (size_t i = 0; i < validElementsIndex; i++) {
+        if (pi.at((i+1)*sizeof(OperationType)-1))
+            acc += readAS<OperationType>(elements.at(i));
+    }
+
+    value = readAS<StorageType>(acc);
+};
+
+std::visit(overloaded{
+    [&](StreamReg8 &src) { uint8_t value = 0; baseBehaviour(destReg, src, predReg, (signed char){}); WRITE_REG(destReg, value); },
+    [&](StreamReg16 &src) { uint16_t value = 0; baseBehaviour(destReg, src, predReg, (short int){}); WRITE_REG(destReg, value); },
+    [&](StreamReg32 &src) { uint32_t value = 0; baseBehaviour(destReg, src, predReg, int{}); WRITE_REG(destReg, value); },
+    [&](StreamReg64 &src) { uint64_t value = 0; baseBehaviour(destReg, src, predReg, (long int){}); WRITE_REG(destReg, value); },
+    [&](auto &src) { assert_msg("Invoking so.a.adds.sg with invalid parameter sizes", false); }
+}, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_adds_us.h b/riscv/insns/so_a_adds_us.h
new file mode 100644
index 00000000..1edfacea
--- /dev/null
+++ b/riscv/insns/so_a_adds_us.h
@@ -0,0 +1,30 @@
+auto destReg = insn.uve_rd();
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &value, auto &src, auto &pred, auto extra) {
+    auto elements = src.getElements();
+    auto pi = pred.getPredicate();
+    auto validElementsIndex = src.getValidElements();
+
+    using OperationType = decltype(extra);
+    using StorageType = typename std::remove_reference_t<decltype(src)>::ElementsType;
+
+    OperationType acc = 0;
+
+    for (size_t i = 0; i < validElementsIndex; i++) {
+        if (pi.at((i+1)*sizeof(OperationType)-1))
+            acc += readAS<OperationType>(elements.at(i));
+    }
+
+    value = readAS<StorageType>(acc);
+};
+
+std::visit(overloaded{
+    [&](StreamReg8 &src) { uint8_t value = 0; baseBehaviour(destReg, src, predReg, (unsigned char){}); WRITE_REG(destReg, value); },
+    [&](StreamReg16 &src) { uint16_t value = 0; baseBehaviour(destReg, src, predReg, (unsigned short int){}); WRITE_REG(destReg, value); },
+    [&](StreamReg32 &src) { uint32_t value = 0; baseBehaviour(destReg, src, predReg, (unsigned int){}); WRITE_REG(destReg, value); },
+    [&](StreamReg64 &src) { uint64_t value = 0; baseBehaviour(destReg, src, predReg, (unsigned long int){}); WRITE_REG(destReg, value); },
+    [&](auto &src) { assert_msg("Invoking so.a.adds.us with invalid parameter sizes", false); }
+}, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_and.h b/riscv/insns/so_a_and.h
new file mode 100644
index 00000000..bdea9077
--- /dev/null
+++ b/riscv/insns/so_a_and.h
@@ -0,0 +1,75 @@
+
+
+
+
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                out.at(i) = readAS<StorageType>(e1 & e2);
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.and with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src1, StreamReg8 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src1, StreamReg16 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned int){}); },
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned long int){}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.and with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_dec_fp.h b/riscv/insns/so_a_dec_fp.h
new file mode 100644
index 00000000..09e8a18d
--- /dev/null
+++ b/riscv/insns/so_a_dec_fp.h
@@ -0,0 +1,53 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred, auto extra) {
+    auto vLen = src.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src.getType() == RegisterConfig::Load;
+
+    auto elements = src.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = src.getValidElements();
+    auto pi = pred.getPredicate();
+
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i+1)*sizeof(OperationType)-1)){
+                OperationType e = readAS<OperationType>(elements.at(i)) - 1.0;
+                out.at(i) = readAS<StorageType>(e);
+            }
+        } else
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+// If the destination register is not configured, we have to build it before the operation so that its element size matches before any calculations are done
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.maxe.fp with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+    [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg, double{}); },
+    [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg, float{}); },
+    [&](auto &dest, auto &src) { assert_msg("Invoking so.a.maxe.fp with invalid parameter sizes", false); }
+}, destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_dec_sg.h b/riscv/insns/so_a_dec_sg.h
new file mode 100644
index 00000000..93670b7f
--- /dev/null
+++ b/riscv/insns/so_a_dec_sg.h
@@ -0,0 +1,61 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred, auto extra) {
+    auto vLen = src.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src.getType() == RegisterConfig::Load;
+
+    auto elements = src.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = src.getValidElements();
+    auto pi = pred.getPredicate();
+
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i+1)*sizeof(OperationType)-1)){
+                OperationType e = readAS<OperationType>(elements.at(i)) - 1.0;
+                out.at(i) = readAS<StorageType>(e);
+            }
+        } else
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+// If the destination register is not configured, we have to build it before the operation so that its element size matches before any calculations are done
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.maxe.sg with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+    [&](StreamReg8 &dest, StreamReg8 &src) { baseBehaviour(dest, src, predReg, (signed char){}); },
+    [&](StreamReg16 &dest, StreamReg16 &src) { baseBehaviour(dest, src, predReg, (short int){}); },
+    [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg, int{}); },
+    [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg, (long int){}); },
+    [&](auto &dest, auto &src) { assert_msg("Invoking so.a.maxe.sg with invalid parameter sizes", false); }
+}, destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_dec_us.h b/riscv/insns/so_a_dec_us.h
new file mode 100644
index 00000000..1d298212
--- /dev/null
+++ b/riscv/insns/so_a_dec_us.h
@@ -0,0 +1,61 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred, auto extra) {
+    auto vLen = src.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src.getType() == RegisterConfig::Load;
+
+    auto elements = src.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = src.getValidElements();
+    auto pi = pred.getPredicate();
+
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i+1)*sizeof(OperationType)-1)){
+                OperationType e = readAS<OperationType>(elements.at(i)) - 1.0;
+                out.at(i) = readAS<StorageType>(e);
+            }
+        } else
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+// If the destination register is not configured, we have to build it before the operation so that its element size matches before any calculations are done
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.maxe.us with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+    [&](StreamReg8 &dest, StreamReg8 &src) { baseBehaviour(dest, src, predReg, (unsigned char){}); },
+    [&](StreamReg16 &dest, StreamReg16 &src) { baseBehaviour(dest, src, predReg, (unsigned short int){}); },
+    [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg, (unsigned int){}); },
+    [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg, (unsigned long int){}); },
+    [&](auto &dest, auto &src) { assert_msg("Invoking so.a.maxe.us with invalid parameter sizes", false); }
+}, destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_div_fp.h b/riscv/insns/so_a_div_fp.h
new file mode 100644
index 00000000..67698dbc
--- /dev/null
+++ b/riscv/insns/so_a_div_fp.h
@@ -0,0 +1,71 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = dest.getElements(false); // for merging predication
+
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                out.at(i) = readAS<StorageType>(OperationType(e1 / e2));
+                //std::cout << "DIV   " << e1 << " / " << e2 << " = " << readAS<OperationType>(out.at(i)) << "\n";
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            /*operateRegister(P.SU, streamReg, [=](auto& reg) {
+              reg.endConfiguration();
+            });*/
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            /*operateRegister(P.SU, streamReg, [=](auto& reg) {
+              reg.endConfiguration();
+            });*/
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.div.fp with invalid src type", false);
+    }
+},
+           destReg);
+
+std::visit(overloaded{
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, double{}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, float{}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.div.fp with invalid parameter sizes", false); }},
+           destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_div_sg.h b/riscv/insns/so_a_div_sg.h
new file mode 100644
index 00000000..110ad108
--- /dev/null
+++ b/riscv/insns/so_a_div_sg.h
@@ -0,0 +1,72 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = dest.getElements(false); // for merging predication
+
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                out.at(i) = readAS<StorageType>(OperationType(e1 / e2));
+                //std::cout << "DIV   " << e1 << " / " << e2 << " = " << readAS<OperationType>(out.at(i)) << "\n";
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.div.sg with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src1, StreamReg8 &src2) { baseBehaviour(dest, src1, src2, predReg, (signed char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src1, StreamReg16 &src2) { baseBehaviour(dest, src1, src2, predReg, (short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, int{}); },
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, (long int){}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.div.sg with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_div_us.h b/riscv/insns/so_a_div_us.h
new file mode 100644
index 00000000..2ee53677
--- /dev/null
+++ b/riscv/insns/so_a_div_us.h
@@ -0,0 +1,72 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = dest.getElements(false); // for merging predication
+
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                out.at(i) = readAS<StorageType>(OperationType(e1 / e2));
+                //std::cout << "DIV   " << e1 << " / " << e2 << " = " << readAS<OperationType>(out.at(i)) << "\n";
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.div.us with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src1, StreamReg8 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src1, StreamReg16 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned int){}); },
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned long int){}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.div.us with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_inc_fp.h b/riscv/insns/so_a_inc_fp.h
new file mode 100644
index 00000000..c5f8ba76
--- /dev/null
+++ b/riscv/insns/so_a_inc_fp.h
@@ -0,0 +1,53 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred, auto extra) {
+    auto vLen = src.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src.getType() == RegisterConfig::Load;
+
+    auto elements = src.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = src.getValidElements();
+    auto pi = pred.getPredicate();
+
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i+1)*sizeof(OperationType)-1)){
+                OperationType e = readAS<OperationType>(elements.at(i)) + 1.0;
+                out.at(i) = readAS<StorageType>(e);
+            }
+        } else
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+// If the destination register is not configured, we have to build it before the operation so that its element size matches before any calculations are done
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.maxe.fp with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+    [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg, double{}); },
+    [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg, float{}); },
+    [&](auto &dest, auto &src) { assert_msg("Invoking so.a.maxe.fp with invalid parameter sizes", false); }
+}, destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_inc_sg.h b/riscv/insns/so_a_inc_sg.h
new file mode 100644
index 00000000..b12a8565
--- /dev/null
+++ b/riscv/insns/so_a_inc_sg.h
@@ -0,0 +1,61 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred, auto extra) {
+    auto vLen = src.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src.getType() == RegisterConfig::Load;
+
+    auto elements = src.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = src.getValidElements();
+    auto pi = pred.getPredicate();
+
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i+1)*sizeof(OperationType)-1)){
+                OperationType e = readAS<OperationType>(elements.at(i)) + 1.0;
+                out.at(i) = readAS<StorageType>(e);
+            }
+        } else
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+// If the destination register is not configured, we have to build it before the operation so that its element size matches before any calculations are done
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.maxe.sg with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+    [&](StreamReg8 &dest, StreamReg8 &src) { baseBehaviour(dest, src, predReg, (signed char){}); },
+    [&](StreamReg16 &dest, StreamReg16 &src) { baseBehaviour(dest, src, predReg, (short int){}); },
+    [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg, int{}); },
+    [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg, (long int){}); },
+    [&](auto &dest, auto &src) { assert_msg("Invoking so.a.maxe.sg with invalid parameter sizes", false); }
+}, destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_inc_us.h b/riscv/insns/so_a_inc_us.h
new file mode 100644
index 00000000..e9cdb00c
--- /dev/null
+++ b/riscv/insns/so_a_inc_us.h
@@ -0,0 +1,61 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred, auto extra) {
+    auto vLen = src.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src.getType() == RegisterConfig::Load;
+
+    auto elements = src.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = src.getValidElements();
+    auto pi = pred.getPredicate();
+
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i+1)*sizeof(OperationType)-1)){
+                OperationType e = readAS<OperationType>(elements.at(i)) + 1.0;
+                out.at(i) = readAS<StorageType>(e);
+            }
+        } else
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+// If the destination register is not configured, we have to build it before the operation so that its element size matches before any calculations are done
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.maxe.us with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+    [&](StreamReg8 &dest, StreamReg8 &src) { baseBehaviour(dest, src, predReg, (unsigned char){}); },
+    [&](StreamReg16 &dest, StreamReg16 &src) { baseBehaviour(dest, src, predReg, (unsigned short int){}); },
+    [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg, (unsigned int){}); },
+    [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg, (unsigned long int){}); },
+    [&](auto &dest, auto &src) { assert_msg("Invoking so.a.maxe.us with invalid parameter sizes", false); }
+}, destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_mac_fp.h b/riscv/insns/so_a_mac_fp.h
new file mode 100644
index 00000000..89d3588b
--- /dev/null
+++ b/riscv/insns/so_a_mac_fp.h
@@ -0,0 +1,86 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = dest.getElements(false);
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = destElements; // for merging predication
+
+    /* print elements1
+    std::cout << "elements1: ";
+    for (auto e : elements1) {
+        std::cout << readAS<float>(e) << " ";
+    }
+    std::cout << std::endl;
+    // print elements2
+    std::cout << "elements2: ";
+    for (auto e : elements2) {
+        std::cout << readAS<float>(e) << " ";
+    }
+    std::cout << std::endl;
+    // print elements3
+    std::cout << "destElements: ";
+    for (auto e : destElements) {
+        std::cout << readAS<float>(e) << " ";
+    }
+    std::cout << std::endl;
+    */
+
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                auto e3 = readAS<OperationType>(destElements.at(i));
+                out.at(i) = readAS<StorageType>(e1 * e2 + e3);
+                //std::cout << "MAC   e1: " << e1 << " e2: " << e2 << " e3: " << e3 << " result: " << readAS<OperationType>(out.at(i)) << std::endl;
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.mac.fp with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, double{}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, float{}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.mac.fp with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_mac_sg.h b/riscv/insns/so_a_mac_sg.h
new file mode 100644
index 00000000..cf3ae2af
--- /dev/null
+++ b/riscv/insns/so_a_mac_sg.h
@@ -0,0 +1,74 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = dest.getElements(false);
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = destElements; // for merging predication
+
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                auto e3 = readAS<OperationType>(destElements.at(i));
+                out.at(i) = readAS<StorageType>(e1 * e2 + e3);
+                //std::cout << "MAC   e1: " << e1 << " e2: " << e2 << " e3: " << e3 << " result: " << readAS<OperationType>(out.at(i)) << std::endl;
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.mac.sg with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src1, StreamReg8 &src2) { baseBehaviour(dest, src1, src2, predReg, (signed char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src1, StreamReg16 &src2) { baseBehaviour(dest, src1, src2, predReg, (short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, int{}); },
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, (long int){}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.mac.sg with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_mac_us.h b/riscv/insns/so_a_mac_us.h
new file mode 100644
index 00000000..9ee9c8b5
--- /dev/null
+++ b/riscv/insns/so_a_mac_us.h
@@ -0,0 +1,74 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = dest.getElements(false);
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = destElements; // for merging predication
+
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                auto e3 = readAS<OperationType>(destElements.at(i));
+                out.at(i) = readAS<StorageType>(e1 * e2 + e3);
+                //std::cout << "MAC   e1: " << e1 << " e2: " << e2 << " e3: " << e3 << " result: " << readAS<OperationType>(out.at(i)) << std::endl;
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.mac.us with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src1, StreamReg8 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src1, StreamReg16 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned int){}); },
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned long int){}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.mac.us with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_max_fp.h b/riscv/insns/so_a_max_fp.h
new file mode 100644
index 00000000..46bbcaf8
--- /dev/null
+++ b/riscv/insns/so_a_max_fp.h
@@ -0,0 +1,61 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1))
+                out.at(i) = readAS<StorageType>(std::max(readAS<OperationType>(elements1.at(i)), readAS<OperationType>(elements2.at(i))));
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(dest.getVLen() == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.max.fp with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, double{}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, float{}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.max.fp with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_max_sg.h b/riscv/insns/so_a_max_sg.h
new file mode 100644
index 00000000..6e8bda50
--- /dev/null
+++ b/riscv/insns/so_a_max_sg.h
@@ -0,0 +1,68 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1))
+                out.at(i) = readAS<StorageType>(std::max(readAS<OperationType>(elements1.at(i)), readAS<OperationType>(elements2.at(i))));
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(dest.getVLen() == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.max.sg with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src1, StreamReg8 &src2) { baseBehaviour(dest, src1, src2, predReg, (signed char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src1, StreamReg16 &src2) { baseBehaviour(dest, src1, src2, predReg, (short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, int{}); },
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, (long int){}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.max.sg with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_max_us.h b/riscv/insns/so_a_max_us.h
new file mode 100644
index 00000000..a0412e50
--- /dev/null
+++ b/riscv/insns/so_a_max_us.h
@@ -0,0 +1,68 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1))
+                out.at(i) = readAS<StorageType>(std::max(readAS<OperationType>(elements1.at(i)), readAS<OperationType>(elements2.at(i))));
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(dest.getVLen() == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.max.us with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src1, StreamReg8 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src1, StreamReg16 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned int){}); },
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned long int){}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.max.us with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_maxe_fp.h b/riscv/insns/so_a_maxe_fp.h
new file mode 100644
index 00000000..c6a29d29
--- /dev/null
+++ b/riscv/insns/so_a_maxe_fp.h
@@ -0,0 +1,50 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred, auto extra) {
+    auto elements = src.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = src.getValidElements();
+    auto pi = pred.getPredicate();
+
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+
+    auto value = std::numeric_limits<OperationType>::min();
+
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < validElementsIndex; i++) {
+        if (pi.at((i+1)*sizeof(OperationType)-1)){
+            OperationType e = readAS<OperationType>(elements.at(i));
+            if (e > value)
+                value = e;
+        }
+    }
+    out.at(0) = readAS<StorageType>(value);
+    dest.setMode(RegisterMode::Scalar);
+    dest.setElements(out);
+};
+
+// If the destination register is not configured, we have to build it before the operation so that its element size matches before any calculations are done
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.maxe.fp with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+    [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg, double{}); },
+    [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg, float{}); },
+    [&](auto &dest, auto &src) { assert_msg("Invoking so.a.maxe.fp with invalid parameter sizes", false); }
+}, destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_maxe_sg.h b/riscv/insns/so_a_maxe_sg.h
new file mode 100644
index 00000000..e36ab002
--- /dev/null
+++ b/riscv/insns/so_a_maxe_sg.h
@@ -0,0 +1,58 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred, auto extra) {
+    auto elements = src.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = src.getValidElements();
+    auto pi = pred.getPredicate();
+
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+
+    auto value = std::numeric_limits<OperationType>::min();
+
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < validElementsIndex; i++) {
+        if (pi.at((i+1)*sizeof(OperationType)-1)){
+            OperationType e = readAS<OperationType>(elements.at(i));
+            if (e > value)
+                value = e;
+        }
+    }
+    out.at(0) = readAS<StorageType>(value);
+    dest.setMode(RegisterMode::Scalar);
+    dest.setElements(out);
+};
+
+// If the destination register is not configured, we have to build it before the operation so that its element size matches before any calculations are done
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.maxe.sg with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+    [&](StreamReg8 &dest, StreamReg8 &src) { baseBehaviour(dest, src, predReg, (signed char){}); },
+    [&](StreamReg16 &dest, StreamReg16 &src) { baseBehaviour(dest, src, predReg, (short int){}); },
+    [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg, int{}); },
+    [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg, (long int){}); },
+    [&](auto &dest, auto &src) { assert_msg("Invoking so.a.maxe.sg with invalid parameter sizes", false); }
+}, destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_maxe_us.h b/riscv/insns/so_a_maxe_us.h
new file mode 100644
index 00000000..5e2a107b
--- /dev/null
+++ b/riscv/insns/so_a_maxe_us.h
@@ -0,0 +1,58 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred, auto extra) {
+    auto elements = src.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = src.getValidElements();
+    auto pi = pred.getPredicate();
+
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+
+    auto value = std::numeric_limits<OperationType>::min();
+
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < validElementsIndex; i++) {
+        if (pi.at((i+1)*sizeof(OperationType)-1)){
+            OperationType e = readAS<OperationType>(elements.at(i));
+            if (e > value)
+                value = e;
+        }
+    }
+    out.at(0) = readAS<StorageType>(value);
+    dest.setMode(RegisterMode::Scalar);
+    dest.setElements(out);
+};
+
+// If the destination register is not configured, we have to build it before the operation so that its element size matches before any calculations are done
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.maxe.us with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+    [&](StreamReg8 &dest, StreamReg8 &src) { baseBehaviour(dest, src, predReg, (unsigned char){}); },
+    [&](StreamReg16 &dest, StreamReg16 &src) { baseBehaviour(dest, src, predReg, (unsigned short int){}); },
+    [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg, (unsigned int){}); },
+    [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg, (unsigned long int){}); },
+    [&](auto &dest, auto &src) { assert_msg("Invoking so.a.maxe.us with invalid parameter sizes", false); }
+}, destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_min_fp.h b/riscv/insns/so_a_min_fp.h
new file mode 100644
index 00000000..36a88a3d
--- /dev/null
+++ b/riscv/insns/so_a_min_fp.h
@@ -0,0 +1,59 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    auto vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1))
+                out.at(i) = readAS<StorageType>(std::min(readAS<OperationType>(elements1.at(i)), readAS<OperationType>(elements2.at(i))));
+        }   else
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(dest.getVLen() == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.min.fp with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, double{}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, float{}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.min.fp with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_min_sg.h b/riscv/insns/so_a_min_sg.h
new file mode 100644
index 00000000..f136bcf6
--- /dev/null
+++ b/riscv/insns/so_a_min_sg.h
@@ -0,0 +1,67 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    auto vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1))
+                out.at(i) = readAS<StorageType>(std::min(readAS<OperationType>(elements1.at(i)), readAS<OperationType>(elements2.at(i))));
+        }   else
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(dest.getVLen() == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.min.sg with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src1, StreamReg8 &src2) { baseBehaviour(dest, src1, src2, predReg, (signed char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src1, StreamReg16 &src2) { baseBehaviour(dest, src1, src2, predReg, (short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, int{}); },
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, (long int){}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.min.sg with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_min_us.h b/riscv/insns/so_a_min_us.h
new file mode 100644
index 00000000..dc3e8463
--- /dev/null
+++ b/riscv/insns/so_a_min_us.h
@@ -0,0 +1,67 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    auto vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1))
+                out.at(i) = readAS<StorageType>(std::min(readAS<OperationType>(elements1.at(i)), readAS<OperationType>(elements2.at(i))));
+        }   else
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(dest.getVLen() == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.min.us with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src1, StreamReg8 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src1, StreamReg16 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned int){}); },
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned long int){}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.min.us with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_mine_fp.h b/riscv/insns/so_a_mine_fp.h
new file mode 100644
index 00000000..7d705cb9
--- /dev/null
+++ b/riscv/insns/so_a_mine_fp.h
@@ -0,0 +1,50 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred, auto extra) {
+    auto elements = src.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = src.getValidElements();
+    auto pi = pred.getPredicate();
+
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+
+    auto value = std::numeric_limits<OperationType>::max();
+
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < validElementsIndex; i++) {
+        if (pi.at((i+1)*sizeof(OperationType)-1)){
+            OperationType e = readAS<OperationType>(elements.at(i));
+            if (e < value)
+                value = e;
+        }
+    }
+    out.at(0) = readAS<StorageType>(value);
+    dest.setMode(RegisterMode::Scalar);
+    dest.setElements(out);
+};
+
+// If the destination register is not configured, we have to build it before the operation so that its element size matches before any calculations are done
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.mine.fp with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+    [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg, double{}); },
+    [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg, float{}); },
+    [&](auto &dest, auto &src) { assert_msg("Invoking so.a.mine.fp with invalid parameter sizes", false); }
+}, destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_mine_sg.h b/riscv/insns/so_a_mine_sg.h
new file mode 100644
index 00000000..81ce7c88
--- /dev/null
+++ b/riscv/insns/so_a_mine_sg.h
@@ -0,0 +1,58 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred, auto extra) {
+    auto elements = src.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = src.getValidElements();
+    auto pi = pred.getPredicate();
+
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+
+    auto value = std::numeric_limits<OperationType>::max();
+
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < validElementsIndex; i++) {
+        if (pi.at((i+1)*sizeof(OperationType)-1)){
+            OperationType e = readAS<OperationType>(elements.at(i));
+            if (e < value)
+                value = e;
+        }
+    }
+    out.at(0) = readAS<StorageType>(value);
+    dest.setMode(RegisterMode::Scalar);
+    dest.setElements(out);
+};
+
+// If the destination register is not configured, we have to build it before the operation so that its element size matches before any calculations are done
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.mine.sg with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+    [&](StreamReg8 &dest, StreamReg8 &src) { baseBehaviour(dest, src, predReg, (signed char){}); },
+    [&](StreamReg16 &dest, StreamReg16 &src) { baseBehaviour(dest, src, predReg, (short int){}); },
+    [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg, int{}); },
+    [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg, (long int){}); },
+    [&](auto &dest, auto &src) { assert_msg("Invoking so.a.mine.sg with invalid parameter sizes", false); }
+}, destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_mine_us.h b/riscv/insns/so_a_mine_us.h
new file mode 100644
index 00000000..eec0f9b2
--- /dev/null
+++ b/riscv/insns/so_a_mine_us.h
@@ -0,0 +1,58 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to later on infer its type and know the storage we need to use
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred, auto extra) {
+    auto elements = src.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = src.getValidElements();
+    auto pi = pred.getPredicate();
+
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+
+    auto value = std::numeric_limits<OperationType>::max();
+
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < validElementsIndex; i++) {
+        if (pi.at((i+1)*sizeof(OperationType)-1)){
+            OperationType e = readAS<OperationType>(elements.at(i));
+            if (e < value)
+                value = e;
+        }
+    }
+    out.at(0) = readAS<StorageType>(value);
+    dest.setMode(RegisterMode::Scalar);
+    dest.setElements(out);
+};
+
+// If the destination register is not configured, we have to build it before the operation so that its element size matches before any calculations are done
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.mine.us with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+    [&](StreamReg8 &dest, StreamReg8 &src) { baseBehaviour(dest, src, predReg, (unsigned char){}); },
+    [&](StreamReg16 &dest, StreamReg16 &src) { baseBehaviour(dest, src, predReg, (unsigned short int){}); },
+    [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg, (unsigned int){}); },
+    [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg, (unsigned long int){}); },
+    [&](auto &dest, auto &src) { assert_msg("Invoking so.a.mine.us with invalid parameter sizes", false); }
+}, destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_mul_fp.h b/riscv/insns/so_a_mul_fp.h
new file mode 100644
index 00000000..a6923d32
--- /dev/null
+++ b/riscv/insns/so_a_mul_fp.h
@@ -0,0 +1,84 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = dest.getElements(false); // for merging predication
+
+    // print elements2
+    /*std::cout << "MUL elements2: ";
+    for (auto e : elements2) {
+        std::cout << readAS<float>(e) << " ";
+    }*/
+    //std::cout << "\nValid index: " << src2.getValidElements() << "\n";
+
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    // print number of valid elements
+    //std::cout << "u" << src1.registerN << "    src1 valid elements: " << src1.getValidElements() << "\n";
+    //std::cout << "u" << src2.registerN << "    src2 valid elements: " << src2.getValidElements() << "\n";
+
+    auto pi = pred.getPredicate();
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                out.at(i) = readAS<StorageType>(OperationType(e1 * e2));
+                //std::cout << "MUL   " << e1 << " * " << e2 << " = " << readAS<OperationType>(out.at(i)) << "\n";
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //std::cout << "MUL END\n\n";
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            /*operateRegister(P.SU, streamReg, [=](auto& reg) {
+              reg.endConfiguration();
+            });*/
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            /*operateRegister(P.SU, streamReg, [=](auto& reg) {
+              reg.endConfiguration();
+            });*/
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.adde.fp with invalid src type", false);
+    }
+},
+           destReg);
+
+std::visit(overloaded{
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, double{}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, float{}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.mul.fp with invalid parameter sizes", false); }},
+           destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_mul_sg.h b/riscv/insns/so_a_mul_sg.h
new file mode 100644
index 00000000..f09041c7
--- /dev/null
+++ b/riscv/insns/so_a_mul_sg.h
@@ -0,0 +1,82 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// fprintf(stderr, "UVE    Register u%ld\n", streamReg);
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = dest.getElements(false); // for merging predication
+
+    // print elements2
+    /*std::cout << "MUL elements2: ";
+    for (auto e : elements2) {
+        std::cout << readAS<float>(e) << " ";
+    }*/
+    //std::cout << "\nValid index: " << src2.getValidElements() << "\n";
+
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                out.at(i) = readAS<StorageType>(OperationType(e1 * e2));
+                //std::cout << "MUL   " << e1 << " * " << e2 << " = " << readAS<OperationType>(out.at(i)) << "\n";
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.mul.sg with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src1, StreamReg8 &src2) { baseBehaviour(dest, src1, src2, predReg, (signed char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src1, StreamReg16 &src2) { baseBehaviour(dest, src1, src2, predReg, (short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, int{}); },
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, (long int){}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.mul.sg with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_mul_us.h b/riscv/insns/so_a_mul_us.h
new file mode 100644
index 00000000..ca06ac9d
--- /dev/null
+++ b/riscv/insns/so_a_mul_us.h
@@ -0,0 +1,82 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+// fprintf(stderr, "UVE    Register u%ld\n", streamReg);
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = dest.getElements(false); // for merging predication
+
+    // print elements2
+    /*std::cout << "MUL elements2: ";
+    for (auto e : elements2) {
+        std::cout << readAS<float>(e) << " ";
+    }*/
+    //std::cout << "\nValid index: " << src2.getValidElements() << "\n";
+
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                out.at(i) = readAS<StorageType>(OperationType(e1 * e2));
+                //std::cout << "MUL   " << e1 << " * " << e2 << " = " << readAS<OperationType>(out.at(i)) << "\n";
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.mul.us with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src1, StreamReg8 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src1, StreamReg16 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned int){}); },
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned long int){}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.mul.us with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_nand.h b/riscv/insns/so_a_nand.h
new file mode 100644
index 00000000..04e703d7
--- /dev/null
+++ b/riscv/insns/so_a_nand.h
@@ -0,0 +1,75 @@
+
+
+
+
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                out.at(i) = readAS<StorageType>(~(e1 & e2));
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.nand with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src1, StreamReg8 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src1, StreamReg16 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned int){}); },
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned long int){}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.nand with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_nor.h b/riscv/insns/so_a_nor.h
new file mode 100644
index 00000000..3e15edc7
--- /dev/null
+++ b/riscv/insns/so_a_nor.h
@@ -0,0 +1,70 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                out.at(i) = readAS<StorageType>(~(e1 | e2));
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.nor with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src1, StreamReg8 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src1, StreamReg16 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned int){}); },
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned long int){}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.nor with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_not.h b/riscv/insns/so_a_not.h
new file mode 100644
index 00000000..e5e7e2d5
--- /dev/null
+++ b/riscv/insns/so_a_not.h
@@ -0,0 +1,67 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred, auto extra) {
+    /* We can only operate on the first available values of the stream */
+    size_t vLen = src.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+bool zeroing = src.getType() == RegisterConfig::Load;
+    auto elements = src.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = src.getValidElements();
+
+    auto pi = pred.getPredicate();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                OperationType e = readAS<OperationType>(elements.at(i));
+                out.at(i) = readAS<StorageType>(!e);
+                //std::cout << "ADD element1: " << e1 << " element2: " << e2 << " result: " << value << "\n";
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+    // std::cout << "\n\nOUT: " << out.size() << "\n\n";
+    //dest.setValidIndex(dest.vLen);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.not with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src) { baseBehaviour(dest, src, predReg, (unsigned char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src) { baseBehaviour(dest, src, predReg, (unsigned short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg, (unsigned int){}); },
+               [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg, (unsigned long int){}); },
+               [&](auto &dest, auto &src) { assert_msg("Invoking so.a.not with invalid parameter sizes", false); }
+}, destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_or.h b/riscv/insns/so_a_or.h
new file mode 100644
index 00000000..9ff80652
--- /dev/null
+++ b/riscv/insns/so_a_or.h
@@ -0,0 +1,75 @@
+
+
+
+
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                out.at(i) = readAS<StorageType>(e1 | e2);
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.or with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src1, StreamReg8 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src1, StreamReg16 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned int){}); },
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned long int){}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.or with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_sll.h b/riscv/insns/so_a_sll.h
new file mode 100644
index 00000000..15d092b5
--- /dev/null
+++ b/riscv/insns/so_a_sll.h
@@ -0,0 +1,76 @@
+
+
+
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+    /* We can only operate on the first available values of the stream */
+    auto values = src1.getElements();
+    auto shiftValues = src2.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                auto value = readAS<OperationType>(values.at(i));
+                auto shift = readAS<OperationType>(shiftValues.at(i));
+                out.at(i) = readAS<StorageType>(value << shift);
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+    // std::cout << "\n\nOUT: " << out.size() << "\n\n";
+    //dest.setValidIndex(dest.vLen);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.sll with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src1, StreamReg8 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src1, StreamReg16 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned int){}); },
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned long int){}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.sll with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_slls.h b/riscv/insns/so_a_slls.h
new file mode 100644
index 00000000..ecaa3f3f
--- /dev/null
+++ b/riscv/insns/so_a_slls.h
@@ -0,0 +1,71 @@
+#define readRegAS(T, reg) static_cast<T>( READ_REG(reg) )
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto src2 = insn.uve_rs2();
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+const uint64_t shiftValue = readRegAS(uint64_t, src2);
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src, uint64_t shiftValue, auto &pred, auto extra) {
+    /* We can only operate on the first available values of the stream */
+    size_t vLen = src.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+bool zeroing = src.getType() == RegisterConfig::Load;
+    auto values = src.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = src.getValidElements();
+
+    auto pi = pred.getPredicate();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                auto value = readAS<OperationType>(values.at(i));
+                out.at(i) = readAS<StorageType>(value << shiftValue);
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+    // std::cout << "\n\nOUT: " << out.size() << "\n\n";
+    //dest.setValidIndex(dest.vLen);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.slls with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src) { baseBehaviour(dest, src, shiftValue, predReg, (unsigned char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src) { baseBehaviour(dest, src, shiftValue, predReg, (unsigned short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, shiftValue, predReg, (unsigned int){}); },
+               [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, shiftValue, predReg, (unsigned long int){}); },
+               [&](auto &dest, auto &src) { assert_msg("Invoking so.a.slls with invalid parameter sizes", false); }
+}, destReg, src1Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_sra.h b/riscv/insns/so_a_sra.h
new file mode 100644
index 00000000..470e7bd2
--- /dev/null
+++ b/riscv/insns/so_a_sra.h
@@ -0,0 +1,74 @@
+
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+    /* We can only operate on the first available values of the stream */
+    auto values = src1.getElements();
+    auto shiftValues = src2.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = destElements;
+
+    OperationType high_bit = static_cast<OperationType>(-1);
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                auto value = readAS<OperationType>(values.at(i));
+                auto shift = readAS<OperationType>(shiftValues.at(i));
+                out.at(i) = readAS<StorageType>((value >> shift) | -((value & high_bit) >> shift)); // https://stackoverflow.com/questions/76495063/how-can-i-reliably-perform-an-arithmetic-shift-right-in-c
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.sra with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src1, StreamReg8 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src1, StreamReg16 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned int){}); },
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned long int){}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.sra with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_sras.h b/riscv/insns/so_a_sras.h
new file mode 100644
index 00000000..8291bc5b
--- /dev/null
+++ b/riscv/insns/so_a_sras.h
@@ -0,0 +1,73 @@
+#define readRegAS(T, reg) static_cast<T>( READ_REG(reg) )
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto src2 = insn.uve_rs2();
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+const uint64_t shiftValue = readRegAS(uint64_t, src2);
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src, uint64_t shiftValue, auto &pred, auto extra) {
+    /* We can only operate on the first available values of the stream */
+    size_t vLen = src.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+bool zeroing = src.getType() == RegisterConfig::Load;
+    auto values = src.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = src.getValidElements();
+
+    auto pi = pred.getPredicate();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = destElements;
+
+    OperationType high_bit = static_cast<OperationType>(-1);
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                auto value = readAS<OperationType>(values.at(i));
+                out.at(i) = readAS<StorageType>((value >> shiftValue) | -((value & high_bit) >> shiftValue)); // https://stackoverflow.com/questions/76495063/how-can-i-reliably-perform-an-arithmetic-shift-right-in-c
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+    // std::cout << "\n\nOUT: " << out.size() << "\n\n";
+    //dest.setValidIndex(dest.vLen);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.sras with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src) { baseBehaviour(dest, src, shiftValue, predReg, (unsigned char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src) { baseBehaviour(dest, src, shiftValue, predReg, (unsigned short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, shiftValue, predReg, (unsigned int){}); },
+               [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, shiftValue, predReg, (unsigned long int){}); },
+               [&](auto &dest, auto &src) { assert_msg("Invoking so.a.sras with invalid parameter sizes", false); }
+}, destReg, src1Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_srl.h b/riscv/insns/so_a_srl.h
new file mode 100644
index 00000000..51a345d7
--- /dev/null
+++ b/riscv/insns/so_a_srl.h
@@ -0,0 +1,77 @@
+
+
+
+
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+    /* We can only operate on the first available values of the stream */
+    auto values = src1.getElements();
+    auto shiftValues = src2.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                auto value = readAS<OperationType>(values.at(i));
+                auto shift = readAS<OperationType>(shiftValues.at(i));
+                out.at(i) = readAS<StorageType>(value >> shift);
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+    // std::cout << "\n\nOUT: " << out.size() << "\n\n";
+    //dest.setValidIndex(dest.vLen);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.srl with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src1, StreamReg8 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src1, StreamReg16 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned int){}); },
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned long int){}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.srl with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_srls.h b/riscv/insns/so_a_srls.h
new file mode 100644
index 00000000..9ec446f4
--- /dev/null
+++ b/riscv/insns/so_a_srls.h
@@ -0,0 +1,72 @@
+#define readRegAS(T, reg) static_cast<T>( READ_REG(reg) )
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto src2 = insn.uve_rs2();
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+const uint64_t shiftValue = readRegAS(uint64_t, src2);
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src, uint64_t shiftValue, auto &pred, auto extra) {
+    /* We can only operate on the first available values of the stream */
+    size_t vLen = src.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+bool zeroing = src.getType() == RegisterConfig::Load;
+    auto values = src.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = src.getValidElements();
+
+    auto pi = pred.getPredicate();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                auto value = readAS<OperationType>(values.at(i));
+                out.at(i) = readAS<StorageType>(value >> shiftValue);
+                //std::cout << "ADD element1: " << e1 << " element2: " << e2 << " result: " << value << "\n";
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+    // std::cout << "\n\nOUT: " << out.size() << "\n\n";
+    //dest.setValidIndex(dest.vLen);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.srls with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src) { baseBehaviour(dest, src, shiftValue, predReg, (unsigned char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src) { baseBehaviour(dest, src, shiftValue, predReg, (unsigned short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, shiftValue, predReg, (unsigned int){}); },
+               [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, shiftValue, predReg, (unsigned long int){}); },
+               [&](auto &dest, auto &src) { assert_msg("Invoking so.a.srls with invalid parameter sizes", false); }
+}, destReg, src1Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_sub_fp.h b/riscv/insns/so_a_sub_fp.h
new file mode 100644
index 00000000..3c47e2a4
--- /dev/null
+++ b/riscv/insns/so_a_sub_fp.h
@@ -0,0 +1,71 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = dest.getElements(false); // for merging predication
+
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                out.at(i) = readAS<StorageType>(OperationType(e1 - e2));
+                //std::cout << "SUB   " << e1 << " - " << e2 << " = " << readAS<OperationType>(out.at(i)) << "\n";
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            /*operateRegister(P.SU, streamReg, [=](auto& reg) {
+              reg.endConfiguration();
+            });*/
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            /*operateRegister(P.SU, streamReg, [=](auto& reg) {
+              reg.endConfiguration();
+            });*/
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.adde.fp with invalid src type", false);
+    }
+},
+           destReg);
+
+std::visit(overloaded{
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, double{}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, float{}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.sub.fp with invalid parameter sizes", false); }},
+           destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_sub_sg.h b/riscv/insns/so_a_sub_sg.h
new file mode 100644
index 00000000..9e643f3b
--- /dev/null
+++ b/riscv/insns/so_a_sub_sg.h
@@ -0,0 +1,72 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = dest.getElements(false); // for merging predication
+
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                out.at(i) = readAS<StorageType>(OperationType(e1 - e2));
+                //std::cout << "SUB   " << e1 << " - " << e2 << " = " << readAS<OperationType>(out.at(i)) << "\n";
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.sub.sg with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src1, StreamReg8 &src2) { baseBehaviour(dest, src1, src2, predReg, (signed char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src1, StreamReg16 &src2) { baseBehaviour(dest, src1, src2, predReg, (short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, int{}); },
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, (long int){}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.sub.sg with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_sub_us.h b/riscv/insns/so_a_sub_us.h
new file mode 100644
index 00000000..b8a8829c
--- /dev/null
+++ b/riscv/insns/so_a_sub_us.h
@@ -0,0 +1,72 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = dest.getElements(false); // for merging predication
+
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                out.at(i) = readAS<StorageType>(OperationType(e1 - e2));
+                //std::cout << "SUB   " << e1 << " - " << e2 << " = " << readAS<OperationType>(out.at(i)) << "\n";
+            }
+        } else if (zeroing)
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    //dest.setValidIndex(dest.vLen);
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.sub.us with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src1, StreamReg8 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src1, StreamReg16 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned int){}); },
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned long int){}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.sub.us with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_a_xor.h b/riscv/insns/so_a_xor.h
new file mode 100644
index 00000000..1d0eb794
--- /dev/null
+++ b/riscv/insns/so_a_xor.h
@@ -0,0 +1,73 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &src1Reg = P.SU.registers[insn.uve_rs1()];
+auto &src2Reg = P.SU.registers[insn.uve_rs2()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+/* The extra argument is passed because we need to tell the lambda the computation type. In C++20 we would
+    use a lambda template parameter, however in C++17 we don't have those. As such, we pass an extra value to
+    later on infer its type and know the storage we need to use */
+auto baseBehaviour = [](auto &dest, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    size_t vLen = src1.getMode() == RegisterMode::Scalar ||  src2.getMode() == RegisterMode::Scalar ? 1 : dest.getVLen();
+    bool zeroing = src1.getType() == RegisterConfig::Load || src2.getType() == RegisterConfig::Load;
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = dest.getElements(false);
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+
+    /* Grab used types for storage and operation */
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    using OperationType = decltype(extra);
+    std::vector<StorageType> out = destElements;
+
+    for (size_t i = 0; i < vLen; i++) {
+        if (i < validElementsIndex){
+            if (pi.at((i + 1) * sizeof(OperationType) - 1)) {
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                out.at(i) = readAS<StorageType>(e1 ^ e2);
+                //std::cout << "ADD element1: " << e1 << " element2: " << e2 << " result: " << value << "\n";
+            }
+        } else
+            out.at(i) = 0; // zeroing out the rest of the elements
+    }
+    dest.setMode(vLen == 1 ? RegisterMode::Scalar : RegisterMode::Vector);
+    dest.setElements(out);
+    // std::cout << "\n\nOUT: " << out.size() << "\n\n";
+    //dest.setValidIndex(dest.vLen);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg8>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+            dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg64>(src1Reg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+            dest.endConfiguration();
+        } else
+            assert_msg("Trying to run so.a.xor with invalid src type", false);
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg8 &dest, StreamReg8 &src1, StreamReg8 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned char){}); },
+               [&](StreamReg16 &dest, StreamReg16 &src1, StreamReg16 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned short int){}); },
+               [&](StreamReg32 &dest, StreamReg32 &src1, StreamReg32 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned int){}); },
+               [&](StreamReg64 &dest, StreamReg64 &src1, StreamReg64 &src2) { baseBehaviour(dest, src1, src2, predReg, (unsigned long int){}); },
+               [&](auto &dest, auto &src1, auto &src2) { assert_msg("Invoking so.a.xor with invalid parameter sizes", false); }
+}, destReg, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_b_c.h b/riscv/insns/so_b_c.h
new file mode 100644
index 00000000..235b9176
--- /dev/null
+++ b/riscv/insns/so_b_c.h
@@ -0,0 +1,17 @@
+auto& streamReg = P.SU.registers[insn.uve_branch_rs()];
+auto branchIMM = insn.uve_branch_imm();
+
+const bool complete = std::visit([](const auto &reg){
+    return reg.hasStreamFinished();
+}, streamReg);
+
+/*auto streamReg = insn.uve_branch_rs();
+auto branchIMM = insn.uve_branch_imm();
+
+const bool notComplete = operateRegister(P.SU, streamReg, [=](auto& reg) {
+    return !reg.hasStreamFinished();
+});
+*/
+
+if (complete)
+    set_pc(pc + branchIMM);
\ No newline at end of file
diff --git a/riscv/insns/so_b_dc_1.h b/riscv/insns/so_b_dc_1.h
new file mode 100644
index 00000000..965477ae
--- /dev/null
+++ b/riscv/insns/so_b_dc_1.h
@@ -0,0 +1,5 @@
+auto regN = insn.uve_branch_rs();
+auto branchIMM = insn.uve_branch_imm();
+
+if (P.SU.EODTable.at(regN).at(0))
+    set_pc(pc + branchIMM);
\ No newline at end of file
diff --git a/riscv/insns/so_b_dc_2.h b/riscv/insns/so_b_dc_2.h
new file mode 100644
index 00000000..413b1cff
--- /dev/null
+++ b/riscv/insns/so_b_dc_2.h
@@ -0,0 +1,5 @@
+auto regN = insn.uve_branch_rs();
+auto branchIMM = insn.uve_branch_imm();
+
+if (P.SU.EODTable.at(regN).at(1))
+    set_pc(pc + branchIMM);
\ No newline at end of file
diff --git a/riscv/insns/so_b_dc_3.h b/riscv/insns/so_b_dc_3.h
new file mode 100644
index 00000000..ee9692f7
--- /dev/null
+++ b/riscv/insns/so_b_dc_3.h
@@ -0,0 +1,5 @@
+auto regN = insn.uve_branch_rs();
+auto branchIMM = insn.uve_branch_imm();
+
+if (P.SU.EODTable.at(regN).at(2))
+    set_pc(pc + branchIMM);
\ No newline at end of file
diff --git a/riscv/insns/so_b_dc_4.h b/riscv/insns/so_b_dc_4.h
new file mode 100644
index 00000000..178a9a65
--- /dev/null
+++ b/riscv/insns/so_b_dc_4.h
@@ -0,0 +1,5 @@
+auto regN = insn.uve_branch_rs();
+auto branchIMM = insn.uve_branch_imm();
+
+if (P.SU.EODTable.at(regN).at(3))
+    set_pc(pc + branchIMM);
\ No newline at end of file
diff --git a/riscv/insns/so_b_dc_5.h b/riscv/insns/so_b_dc_5.h
new file mode 100644
index 00000000..70cd540f
--- /dev/null
+++ b/riscv/insns/so_b_dc_5.h
@@ -0,0 +1,5 @@
+auto regN = insn.uve_branch_rs();
+auto branchIMM = insn.uve_branch_imm();
+
+if (P.SU.EODTable.at(regN).at(4))
+    set_pc(pc + branchIMM);
\ No newline at end of file
diff --git a/riscv/insns/so_b_dc_6.h b/riscv/insns/so_b_dc_6.h
new file mode 100644
index 00000000..acb16b5a
--- /dev/null
+++ b/riscv/insns/so_b_dc_6.h
@@ -0,0 +1,5 @@
+auto regN = insn.uve_branch_rs();
+auto branchIMM = insn.uve_branch_imm();
+
+if (P.SU.EODTable.at(regN).at(5))
+    set_pc(pc + branchIMM);
\ No newline at end of file
diff --git a/riscv/insns/so_b_dc_7.h b/riscv/insns/so_b_dc_7.h
new file mode 100644
index 00000000..8e12a4ce
--- /dev/null
+++ b/riscv/insns/so_b_dc_7.h
@@ -0,0 +1,5 @@
+auto regN = insn.uve_branch_rs();
+auto branchIMM = insn.uve_branch_imm();
+
+if (P.SU.EODTable.at(regN).at(6))
+    set_pc(pc + branchIMM);
\ No newline at end of file
diff --git a/riscv/insns/so_b_nc.h b/riscv/insns/so_b_nc.h
new file mode 100644
index 00000000..a39a3eaa
--- /dev/null
+++ b/riscv/insns/so_b_nc.h
@@ -0,0 +1,17 @@
+auto& streamReg = P.SU.registers[insn.uve_branch_rs()];
+auto branchIMM = insn.uve_branch_imm();
+
+const bool notComplete = std::visit([](const auto &reg){
+    return !reg.hasStreamFinished();
+}, streamReg);
+
+/*auto streamReg = insn.uve_branch_rs();
+auto branchIMM = insn.uve_branch_imm();
+
+const bool notComplete = operateRegister(P.SU, streamReg, [=](auto& reg) {
+    return !reg.hasStreamFinished();
+});
+*/
+
+if (notComplete)
+    set_pc(pc + branchIMM);
\ No newline at end of file
diff --git a/riscv/insns/so_b_ndc_1.h b/riscv/insns/so_b_ndc_1.h
new file mode 100644
index 00000000..5fc2645c
--- /dev/null
+++ b/riscv/insns/so_b_ndc_1.h
@@ -0,0 +1,21 @@
+auto regN = insn.uve_branch_rs();
+//auto& streamReg = P.SU.registers[regN];
+auto branchIMM = insn.uve_branch_imm();
+
+/*
+const bool notComplete = std::visit([](const auto &reg){
+    return !reg.isEndOfDimensionOfDim(0);
+}, streamReg);
+*/
+
+/*auto streamReg = insn.uve_branch_rs();
+auto branchIMM = insn.uve_branch_imm();
+
+const bool notComplete = operateRegister(P.SU, streamReg, [=](auto &reg) {
+    return !reg.isEndOfDimensionOfDim(0);
+});*/
+
+//if (notComplete)
+
+if (!P.SU.EODTable.at(regN).at(0))
+    set_pc(pc + branchIMM);
\ No newline at end of file
diff --git a/riscv/insns/so_b_ndc_2.h b/riscv/insns/so_b_ndc_2.h
new file mode 100644
index 00000000..03e6b1b1
--- /dev/null
+++ b/riscv/insns/so_b_ndc_2.h
@@ -0,0 +1,21 @@
+auto regN = insn.uve_branch_rs();
+auto& streamReg = P.SU.registers[regN];
+auto branchIMM = insn.uve_branch_imm();
+
+/*
+const bool notComplete = std::visit([](const auto &reg){
+    return !reg.isEndOfDimensionOfDim(0);
+}, streamReg);
+*/
+
+/*auto streamReg = insn.uve_branch_rs();
+auto branchIMM = insn.uve_branch_imm();
+
+const bool notComplete = operateRegister(P.SU, streamReg, [=](auto &reg) {
+    return !reg.isEndOfDimensionOfDim(0);
+});*/
+
+//if (notComplete)
+
+if (!P.SU.EODTable.at(regN).at(1))
+    set_pc(pc + branchIMM);
\ No newline at end of file
diff --git a/riscv/insns/so_b_ndc_3.h b/riscv/insns/so_b_ndc_3.h
new file mode 100644
index 00000000..74b19f84
--- /dev/null
+++ b/riscv/insns/so_b_ndc_3.h
@@ -0,0 +1,21 @@
+auto regN = insn.uve_branch_rs();
+auto& streamReg = P.SU.registers[regN];
+auto branchIMM = insn.uve_branch_imm();
+
+/*
+const bool notComplete = std::visit([](const auto &reg){
+    return !reg.isEndOfDimensionOfDim(0);
+}, streamReg);
+*/
+
+/*auto streamReg = insn.uve_branch_rs();
+auto branchIMM = insn.uve_branch_imm();
+
+const bool notComplete = operateRegister(P.SU, streamReg, [=](auto &reg) {
+    return !reg.isEndOfDimensionOfDim(0);
+});*/
+
+//if (notComplete)
+
+if (!P.SU.EODTable.at(regN).at(2))
+    set_pc(pc + branchIMM);
\ No newline at end of file
diff --git a/riscv/insns/so_b_ndc_4.h b/riscv/insns/so_b_ndc_4.h
new file mode 100644
index 00000000..d922d8f2
--- /dev/null
+++ b/riscv/insns/so_b_ndc_4.h
@@ -0,0 +1,21 @@
+auto regN = insn.uve_branch_rs();
+auto& streamReg = P.SU.registers[regN];
+auto branchIMM = insn.uve_branch_imm();
+
+/*
+const bool notComplete = std::visit([](const auto &reg){
+    return !reg.isEndOfDimensionOfDim(0);
+}, streamReg);
+*/
+
+/*auto streamReg = insn.uve_branch_rs();
+auto branchIMM = insn.uve_branch_imm();
+
+const bool notComplete = operateRegister(P.SU, streamReg, [=](auto &reg) {
+    return !reg.isEndOfDimensionOfDim(0);
+});*/
+
+//if (notComplete)
+
+if (!P.SU.EODTable.at(regN).at(3))
+    set_pc(pc + branchIMM);
\ No newline at end of file
diff --git a/riscv/insns/so_b_ndc_5.h b/riscv/insns/so_b_ndc_5.h
new file mode 100644
index 00000000..e4296399
--- /dev/null
+++ b/riscv/insns/so_b_ndc_5.h
@@ -0,0 +1,21 @@
+auto regN = insn.uve_branch_rs();
+auto& streamReg = P.SU.registers[regN];
+auto branchIMM = insn.uve_branch_imm();
+
+/*
+const bool notComplete = std::visit([](const auto &reg){
+    return !reg.isEndOfDimensionOfDim(0);
+}, streamReg);
+*/
+
+/*auto streamReg = insn.uve_branch_rs();
+auto branchIMM = insn.uve_branch_imm();
+
+const bool notComplete = operateRegister(P.SU, streamReg, [=](auto &reg) {
+    return !reg.isEndOfDimensionOfDim(0);
+});*/
+
+//if (notComplete)
+
+if (!P.SU.EODTable.at(regN).at(4))
+    set_pc(pc + branchIMM);
\ No newline at end of file
diff --git a/riscv/insns/so_b_ndc_6.h b/riscv/insns/so_b_ndc_6.h
new file mode 100644
index 00000000..b499f51b
--- /dev/null
+++ b/riscv/insns/so_b_ndc_6.h
@@ -0,0 +1,21 @@
+auto regN = insn.uve_branch_rs();
+auto& streamReg = P.SU.registers[regN];
+auto branchIMM = insn.uve_branch_imm();
+
+/*
+const bool notComplete = std::visit([](const auto &reg){
+    return !reg.isEndOfDimensionOfDim(0);
+}, streamReg);
+*/
+
+/*auto streamReg = insn.uve_branch_rs();
+auto branchIMM = insn.uve_branch_imm();
+
+const bool notComplete = operateRegister(P.SU, streamReg, [=](auto &reg) {
+    return !reg.isEndOfDimensionOfDim(0);
+});*/
+
+//if (notComplete)
+
+if (!P.SU.EODTable.at(regN).at(5))
+    set_pc(pc + branchIMM);
\ No newline at end of file
diff --git a/riscv/insns/so_b_ndc_7.h b/riscv/insns/so_b_ndc_7.h
new file mode 100644
index 00000000..8fefc70d
--- /dev/null
+++ b/riscv/insns/so_b_ndc_7.h
@@ -0,0 +1,21 @@
+auto regN = insn.uve_branch_rs();
+auto& streamReg = P.SU.registers[regN];
+auto branchIMM = insn.uve_branch_imm();
+
+/*
+const bool notComplete = std::visit([](const auto &reg){
+    return !reg.isEndOfDimensionOfDim(0);
+}, streamReg);
+*/
+
+/*auto streamReg = insn.uve_branch_rs();
+auto branchIMM = insn.uve_branch_imm();
+
+const bool notComplete = operateRegister(P.SU, streamReg, [=](auto &reg) {
+    return !reg.isEndOfDimensionOfDim(0);
+});*/
+
+//if (notComplete)
+
+if (!P.SU.EODTable.at(regN).at(6))
+    set_pc(pc + branchIMM);
\ No newline at end of file
diff --git a/riscv/insns/so_p_cv_b.h b/riscv/insns/so_p_cv_b.h
new file mode 100644
index 00000000..59a07e12
--- /dev/null
+++ b/riscv/insns/so_p_cv_b.h
@@ -0,0 +1,45 @@
+auto dest = insn.uve_pred_rd();
+auto& destPReg = P.SU.predicates[dest];
+auto& src1Reg = P.SU.registers[insn.uve_pred_vs1()];
+auto& src2Reg = P.SU.registers[insn.uve_pred_rs2()];
+auto& predReg = P.SU.predicates[insn.uve_pred()];
+
+auto baseBehaviour = [](auto &destP, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+
+
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = destP.getPredicate();
+    auto validElementsIndex = std::min(elements1.size(), elements2.size());
+
+    auto pi = pred.getPredicate();
+    std::vector<uint8_t> predicate(pred.vLen);
+
+    using Operation = decltype(extra);
+    if (validElementsIndex) {
+        /* Grab used types for storage and operation */
+        using OperationType = decltype(extra);
+        auto destValidIndex = destElements.size();
+        uint8_t value = 0;
+        for (size_t i = 0; i < validElementsIndex; i++) {
+            if(pi.at(i)){
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                value = e1 >= e2;
+            } else
+                value =  i < destValidIndex ? readAS<OperationType>(destElements.at(i)) : 0;
+            predicate.at(i) = value;
+        }
+    }
+    return predicate;
+};
+
+std::visit(overloaded{
+    [&](StreamReg64 &src1, StreamReg64 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, double{}); P.SU.makePredRegister(pr, dest);},
+    [&](StreamReg32 &src1, StreamReg32 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, float{}); P.SU.makePredRegister(pr, dest);},
+    [&](auto &src1, auto &src2) { assert_msg("Invoking so.p.egt.fp with invalid parameter sizes", false); }
+}, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_p_cv_d.h b/riscv/insns/so_p_cv_d.h
new file mode 100644
index 00000000..59a07e12
--- /dev/null
+++ b/riscv/insns/so_p_cv_d.h
@@ -0,0 +1,45 @@
+auto dest = insn.uve_pred_rd();
+auto& destPReg = P.SU.predicates[dest];
+auto& src1Reg = P.SU.registers[insn.uve_pred_vs1()];
+auto& src2Reg = P.SU.registers[insn.uve_pred_rs2()];
+auto& predReg = P.SU.predicates[insn.uve_pred()];
+
+auto baseBehaviour = [](auto &destP, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+
+
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = destP.getPredicate();
+    auto validElementsIndex = std::min(elements1.size(), elements2.size());
+
+    auto pi = pred.getPredicate();
+    std::vector<uint8_t> predicate(pred.vLen);
+
+    using Operation = decltype(extra);
+    if (validElementsIndex) {
+        /* Grab used types for storage and operation */
+        using OperationType = decltype(extra);
+        auto destValidIndex = destElements.size();
+        uint8_t value = 0;
+        for (size_t i = 0; i < validElementsIndex; i++) {
+            if(pi.at(i)){
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                value = e1 >= e2;
+            } else
+                value =  i < destValidIndex ? readAS<OperationType>(destElements.at(i)) : 0;
+            predicate.at(i) = value;
+        }
+    }
+    return predicate;
+};
+
+std::visit(overloaded{
+    [&](StreamReg64 &src1, StreamReg64 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, double{}); P.SU.makePredRegister(pr, dest);},
+    [&](StreamReg32 &src1, StreamReg32 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, float{}); P.SU.makePredRegister(pr, dest);},
+    [&](auto &src1, auto &src2) { assert_msg("Invoking so.p.egt.fp with invalid parameter sizes", false); }
+}, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_p_cv_h.h b/riscv/insns/so_p_cv_h.h
new file mode 100644
index 00000000..59a07e12
--- /dev/null
+++ b/riscv/insns/so_p_cv_h.h
@@ -0,0 +1,45 @@
+auto dest = insn.uve_pred_rd();
+auto& destPReg = P.SU.predicates[dest];
+auto& src1Reg = P.SU.registers[insn.uve_pred_vs1()];
+auto& src2Reg = P.SU.registers[insn.uve_pred_rs2()];
+auto& predReg = P.SU.predicates[insn.uve_pred()];
+
+auto baseBehaviour = [](auto &destP, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+
+
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = destP.getPredicate();
+    auto validElementsIndex = std::min(elements1.size(), elements2.size());
+
+    auto pi = pred.getPredicate();
+    std::vector<uint8_t> predicate(pred.vLen);
+
+    using Operation = decltype(extra);
+    if (validElementsIndex) {
+        /* Grab used types for storage and operation */
+        using OperationType = decltype(extra);
+        auto destValidIndex = destElements.size();
+        uint8_t value = 0;
+        for (size_t i = 0; i < validElementsIndex; i++) {
+            if(pi.at(i)){
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                value = e1 >= e2;
+            } else
+                value =  i < destValidIndex ? readAS<OperationType>(destElements.at(i)) : 0;
+            predicate.at(i) = value;
+        }
+    }
+    return predicate;
+};
+
+std::visit(overloaded{
+    [&](StreamReg64 &src1, StreamReg64 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, double{}); P.SU.makePredRegister(pr, dest);},
+    [&](StreamReg32 &src1, StreamReg32 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, float{}); P.SU.makePredRegister(pr, dest);},
+    [&](auto &src1, auto &src2) { assert_msg("Invoking so.p.egt.fp with invalid parameter sizes", false); }
+}, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_p_cv_w.h b/riscv/insns/so_p_cv_w.h
new file mode 100644
index 00000000..59a07e12
--- /dev/null
+++ b/riscv/insns/so_p_cv_w.h
@@ -0,0 +1,45 @@
+auto dest = insn.uve_pred_rd();
+auto& destPReg = P.SU.predicates[dest];
+auto& src1Reg = P.SU.registers[insn.uve_pred_vs1()];
+auto& src2Reg = P.SU.registers[insn.uve_pred_rs2()];
+auto& predReg = P.SU.predicates[insn.uve_pred()];
+
+auto baseBehaviour = [](auto &destP, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+
+
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = destP.getPredicate();
+    auto validElementsIndex = std::min(elements1.size(), elements2.size());
+
+    auto pi = pred.getPredicate();
+    std::vector<uint8_t> predicate(pred.vLen);
+
+    using Operation = decltype(extra);
+    if (validElementsIndex) {
+        /* Grab used types for storage and operation */
+        using OperationType = decltype(extra);
+        auto destValidIndex = destElements.size();
+        uint8_t value = 0;
+        for (size_t i = 0; i < validElementsIndex; i++) {
+            if(pi.at(i)){
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                value = e1 >= e2;
+            } else
+                value =  i < destValidIndex ? readAS<OperationType>(destElements.at(i)) : 0;
+            predicate.at(i) = value;
+        }
+    }
+    return predicate;
+};
+
+std::visit(overloaded{
+    [&](StreamReg64 &src1, StreamReg64 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, double{}); P.SU.makePredRegister(pr, dest);},
+    [&](StreamReg32 &src1, StreamReg32 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, float{}); P.SU.makePredRegister(pr, dest);},
+    [&](auto &src1, auto &src2) { assert_msg("Invoking so.p.egt.fp with invalid parameter sizes", false); }
+}, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_p_eq_fp.h b/riscv/insns/so_p_eq_fp.h
new file mode 100644
index 00000000..806dc5a7
--- /dev/null
+++ b/riscv/insns/so_p_eq_fp.h
@@ -0,0 +1,46 @@
+auto dest = insn.uve_pred_rd();
+auto& destPReg = P.SU.predicates[dest];
+auto& src1Reg = P.SU.registers[insn.uve_pred_vs1()];
+auto& src2Reg = P.SU.registers[insn.uve_pred_rs2()];
+auto& predReg = P.SU.predicates[insn.uve_pred()];
+
+auto baseBehaviour = [](auto &destP, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+
+
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = destP.getPredicate();
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+    std::vector<uint8_t> predicate(pred.vLen);
+
+    auto iterator = predicate.begin();
+
+    if (validElementsIndex) {
+        /* Grab used types for storage and operation */
+        using OperationType = decltype(extra);
+        uint8_t value = 0;
+        for (size_t i = 0; i < validElementsIndex; i++) {
+            if(pi.at((i+1)*sizeof(OperationType)-1)){
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                value = e1 == e2;
+            } else
+                value = readAS<OperationType>(destElements.at(i));
+            std::fill(iterator, iterator+sizeof(OperationType), value);
+            iterator += sizeof(OperationType);
+        }
+    }
+    return predicate;
+};
+
+std::visit(overloaded{
+    [&](StreamReg64 &src1, StreamReg64 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, double{}); P.SU.makePredRegister(pr, dest);},
+    [&](StreamReg32 &src1, StreamReg32 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, float{}); P.SU.makePredRegister(pr, dest);},
+    [&](auto &src1, auto &src2) { assert_msg("Invoking so.pr.eq.fp with invalid parameter sizes", false); }
+}, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_p_eq_sg.h b/riscv/insns/so_p_eq_sg.h
new file mode 100644
index 00000000..6e159a29
--- /dev/null
+++ b/riscv/insns/so_p_eq_sg.h
@@ -0,0 +1,48 @@
+auto dest = insn.uve_pred_rd();
+auto& destPReg = P.SU.predicates[dest];
+auto& src1Reg = P.SU.registers[insn.uve_pred_vs1()];
+auto& src2Reg = P.SU.registers[insn.uve_pred_rs2()];
+auto& predReg = P.SU.predicates[insn.uve_pred()];
+
+auto baseBehaviour = [](auto &destP, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+
+
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = destP.getPredicate();
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+    std::vector<uint8_t> predicate(pred.vLen);
+
+    auto iterator = predicate.begin();
+
+    if (validElementsIndex) {
+        /* Grab used types for storage and operation */
+        using OperationType = decltype(extra);
+        uint8_t value = 0;
+        for (size_t i = 0; i < validElementsIndex; i++) {
+            if(pi.at((i+1)*sizeof(OperationType)-1)){
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                value = e1 == e2;
+            } else
+                value = readAS<OperationType>(destElements.at(i));
+            std::fill(iterator, iterator+sizeof(OperationType), value);
+            iterator += sizeof(OperationType);
+        }
+    }
+    return predicate;
+};
+
+std::visit(overloaded{
+    [&](StreamReg8 &src1, StreamReg8 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, (signed char){}); P.SU.makePredRegister(pr, dest); },
+    [&](StreamReg16 &src1, StreamReg16 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, (short int){}); P.SU.makePredRegister(pr, dest); },
+    [&](StreamReg32 &src1, StreamReg32 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, int{}); P.SU.makePredRegister(pr, dest); },
+    [&](StreamReg64 &src1, StreamReg64 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, (long int){}); P.SU.makePredRegister(pr, dest); },
+    [&](auto &src1, auto &src2) { assert_msg("Invoking so.p.eq.sg with invalid parameter sizes", false); }
+}, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_p_eq_us.h b/riscv/insns/so_p_eq_us.h
new file mode 100644
index 00000000..58635919
--- /dev/null
+++ b/riscv/insns/so_p_eq_us.h
@@ -0,0 +1,48 @@
+auto dest = insn.uve_pred_rd();
+auto& destPReg = P.SU.predicates[dest];
+auto& src1Reg = P.SU.registers[insn.uve_pred_vs1()];
+auto& src2Reg = P.SU.registers[insn.uve_pred_rs2()];
+auto& predReg = P.SU.predicates[insn.uve_pred()];
+
+auto baseBehaviour = [](auto &destP, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+
+
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = destP.getPredicate();
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+    std::vector<uint8_t> predicate(pred.vLen);
+
+    auto iterator = predicate.begin();
+
+    if (validElementsIndex) {
+        /* Grab used types for storage and operation */
+        using OperationType = decltype(extra);
+        uint8_t value = 0;
+        for (size_t i = 0; i < validElementsIndex; i++) {
+            if(pi.at((i+1)*sizeof(OperationType)-1)){
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                value = e1 == e2;
+            } else
+                value = readAS<OperationType>(destElements.at(i));
+            std::fill(iterator, iterator+sizeof(OperationType), value);
+            iterator += sizeof(OperationType);
+        }
+    }
+    return predicate;
+};
+
+std::visit(overloaded{
+    [&](StreamReg8 &src1, StreamReg8 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, (unsigned char){}); P.SU.makePredRegister(pr, dest);},
+    [&](StreamReg16 &src1, StreamReg16 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, (unsigned short int){}); P.SU.makePredRegister(pr, dest);},
+    [&](StreamReg32 &src1, StreamReg32 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, (unsigned int){}); P.SU.makePredRegister(pr, dest);},
+    [&](StreamReg64 &src1, StreamReg64 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, (unsigned long int){}); P.SU.makePredRegister(pr, dest);},
+    [&](auto &src1, auto &src2) { assert_msg("Invoking so.p.eq.us with invalid parameter sizes", false); }
+}, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_p_ge_fp.h b/riscv/insns/so_p_ge_fp.h
new file mode 100644
index 00000000..9d3983a0
--- /dev/null
+++ b/riscv/insns/so_p_ge_fp.h
@@ -0,0 +1,44 @@
+auto dest = insn.uve_pred_rd();
+auto& destPReg = P.SU.predicates[dest];
+auto& src1Reg = P.SU.registers[insn.uve_pred_vs1()];
+auto& src2Reg = P.SU.registers[insn.uve_pred_rs2()];
+auto& predReg = P.SU.predicates[insn.uve_pred()];
+
+auto baseBehaviour = [](auto &destP, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = destP.getPredicate();
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+    std::vector<uint8_t> predicate(pred.vLen);
+
+    auto iterator = predicate.begin();
+
+    if (validElementsIndex) {
+        /* Grab used types for storage and operation */
+        using OperationType = decltype(extra);
+        uint8_t value = 0;
+        for (size_t i = 0; i < validElementsIndex; i++) {
+            if(pi.at((i+1)*sizeof(OperationType)-1)){
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                value = e1 >= e2;
+            } else
+                value = readAS<OperationType>(destElements.at(i));
+            std::fill(iterator, iterator+sizeof(OperationType), value);
+            iterator += sizeof(OperationType);
+        }
+    }
+    return predicate;
+};
+
+std::visit(overloaded{
+    [&](StreamReg64 &src1, StreamReg64 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, double{}); P.SU.makePredRegister(pr, dest);},
+    [&](StreamReg32 &src1, StreamReg32 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, float{}); P.SU.makePredRegister(pr, dest);},
+    [&](auto &src1, auto &src2) { assert_msg("Invoking so.p.egt.fp with invalid parameter sizes", false); }
+}, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_p_ge_sg.h b/riscv/insns/so_p_ge_sg.h
new file mode 100644
index 00000000..7acca66c
--- /dev/null
+++ b/riscv/insns/so_p_ge_sg.h
@@ -0,0 +1,46 @@
+auto dest = insn.uve_pred_rd();
+auto& destPReg = P.SU.predicates[dest];
+auto& src1Reg = P.SU.registers[insn.uve_pred_vs1()];
+auto& src2Reg = P.SU.registers[insn.uve_pred_rs2()];
+auto& predReg = P.SU.predicates[insn.uve_pred()];
+
+auto baseBehaviour = [](auto &destP, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = destP.getPredicate();
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+    std::vector<uint8_t> predicate(pred.vLen);
+
+    auto iterator = predicate.begin();
+
+    if (validElementsIndex) {
+        /* Grab used types for storage and operation */
+        using OperationType = decltype(extra);
+        uint8_t value = 0;
+        for (size_t i = 0; i < validElementsIndex; i++) {
+            if(pi.at((i+1)*sizeof(OperationType)-1)){
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                value = e1 >= e2;
+            } else
+                value = readAS<OperationType>(destElements.at(i));
+            std::fill(iterator, iterator+sizeof(OperationType), value);
+            iterator += sizeof(OperationType);
+        }
+    }
+    return predicate;
+};
+
+std::visit(overloaded{
+    [&](StreamReg8 &src1, StreamReg8 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, (signed char){}); P.SU.makePredRegister(pr, dest); },
+    [&](StreamReg16 &src1, StreamReg16 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, (short int){}); P.SU.makePredRegister(pr, dest); },
+    [&](StreamReg32 &src1, StreamReg32 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, int{}); P.SU.makePredRegister(pr, dest); },
+    [&](StreamReg64 &src1, StreamReg64 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, (long int){}); P.SU.makePredRegister(pr, dest); },
+    [&](auto &src1, auto &src2) { assert_msg("Invoking so.p.egt.sg with invalid parameter sizes", false); }
+}, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_p_ge_us.h b/riscv/insns/so_p_ge_us.h
new file mode 100644
index 00000000..e03e3a94
--- /dev/null
+++ b/riscv/insns/so_p_ge_us.h
@@ -0,0 +1,46 @@
+auto dest = insn.uve_pred_rd();
+auto& destPReg = P.SU.predicates[dest];
+auto& src1Reg = P.SU.registers[insn.uve_pred_vs1()];
+auto& src2Reg = P.SU.registers[insn.uve_pred_rs2()];
+auto& predReg = P.SU.predicates[insn.uve_pred()];
+
+auto baseBehaviour = [](auto &destP, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = destP.getPredicate();
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+    std::vector<uint8_t> predicate(pred.vLen);
+
+    auto iterator = predicate.begin();
+
+    if (validElementsIndex) {
+        /* Grab used types for storage and operation */
+        using OperationType = decltype(extra);
+        uint8_t value = 0;
+        for (size_t i = 0; i < validElementsIndex; i++) {
+            if(pi.at((i+1)*sizeof(OperationType)-1)){
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                value = e1 >= e2;
+            } else
+                value = readAS<OperationType>(destElements.at(i));
+            std::fill(iterator, iterator+sizeof(OperationType), value);
+            iterator += sizeof(OperationType);
+        }
+    }
+    return predicate;
+};
+
+std::visit(overloaded{
+    [&](StreamReg8 &src1, StreamReg8 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, (unsigned char){}); P.SU.makePredRegister(pr, dest);},
+    [&](StreamReg16 &src1, StreamReg16 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, (unsigned short int){}); P.SU.makePredRegister(pr, dest);},
+    [&](StreamReg32 &src1, StreamReg32 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, (unsigned int){}); P.SU.makePredRegister(pr, dest);},
+    [&](StreamReg64 &src1, StreamReg64 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, (unsigned long int){}); P.SU.makePredRegister(pr, dest);},
+    [&](auto &src1, auto &src2) { assert_msg("Invoking so.p.egt.us with invalid parameter sizes", false); }
+}, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_p_lt_fp.h b/riscv/insns/so_p_lt_fp.h
new file mode 100644
index 00000000..c0a07c72
--- /dev/null
+++ b/riscv/insns/so_p_lt_fp.h
@@ -0,0 +1,46 @@
+auto dest = insn.uve_pred_rd();
+auto& destPReg = P.SU.predicates[dest];
+auto& src1Reg = P.SU.registers[insn.uve_pred_vs1()];
+auto& src2Reg = P.SU.registers[insn.uve_pred_rs2()];
+auto& predReg = P.SU.predicates[insn.uve_pred()];
+
+auto baseBehaviour = [](auto &destP, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+
+
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = destP.getPredicate();
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+    std::vector<uint8_t> predicate(pred.vLen);
+
+    auto iterator = predicate.begin();
+
+    if (validElementsIndex) {
+        /* Grab used types for storage and operation */
+        using OperationType = decltype(extra);
+        uint8_t value = 0;
+        for (size_t i = 0; i < validElementsIndex; i++) {
+            if(pi.at((i+1)*sizeof(OperationType)-1)){
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                value = e1 < e2;
+            } else
+                value = readAS<OperationType>(destElements.at(i));
+            std::fill(iterator, iterator+sizeof(OperationType), value);
+            iterator += sizeof(OperationType);
+        }
+    }
+    return predicate;
+};
+
+std::visit(overloaded{
+    [&](StreamReg64 &src1, StreamReg64 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, double{}); P.SU.makePredRegister(pr, dest);},
+    [&](StreamReg32 &src1, StreamReg32 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, float{}); P.SU.makePredRegister(pr, dest);},
+    [&](auto &src1, auto &src2) { assert_msg("Invoking so.pr.lt.fp with invalid parameter sizes", false); }
+}, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_p_lt_sg.h b/riscv/insns/so_p_lt_sg.h
new file mode 100644
index 00000000..ab32ee76
--- /dev/null
+++ b/riscv/insns/so_p_lt_sg.h
@@ -0,0 +1,48 @@
+auto dest = insn.uve_pred_rd();
+auto& destPReg = P.SU.predicates[dest];
+auto& src1Reg = P.SU.registers[insn.uve_pred_vs1()];
+auto& src2Reg = P.SU.registers[insn.uve_pred_rs2()];
+auto& predReg = P.SU.predicates[insn.uve_pred()];
+
+auto baseBehaviour = [](auto &destP, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+
+
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = destP.getPredicate();
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+    std::vector<uint8_t> predicate(pred.vLen);
+
+    auto iterator = predicate.begin();
+
+    if (validElementsIndex) {
+        /* Grab used types for storage and operation */
+        using OperationType = decltype(extra);
+        uint8_t value = 0;
+        for (size_t i = 0; i < validElementsIndex; i++) {
+            if(pi.at((i+1)*sizeof(OperationType)-1)){
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                value = e1 < e2;
+            } else
+                value = readAS<OperationType>(destElements.at(i));
+            std::fill(iterator, iterator+sizeof(OperationType), value);
+            iterator += sizeof(OperationType);
+        }
+    }
+    return predicate;
+};
+
+std::visit(overloaded{
+    [&](StreamReg8 &src1, StreamReg8 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, (signed char){}); P.SU.makePredRegister(pr, dest); },
+    [&](StreamReg16 &src1, StreamReg16 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, (short int){}); P.SU.makePredRegister(pr, dest); },
+    [&](StreamReg32 &src1, StreamReg32 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, int{}); P.SU.makePredRegister(pr, dest); },
+    [&](StreamReg64 &src1, StreamReg64 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, (long int){}); P.SU.makePredRegister(pr, dest); },
+    [&](auto &src1, auto &src2) { assert_msg("Invoking so.p.lt.sg with invalid parameter sizes", false); }
+}, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_p_lt_us.h b/riscv/insns/so_p_lt_us.h
new file mode 100644
index 00000000..0e4d8881
--- /dev/null
+++ b/riscv/insns/so_p_lt_us.h
@@ -0,0 +1,48 @@
+auto dest = insn.uve_pred_rd();
+auto& destPReg = P.SU.predicates[dest];
+auto& src1Reg = P.SU.registers[insn.uve_pred_vs1()];
+auto& src2Reg = P.SU.registers[insn.uve_pred_rs2()];
+auto& predReg = P.SU.predicates[insn.uve_pred()];
+
+auto baseBehaviour = [](auto &destP, auto &src1, auto &src2, auto &pred, auto extra) {
+    /* Each stream's elements must have the same width for content to be
+     * operated on */
+
+
+    assert_msg("Given vectors have different widths", src1.getElementWidth() == src2.getElementWidth());
+    /* We can only operate on the first available values of the stream */
+    auto elements1 = src1.getElements();
+    auto elements2 = src2.getElements();
+    auto destElements = destP.getPredicate();
+    auto validElementsIndex = std::min(src1.getValidElements(), src2.getValidElements());
+
+    auto pi = pred.getPredicate();
+    std::vector<uint8_t> predicate(pred.vLen);
+
+    auto iterator = predicate.begin();
+
+    if (validElementsIndex) {
+        /* Grab used types for storage and operation */
+        using OperationType = decltype(extra);
+        uint8_t value = 0;
+        for (size_t i = 0; i < validElementsIndex; i++) {
+            if(pi.at((i+1)*sizeof(OperationType)-1)){
+                OperationType e1 = readAS<OperationType>(elements1.at(i));
+                OperationType e2 = readAS<OperationType>(elements2.at(i));
+                value = e1 < e2;
+            } else
+                value = readAS<OperationType>(destElements.at(i));
+            std::fill(iterator, iterator+sizeof(OperationType), value);
+            iterator += sizeof(OperationType);
+        }
+    }
+    return predicate;
+};
+
+std::visit(overloaded{
+    [&](StreamReg8 &src1, StreamReg8 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, (unsigned char){}); P.SU.makePredRegister(pr, dest);},
+    [&](StreamReg16 &src1, StreamReg16 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, (unsigned short int){}); P.SU.makePredRegister(pr, dest);},
+    [&](StreamReg32 &src1, StreamReg32 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, (unsigned int){}); P.SU.makePredRegister(pr, dest);},
+    [&](StreamReg64 &src1, StreamReg64 &src2) { auto pr = baseBehaviour(destPReg, src1, src2, predReg, (unsigned long int){}); P.SU.makePredRegister(pr, dest);},
+    [&](auto &src1, auto &src2) { assert_msg("Invoking so.p.lt.us with invalid parameter sizes", false); }
+}, src1Reg, src2Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_p_mv.h b/riscv/insns/so_p_mv.h
new file mode 100644
index 00000000..0531d79e
--- /dev/null
+++ b/riscv/insns/so_p_mv.h
@@ -0,0 +1,18 @@
+auto dest = insn.uve_pred_rd();
+auto &destPReg = P.SU.predicates[dest];
+auto &srcPReg = P.SU.predicates[insn.uve_pred_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+auto pi = predReg.getPredicate(); // instruction predicate
+
+auto predicate = srcPReg.getPredicate();
+size_t size = srcPReg.vLen;
+
+auto destPredicate = destPReg.getPredicate();
+
+for (size_t i = 0; i < size; ++i) {
+    if (!pi.at(i))
+        predicate.at(i) = destPredicate.at(i);
+}
+
+P.SU.makePredRegister(predicate, dest);
diff --git a/riscv/insns/so_p_mvt.h b/riscv/insns/so_p_mvt.h
new file mode 100644
index 00000000..d5028264
--- /dev/null
+++ b/riscv/insns/so_p_mvt.h
@@ -0,0 +1,20 @@
+auto dest = insn.uve_pred_rd();
+auto &destPReg = P.SU.predicates[dest];
+auto &srcPReg = P.SU.predicates[insn.uve_pred_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+auto pi = predReg.getPredicate();
+std::reverse(pi.begin(), pi.end()); // reverse the instruction predicate
+
+auto predicate = srcPReg.getPredicate();
+std::reverse(predicate.begin(), predicate.end()); // reverse the source predicate
+size_t size = srcPReg.vLen;
+
+auto destPredicate = destPReg.getPredicate();
+
+for (size_t i = 0; i < size; ++i) {
+    if (!pi.at(i))
+        predicate.at(i) = destPredicate.at(i);
+}
+
+P.SU.makePredRegister(predicate, dest);
diff --git a/riscv/insns/so_p_not.h b/riscv/insns/so_p_not.h
new file mode 100644
index 00000000..b9d775d5
--- /dev/null
+++ b/riscv/insns/so_p_not.h
@@ -0,0 +1,12 @@
+auto dest = insn.uve_pred_rd();
+auto& src = P.SU.predicates[insn.uve_pred_rs1()];
+auto& destPReg = P.SU.predicates[dest];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+std::vector<uint8_t> predicate = src.getPredicate();
+
+for (auto &p : predicate){
+    p = !p;
+}
+
+P.SU.makePredRegister(predicate, dest);
diff --git a/riscv/insns/so_p_one.h b/riscv/insns/so_p_one.h
new file mode 100644
index 00000000..0cdf3b0d
--- /dev/null
+++ b/riscv/insns/so_p_one.h
@@ -0,0 +1,15 @@
+auto dest = insn.uve_pred_rd();
+auto& destPReg = P.SU.predicates[dest];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+auto pi = predReg.getPredicate();
+auto destElements = destPReg.getPredicate();
+
+std::vector<uint8_t> predicate(destPReg.vLen, 1);
+
+for (size_t i = 0; i < destPReg.vLen; i++){
+    if (!pi.at(i))
+        predicate.at(i) = destElements.at(i); // merging
+}
+
+P.SU.makePredRegister(predicate, dest);
diff --git a/riscv/insns/so_p_vr.h b/riscv/insns/so_p_vr.h
new file mode 100644
index 00000000..4b48b7e2
--- /dev/null
+++ b/riscv/insns/so_p_vr.h
@@ -0,0 +1,36 @@
+auto dest = insn.uve_pred_rd();
+auto& destPReg = P.SU.predicates[dest];
+auto& src1Reg = P.SU.registers[insn.uve_pred_vs1()];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+auto baseBehaviour = [](auto &destP, auto &src1, auto &pred) {
+    auto StorageType = src1.getElementWidth();
+    auto destElements = destP.getPredicate();
+    auto validElementsIndex = src1.getValidElements();
+
+    auto pLen = destP.vLen/sizeof(StorageType);
+
+    auto pi = pred.getPredicate();
+    std::vector<uint8_t> predicate(pLen*sizeof(StorageType));
+
+    auto iterator = predicate.begin();
+
+    uint8_t value = 0;
+
+    for (size_t i = 0; i < pLen; i++) {
+        value = pi.at((i+1)*sizeof(StorageType)-1) ? (uint8_t)(i < validElementsIndex) : destElements.at(i); // // valid elements are 1 in the destination predicate : merging
+        std::fill(iterator, iterator+sizeof(StorageType), value);
+        iterator += sizeof(StorageType);
+    }
+
+    return predicate;
+};
+
+
+std::visit(overloaded{
+    [&](StreamReg8 &src1) { auto pr = baseBehaviour(destPReg, src1, predReg); P.SU.makePredRegister(pr, dest); },
+    [&](StreamReg16 &src1) { auto pr = baseBehaviour(destPReg, src1, predReg); P.SU.makePredRegister(pr, dest); },
+    [&](StreamReg32 &src1) { auto pr = baseBehaviour(destPReg, src1, predReg); P.SU.makePredRegister(pr, dest); },
+    [&](StreamReg64 &src1) { auto pr = baseBehaviour(destPReg, src1, predReg); P.SU.makePredRegister(pr, dest); },
+    [&](auto &src1) { assert_msg("Invoking so.p.vr with invalid parameter sizes", false); }
+}, src1Reg);
\ No newline at end of file
diff --git a/riscv/insns/so_p_zero.h b/riscv/insns/so_p_zero.h
new file mode 100644
index 00000000..3c7e08eb
--- /dev/null
+++ b/riscv/insns/so_p_zero.h
@@ -0,0 +1,15 @@
+auto dest = insn.uve_pred_rd();
+auto& destPReg = P.SU.predicates[dest];
+auto &predReg = P.SU.predicates[insn.uve_pred()];
+
+auto pi = predReg.getPredicate();
+auto destElements = destPReg.getPredicate();
+
+std::vector<uint8_t> predicate(destPReg.vLen, 0);
+
+for (size_t i = 0; i < destPReg.vLen; i++){
+    if (!pi.at(i))
+        predicate.at(i) = destElements.at(i); // merging
+}
+
+P.SU.makePredRegister(predicate, dest);
diff --git a/riscv/insns/so_v_dp_b.h b/riscv/insns/so_v_dp_b.h
new file mode 100644
index 00000000..5c1c1127
--- /dev/null
+++ b/riscv/insns/so_v_dp_b.h
@@ -0,0 +1,37 @@
+#define readRegAS(T, reg) static_cast<T>( READ_REG(reg) )
+
+auto streamReg = insn.uve_rd();
+auto& destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_rs1();
+auto &predReg = P.SU.predicates[insn.uve_v_pred()];
+
+const uint8_t value = readRegAS(uint8_t, baseReg);
+
+auto baseBehaviour = [](auto &dest, auto &pred, const auto value) {
+    auto pi = pred.getPredicate();
+    auto destElements = dest.getElements(false);
+    auto destValidIndex = dest.getVLen();
+    std::vector<uint8_t> out(destValidIndex);
+
+    for (size_t i = 0; i < destValidIndex; ++i)
+        out.at(i) = pi.at((i+1)*sizeof(uint8_t)-1) ? value : destElements.at(i);
+
+    dest.setValidIndex(destValidIndex);
+    dest.setElements(out);
+};
+
+// If the destination register is not configured, we have to build it before the operation so that its element size matches before any calculations are done
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+        /*operateRegister(P.SU, streamReg, [=](auto& reg) {
+          reg.endConfiguration();
+        });*/
+        dest.endConfiguration();
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&, value](StreamReg8 &dest) { baseBehaviour(dest, predReg, value); },
+               [&, value](auto &dest) { assert_msg("Invoking so.v.dp.b with invalid parameter sizes", false); }
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/so_v_dp_d.h b/riscv/insns/so_v_dp_d.h
new file mode 100644
index 00000000..bd8c9fcb
--- /dev/null
+++ b/riscv/insns/so_v_dp_d.h
@@ -0,0 +1,37 @@
+#define readRegAS(T, reg) static_cast<T>( READ_REG(reg) )
+
+auto streamReg = insn.uve_rd();
+auto& destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_rs1();
+auto &predReg = P.SU.predicates[insn.uve_v_pred()];
+
+const uint64_t value = readRegAS(uint64_t, baseReg);
+
+auto baseBehaviour = [](auto &dest, auto &pred, const auto value) {
+    auto pi = pred.getPredicate();
+    auto destElements = dest.getElements(false);
+    auto destValidIndex = dest.getVLen();
+    std::vector<uint64_t> out(destValidIndex);
+
+    for (size_t i = 0; i < destValidIndex; ++i)
+        out.at(i) = pi.at((i+1)*sizeof(uint64_t)-1) ? value : destElements.at(i);
+
+    dest.setValidIndex(destValidIndex);
+    dest.setElements(out);
+};
+
+// If the destination register is not configured, we have to build it before the operation so that its element size matches before any calculations are done
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+        /*operateRegister(P.SU, streamReg, [=](auto& reg) {
+          reg.endConfiguration();
+        });*/
+        dest.endConfiguration();
+    }
+}, destReg);
+
+std::visit(overloaded {
+    [&, value](StreamReg64& dest) { baseBehaviour(dest, predReg, value); },
+    [&, value](auto& dest) { assert_msg("Invoking so.v.dp.d with invalid parameter sizes", false); }
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/so_v_dp_h.h b/riscv/insns/so_v_dp_h.h
new file mode 100644
index 00000000..417a6370
--- /dev/null
+++ b/riscv/insns/so_v_dp_h.h
@@ -0,0 +1,38 @@
+#define readRegAS(T, reg) static_cast<T>( READ_REG(reg) )
+
+auto streamReg = insn.uve_rd();
+auto& destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_rs1();
+auto &predReg = P.SU.predicates[insn.uve_v_pred()];
+
+const uint16_t value = readRegAS(uint16_t, baseReg);
+
+auto baseBehaviour = [](auto &dest, auto &pred, const auto value) {
+    auto pi = pred.getPredicate();
+    auto destElements = dest.getElements(false);
+    auto destValidIndex = dest.getVLen();
+    std::vector<uint16_t> out(destValidIndex);
+
+    for (size_t i = 0; i < destValidIndex; ++i)
+        out.at(i) = pi.at((i+1)*sizeof(uint16_t)-1) ? value : destElements.at(i);
+
+    dest.setValidIndex(destValidIndex);
+    dest.setElements(out);
+};
+
+// If the destination register is not configured, we have to build it before the operation so that its element size matches before any calculations are done
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+        /*operateRegister(P.SU, streamReg, [=](auto& reg) {
+          reg.endConfiguration();
+        });*/
+        dest.endConfiguration();
+    }
+}, destReg);
+
+std::visit(overloaded {
+    [&, value](StreamReg16& dest) { baseBehaviour(dest, predReg, value); },
+    [&, value](auto& dest) { assert_msg("Invoking so.v.dp.h with invalid parameter sizes", false); }
+  },
+destReg);
\ No newline at end of file
diff --git a/riscv/insns/so_v_dp_w.h b/riscv/insns/so_v_dp_w.h
new file mode 100644
index 00000000..34fbbeb5
--- /dev/null
+++ b/riscv/insns/so_v_dp_w.h
@@ -0,0 +1,38 @@
+#define readRegAS(T, reg) static_cast<T>( READ_REG(reg) )
+
+auto streamReg = insn.uve_rd();
+auto& destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_rs1();
+auto &predReg = P.SU.predicates[insn.uve_v_pred()];
+
+const uint32_t value = readRegAS(uint32_t, baseReg);
+
+auto baseBehaviour = [](auto &dest, auto &pred, const auto value) {
+    auto pi = pred.getPredicate();
+    auto destElements = dest.getElements(false);
+    auto destValidIndex = dest.getVLen();
+    std::vector<uint32_t> out(destValidIndex);
+
+    for (size_t i = 0; i < destValidIndex; ++i)
+        out.at(i) = pi.at((i+1)*sizeof(uint32_t)-1) ? value : destElements.at(i);
+
+    dest.setValidIndex(destValidIndex);
+    dest.setElements(out);
+};
+
+// If the destination register is not configured, we have to build it before the operation so that its element size matches before any calculations are done
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+        /*operateRegister(P.SU, streamReg, [=](auto& reg) {
+          reg.endConfiguration();
+        });*/
+        dest.endConfiguration();
+    }
+}, destReg);
+
+std::visit(overloaded {
+    [&, value](StreamReg32& dest) { baseBehaviour(dest, predReg, value); },
+    [&, value](auto& dest) { assert_msg("Invoking so.v.dp.w with invalid parameter sizes", false); }
+  },
+destReg);
\ No newline at end of file
diff --git a/riscv/insns/so_v_mv.h b/riscv/insns/so_v_mv.h
new file mode 100644
index 00000000..5645536f
--- /dev/null
+++ b/riscv/insns/so_v_mv.h
@@ -0,0 +1,54 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_v_pred()];
+
+
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred) {
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    /* We can only operate on the first available values of the stream */
+    auto elements = src.getElements();
+    auto destElements = dest.getElements(false); // doesn't iterate the stream
+    auto validElementsIndex = src.getValidElements();
+    std::vector<StorageType> out(dest.getVLen());
+    auto pi = pred.getPredicate();
+
+    //std::cout << "MV   ";
+    for (size_t i = 0; i < validElementsIndex; ++i){
+        out.at(i) = pi.at((i+1)*sizeof(StorageType)-1) ? elements.at(i) : destElements.at(i);
+        //std::cout << readAS<double>(out.at(i)) << " ";
+    }
+    //std::cout << "\n";
+    dest.setValidIndex(validElementsIndex);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+			dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+			dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+			dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg8>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+			dest.endConfiguration();
+        } else {
+            assert_msg("Trying to run so.v.mv with invalid src type", false);
+        }
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg); },
+               [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg); },
+               [&](StreamReg16 &dest, StreamReg16 &src) { baseBehaviour(dest, src, predReg); },
+               [&](StreamReg8 &dest, StreamReg8 &src) { baseBehaviour(dest, src, predReg); },
+               [&](auto &dest, auto &src) { assert_msg("Invoking so.v.mv with invalid parameter sizes", false); }},
+           destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_v_mv_stream.h b/riscv/insns/so_v_mv_stream.h
new file mode 100644
index 00000000..fdf6acf4
--- /dev/null
+++ b/riscv/insns/so_v_mv_stream.h
@@ -0,0 +1,52 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_v_pred()];
+
+
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred) {
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    /* We can only operate on the first available values of the stream */
+    auto elements = src.getElements(false); // doesn't iterate the stream
+    auto destElements = dest.getElements(false); // doesn't iterate the stream
+    auto validElementsIndex = src.getValidElements();
+    std::vector<StorageType> out(dest.getVLen());
+    auto pi = pred.getPredicate();
+
+    for (size_t i = 0; i < validElementsIndex; ++i)
+        out.at(i) = pi.at((i+1)*sizeof(StorageType)-1) ? elements.at(i) : destElements.at(i);
+
+    dest.setValidIndex(validElementsIndex);
+    dest.setElements(out);
+
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+			dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+			dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+			dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg8>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+			dest.endConfiguration();
+        } else {
+            assert_msg("Trying to run so.v.mv.stream with invalid src type", false);
+        }
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg); },
+               [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg); },
+               [&](StreamReg16 &dest, StreamReg16 &src) { baseBehaviour(dest, src, predReg); },
+               [&](StreamReg8 &dest, StreamReg8 &src) { baseBehaviour(dest, src, predReg); },
+               [&](auto &dest, auto &src) { assert_msg("Invoking so.v.mv.stream with invalid parameter sizes", false); }},
+           destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_v_mvsv_b.h b/riscv/insns/so_v_mvsv_b.h
new file mode 100644
index 00000000..cc5747da
--- /dev/null
+++ b/riscv/insns/so_v_mvsv_b.h
@@ -0,0 +1,31 @@
+#define readRegAS(T, reg) static_cast<T>( READ_REG(reg) )
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_rs1();
+
+const uint8_t value = readRegAS(uint8_t, baseReg);
+
+
+auto baseBehaviour = [](auto &dest, auto value) {
+    std::vector<uint8_t> out(dest.getVLen());
+
+    out.at(0) = value;
+
+    dest.setMode(RegisterMode::Scalar);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+		dest.endConfiguration();
+    }
+}, destReg);
+
+std::visit(overloaded{
+    [&](StreamReg8 &dest) { baseBehaviour(dest, value); },
+    [&](auto &dest) { assert_msg("Invoking so.v.mvsv.b with invalid parameter sizes", false); }},
+destReg);
\ No newline at end of file
diff --git a/riscv/insns/so_v_mvsv_d.h b/riscv/insns/so_v_mvsv_d.h
new file mode 100644
index 00000000..c50ba737
--- /dev/null
+++ b/riscv/insns/so_v_mvsv_d.h
@@ -0,0 +1,31 @@
+#define readRegAS(T, reg) static_cast<T>( READ_REG(reg) )
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_rs1();
+
+const uint64_t value = readRegAS(uint64_t, baseReg);
+
+
+auto baseBehaviour = [](auto &dest, auto value) {
+    std::vector<uint64_t> out(dest.getVLen());
+
+    out.at(0) = value;
+
+    dest.setMode(RegisterMode::Scalar);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+		dest.endConfiguration();
+    }
+}, destReg);
+
+std::visit(overloaded{
+    [&](StreamReg64 &dest) { baseBehaviour(dest, value); },
+    [&](auto &dest) { assert_msg("Invoking so.v.mvsv.d with invalid parameter sizes", false); }},
+destReg);
\ No newline at end of file
diff --git a/riscv/insns/so_v_mvsv_h.h b/riscv/insns/so_v_mvsv_h.h
new file mode 100644
index 00000000..99080812
--- /dev/null
+++ b/riscv/insns/so_v_mvsv_h.h
@@ -0,0 +1,31 @@
+#define readRegAS(T, reg) static_cast<T>( READ_REG(reg) )
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_rs1();
+
+const uint16_t value = readRegAS(uint16_t, baseReg);
+
+
+auto baseBehaviour = [](auto &dest, auto value) {
+    std::vector<uint16_t> out(dest.getVLen());
+
+    out.at(0) = value;
+
+    dest.setMode(RegisterMode::Scalar);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+		dest.endConfiguration();
+    }
+}, destReg);
+
+std::visit(overloaded{
+    [&](StreamReg16 &dest) { baseBehaviour(dest, value); },
+    [&](auto &dest) { assert_msg("Invoking so.v.mvsv.h with invalid parameter sizes", false); }},
+destReg);
\ No newline at end of file
diff --git a/riscv/insns/so_v_mvsv_w.h b/riscv/insns/so_v_mvsv_w.h
new file mode 100644
index 00000000..017d10b2
--- /dev/null
+++ b/riscv/insns/so_v_mvsv_w.h
@@ -0,0 +1,31 @@
+#define readRegAS(T, reg) static_cast<T>( READ_REG(reg) )
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_rs1();
+
+const uint32_t value = readRegAS(uint32_t, baseReg);
+
+
+auto baseBehaviour = [](auto &dest, auto value) {
+    std::vector<uint32_t> out(dest.getVLen());
+
+    out.at(0) = value;
+
+    dest.setMode(RegisterMode::Scalar);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+		dest.endConfiguration();
+    }
+}, destReg);
+
+std::visit(overloaded{
+    [&](StreamReg32 &dest) { baseBehaviour(dest, value); },
+    [&](auto &dest) { assert_msg("Invoking so.v.mvsv.w with invalid parameter sizes", false); }},
+destReg);
\ No newline at end of file
diff --git a/riscv/insns/so_v_mvt.h b/riscv/insns/so_v_mvt.h
new file mode 100644
index 00000000..9a34b92d
--- /dev/null
+++ b/riscv/insns/so_v_mvt.h
@@ -0,0 +1,57 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_v_pred()];
+
+
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred) {
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    /* We can only operate on the first available values of the stream */
+    auto validElementsIndex = src.getValidElements();
+
+    auto elements = src.getElements();
+    std::reverse(elements.begin(), elements.begin()+validElementsIndex); // reverse the valid source elements
+
+    auto destElements = dest.getElements(false); // doesn't iterate the stream
+
+    std::vector<StorageType> out(dest.getVLen());
+
+    auto pi = pred.getPredicate();
+    std::reverse(pi.begin(), pi.begin()+validElementsIndex*sizeof(StorageType)); // reverse the necessary instruction predicate
+
+    for (size_t i = 0; i < validElementsIndex; ++i)
+        out.at(i) = pi.at((i+1)*sizeof(StorageType)-1) ? elements.at(i) : destElements.at(i);
+
+    dest.setValidIndex(validElementsIndex);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+			dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+			dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+			dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg8>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+			dest.endConfiguration();
+        } else {
+            assert_msg("Trying to run so.v.mvt with invalid src type", false);
+        }
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg); },
+               [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg); },
+               [&](StreamReg16 &dest, StreamReg16 &src) { baseBehaviour(dest, src, predReg); },
+               [&](StreamReg8 &dest, StreamReg8 &src) { baseBehaviour(dest, src, predReg); },
+               [&](auto &dest, auto &src) { assert_msg("Invoking so.v.mvt with invalid parameter sizes", false); }},
+           destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_v_mvt_stream.h b/riscv/insns/so_v_mvt_stream.h
new file mode 100644
index 00000000..cf084add
--- /dev/null
+++ b/riscv/insns/so_v_mvt_stream.h
@@ -0,0 +1,57 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto &srcReg = P.SU.registers[insn.uve_rs1()];
+auto &predReg = P.SU.predicates[insn.uve_v_pred()];
+
+
+auto baseBehaviour = [](auto &dest, auto &src, auto &pred) {
+    using StorageType = typename std::remove_reference_t<decltype(dest)>::ElementsType;
+    /* We can only operate on the first available values of the stream */
+    auto validElementsIndex = src.getValidElements();
+
+    auto elements = src.getElements(false); // doesn't iterate the stream
+    std::reverse(elements.begin(), elements.begin()+validElementsIndex); // reverse the valid source elements
+
+    auto destElements = dest.getElements(false); // doesn't iterate the stream
+
+    std::vector<StorageType> out(dest.getVLen());
+
+    auto pi = pred.getPredicate();
+    std::reverse(pi.begin(), pi.begin()+validElementsIndex*sizeof(StorageType)); // reverse the necessary instruction predicate
+
+    for (size_t i = 0; i < validElementsIndex; ++i)
+        out.at(i) = pi.at((i+1)*sizeof(StorageType)-1) ? elements.at(i) : destElements.at(i);
+
+    dest.setValidIndex(validElementsIndex);
+    dest.setElements(out);
+};
+
+/* If the destination register is not configured, we have to build it before the
+operation so that its element size matches before any calculations are done */
+std::visit([&](auto &dest) {
+    if (dest.getStatus() == RegisterStatus::NotConfigured) {
+        if (std::holds_alternative<StreamReg64>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint64_t>(streamReg);
+			dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg32>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint32_t>(streamReg);
+			dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg16>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint16_t>(streamReg);
+			dest.endConfiguration();
+        } else if (std::holds_alternative<StreamReg8>(srcReg)) {
+            P.SU.makeStreamRegister<std::uint8_t>(streamReg);
+			dest.endConfiguration();
+        } else {
+            assert_msg("Trying to run so.v.mvt.stream with invalid src type", false);
+        }
+    }
+}, destReg);
+
+std::visit(overloaded{
+               [&](StreamReg64 &dest, StreamReg64 &src) { baseBehaviour(dest, src, predReg); },
+               [&](StreamReg32 &dest, StreamReg32 &src) { baseBehaviour(dest, src, predReg); },
+               [&](StreamReg16 &dest, StreamReg16 &src) { baseBehaviour(dest, src, predReg); },
+               [&](StreamReg8 &dest, StreamReg8 &src) { baseBehaviour(dest, src, predReg); },
+               [&](auto &dest, auto &src) { assert_msg("Invoking so.v.mvt.stream with invalid parameter sizes", false); }},
+           destReg, srcReg);
\ No newline at end of file
diff --git a/riscv/insns/so_v_mvvs.h b/riscv/insns/so_v_mvvs.h
new file mode 100644
index 00000000..643515d3
--- /dev/null
+++ b/riscv/insns/so_v_mvvs.h
@@ -0,0 +1,15 @@
+auto src = insn.uve_rs1();
+auto &srcReg = P.SU.registers[src];
+auto destReg = insn.uve_rd();
+
+auto baseBehaviour = [](auto &src, auto &value) {
+    value = src.getElements(false).at(0);
+};
+
+std::visit(overloaded{
+    [&](StreamReg8 &src) { uint8_t value; baseBehaviour(src, value); WRITE_REG(destReg, value);},
+    [&](StreamReg16 &src) { uint16_t value; baseBehaviour(src, value); WRITE_REG(destReg, value);},
+    [&](StreamReg32 &src) { uint32_t value; baseBehaviour(src, value); WRITE_REG(destReg, value);},
+    [&](StreamReg64 &src) { uint64_t value; baseBehaviour(src, value); WRITE_REG(destReg, value);},
+    [&](auto &src) { assert_msg("Invoking so.v.mvvs with invalid parameter sizes", false); }},
+srcReg);
diff --git a/riscv/insns/ss_app.h b/riscv/insns/ss_app.h
new file mode 100644
index 00000000..f87d494d
--- /dev/null
+++ b/riscv/insns/ss_app.h
@@ -0,0 +1,12 @@
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t offset = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+std::visit([&](auto &reg) {
+    reg.addDimension(dimension_t(offset*reg.elementWidth, size, stride));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_ind_ofs_add_1.h b/riscv/insns/ss_app_ind_ofs_add_1.h
new file mode 100644
index 00000000..4aff342f
--- /dev/null
+++ b/riscv/insns/ss_app_ind_ofs_add_1.h
@@ -0,0 +1,6 @@
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addDynamicModifier(dynamicModifier_t(Target::Offset, dynamicBehaviour::Add, origin, &(P.SU), 0));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_ind_ofs_dec_1.h b/riscv/insns/ss_app_ind_ofs_dec_1.h
new file mode 100644
index 00000000..e98b7062
--- /dev/null
+++ b/riscv/insns/ss_app_ind_ofs_dec_1.h
@@ -0,0 +1,6 @@
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addDynamicModifier(dynamicModifier_t(Target::Offset, dynamicBehaviour::Decrement, origin, &(P.SU), 0));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_ind_ofs_inc_1.h b/riscv/insns/ss_app_ind_ofs_inc_1.h
new file mode 100644
index 00000000..1de69cf5
--- /dev/null
+++ b/riscv/insns/ss_app_ind_ofs_inc_1.h
@@ -0,0 +1,6 @@
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addDynamicModifier(dynamicModifier_t(Target::Offset, dynamicBehaviour::Increment, origin, &(P.SU), 0));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_ind_ofs_set_1.h b/riscv/insns/ss_app_ind_ofs_set_1.h
new file mode 100644
index 00000000..54ae3ca9
--- /dev/null
+++ b/riscv/insns/ss_app_ind_ofs_set_1.h
@@ -0,0 +1,6 @@
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addDynamicModifier(dynamicModifier_t(Target::Offset, dynamicBehaviour::Set, origin, &(P.SU), 0));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_ind_ofs_sg_add.h b/riscv/insns/ss_app_ind_ofs_sg_add.h
new file mode 100644
index 00000000..641a357e
--- /dev/null
+++ b/riscv/insns/ss_app_ind_ofs_sg_add.h
@@ -0,0 +1,8 @@
+// ss.app.ind.sca.ofs.add
+
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addScatterGModifier(scatterGModifier_t(dynamicBehaviour::Add, origin, &(P.SU)));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_ind_ofs_sg_dec.h b/riscv/insns/ss_app_ind_ofs_sg_dec.h
new file mode 100644
index 00000000..c1bc37fe
--- /dev/null
+++ b/riscv/insns/ss_app_ind_ofs_sg_dec.h
@@ -0,0 +1,8 @@
+// ss.app.ind.sca.ofs.add
+
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addScatterGModifier(scatterGModifier_t(dynamicBehaviour::Decrement, origin, &(P.SU)));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_ind_ofs_sg_inc.h b/riscv/insns/ss_app_ind_ofs_sg_inc.h
new file mode 100644
index 00000000..22810103
--- /dev/null
+++ b/riscv/insns/ss_app_ind_ofs_sg_inc.h
@@ -0,0 +1,8 @@
+// ss.app.ind.sca.ofs.add
+
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addScatterGModifier(scatterGModifier_t(dynamicBehaviour::Increment, origin, &(P.SU)));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_ind_ofs_sg_set.h b/riscv/insns/ss_app_ind_ofs_sg_set.h
new file mode 100644
index 00000000..ffe2ab32
--- /dev/null
+++ b/riscv/insns/ss_app_ind_ofs_sg_set.h
@@ -0,0 +1,8 @@
+// ss.app.ind.sca.ofs.add
+
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addScatterGModifier(scatterGModifier_t(dynamicBehaviour::Set, origin, &(P.SU)));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_ind_ofs_sg_sub.h b/riscv/insns/ss_app_ind_ofs_sg_sub.h
new file mode 100644
index 00000000..6842d989
--- /dev/null
+++ b/riscv/insns/ss_app_ind_ofs_sg_sub.h
@@ -0,0 +1,8 @@
+// ss.app.ind.sca.ofs.add
+
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addScatterGModifier(scatterGModifier_t(dynamicBehaviour::Subtract, origin, &(P.SU)));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_ind_ofs_sub_1.h b/riscv/insns/ss_app_ind_ofs_sub_1.h
new file mode 100644
index 00000000..ceaa4aee
--- /dev/null
+++ b/riscv/insns/ss_app_ind_ofs_sub_1.h
@@ -0,0 +1,6 @@
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addDynamicModifier(dynamicModifier_t(Target::Offset, dynamicBehaviour::Subtract, origin, &(P.SU), 0));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_ind_siz_add_1.h b/riscv/insns/ss_app_ind_siz_add_1.h
new file mode 100644
index 00000000..a1c4010d
--- /dev/null
+++ b/riscv/insns/ss_app_ind_siz_add_1.h
@@ -0,0 +1,6 @@
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addDynamicModifier(dynamicModifier_t(Target::Size, dynamicBehaviour::Add, origin, &(P.SU), 0));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_ind_siz_dec_1.h b/riscv/insns/ss_app_ind_siz_dec_1.h
new file mode 100644
index 00000000..d9739ee4
--- /dev/null
+++ b/riscv/insns/ss_app_ind_siz_dec_1.h
@@ -0,0 +1,6 @@
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addDynamicModifier(dynamicModifier_t(Target::Size, dynamicBehaviour::Decrement, origin, &(P.SU), 0));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_ind_siz_inc_1.h b/riscv/insns/ss_app_ind_siz_inc_1.h
new file mode 100644
index 00000000..9d858283
--- /dev/null
+++ b/riscv/insns/ss_app_ind_siz_inc_1.h
@@ -0,0 +1,6 @@
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addDynamicModifier(dynamicModifier_t(Target::Size, dynamicBehaviour::Increment, origin, &(P.SU), 0));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_ind_siz_set_1.h b/riscv/insns/ss_app_ind_siz_set_1.h
new file mode 100644
index 00000000..b9334484
--- /dev/null
+++ b/riscv/insns/ss_app_ind_siz_set_1.h
@@ -0,0 +1,6 @@
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addDynamicModifier(dynamicModifier_t(Target::Size, dynamicBehaviour::Set, origin, &(P.SU), 0));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_ind_siz_sub_1.h b/riscv/insns/ss_app_ind_siz_sub_1.h
new file mode 100644
index 00000000..b0c6f0f9
--- /dev/null
+++ b/riscv/insns/ss_app_ind_siz_sub_1.h
@@ -0,0 +1,6 @@
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addDynamicModifier(dynamicModifier_t(Target::Size, dynamicBehaviour::Subtract, origin, &(P.SU), 0));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_ind_str_add_1.h b/riscv/insns/ss_app_ind_str_add_1.h
new file mode 100644
index 00000000..82152d53
--- /dev/null
+++ b/riscv/insns/ss_app_ind_str_add_1.h
@@ -0,0 +1,6 @@
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addDynamicModifier(dynamicModifier_t(Target::Stride, dynamicBehaviour::Add, origin, &(P.SU), 0));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_ind_str_dec_1.h b/riscv/insns/ss_app_ind_str_dec_1.h
new file mode 100644
index 00000000..c3fa5c1d
--- /dev/null
+++ b/riscv/insns/ss_app_ind_str_dec_1.h
@@ -0,0 +1,6 @@
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addDynamicModifier(dynamicModifier_t(Target::Stride, dynamicBehaviour::Decrement, origin, &(P.SU), 0));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_ind_str_inc_1.h b/riscv/insns/ss_app_ind_str_inc_1.h
new file mode 100644
index 00000000..9fb8955f
--- /dev/null
+++ b/riscv/insns/ss_app_ind_str_inc_1.h
@@ -0,0 +1,6 @@
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addDynamicModifier(dynamicModifier_t(Target::Stride, dynamicBehaviour::Increment, origin, &(P.SU), 0));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_ind_str_set_1.h b/riscv/insns/ss_app_ind_str_set_1.h
new file mode 100644
index 00000000..bffba77d
--- /dev/null
+++ b/riscv/insns/ss_app_ind_str_set_1.h
@@ -0,0 +1,6 @@
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addDynamicModifier(dynamicModifier_t(Target::Stride, dynamicBehaviour::Set, origin, &(P.SU), 0));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_ind_str_sub_1.h b/riscv/insns/ss_app_ind_str_sub_1.h
new file mode 100644
index 00000000..eee0fbdd
--- /dev/null
+++ b/riscv/insns/ss_app_ind_str_sub_1.h
@@ -0,0 +1,6 @@
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addDynamicModifier(dynamicModifier_t(Target::Stride, dynamicBehaviour::Subtract, origin, &(P.SU), 0));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_mod_ofs_dec_1.h b/riscv/insns/ss_app_mod_ofs_dec_1.h
new file mode 100644
index 00000000..bffe8581
--- /dev/null
+++ b/riscv/insns/ss_app_mod_ofs_dec_1.h
@@ -0,0 +1,10 @@
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto sizeReg = insn.uve_mod_size();
+auto dispReg = insn.uve_mod_disp();
+
+//unsigned int size = READ_REG(sizeReg);
+int32_t disp = READ_REG(dispReg);
+
+std::visit([&](auto &reg) {
+    reg.addStaticModifier(staticModifier_t(Target::Offset, staticBehaviour::Decrement, disp, 0));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_mod_ofs_inc_1.h b/riscv/insns/ss_app_mod_ofs_inc_1.h
new file mode 100644
index 00000000..0ff7b72b
--- /dev/null
+++ b/riscv/insns/ss_app_mod_ofs_inc_1.h
@@ -0,0 +1,10 @@
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto sizeReg = insn.uve_mod_size();
+auto dispReg = insn.uve_mod_disp();
+
+//unsigned int size = READ_REG(sizeReg);
+int32_t disp = READ_REG(dispReg);
+
+std::visit([&](auto &reg) {
+    reg.addStaticModifier(staticModifier_t(Target::Offset, staticBehaviour::Increment, disp, 0));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_mod_siz_dec_1.h b/riscv/insns/ss_app_mod_siz_dec_1.h
new file mode 100644
index 00000000..146c90de
--- /dev/null
+++ b/riscv/insns/ss_app_mod_siz_dec_1.h
@@ -0,0 +1,10 @@
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto sizeReg = insn.uve_mod_size();
+auto dispReg = insn.uve_mod_disp();
+
+//unsigned int size = READ_REG(sizeReg);
+int32_t disp = READ_REG(dispReg);
+
+std::visit([&](auto &reg) {
+    reg.addStaticModifier(staticModifier_t(Target::Size, staticBehaviour::Decrement, disp, 0));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_mod_siz_inc_1.h b/riscv/insns/ss_app_mod_siz_inc_1.h
new file mode 100644
index 00000000..5a6f95d1
--- /dev/null
+++ b/riscv/insns/ss_app_mod_siz_inc_1.h
@@ -0,0 +1,10 @@
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto sizeReg = insn.uve_mod_size();
+auto dispReg = insn.uve_mod_disp();
+
+//unsigned int size = READ_REG(sizeReg);
+int32_t disp = READ_REG(dispReg);
+
+std::visit([&](auto &reg) {
+    reg.addStaticModifier(staticModifier_t(Target::Size, staticBehaviour::Increment, disp, 0));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_mod_str_dec_1.h b/riscv/insns/ss_app_mod_str_dec_1.h
new file mode 100644
index 00000000..f33d1583
--- /dev/null
+++ b/riscv/insns/ss_app_mod_str_dec_1.h
@@ -0,0 +1,10 @@
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto sizeReg = insn.uve_mod_size();
+auto dispReg = insn.uve_mod_disp();
+
+//unsigned int size = READ_REG(sizeReg);
+int32_t disp = READ_REG(dispReg);
+
+std::visit([&](auto &reg) {
+    reg.addStaticModifier(staticModifier_t(Target::Stride, staticBehaviour::Decrement, disp, 0));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_app_mod_str_inc_1.h b/riscv/insns/ss_app_mod_str_inc_1.h
new file mode 100644
index 00000000..3560e622
--- /dev/null
+++ b/riscv/insns/ss_app_mod_str_inc_1.h
@@ -0,0 +1,10 @@
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto sizeReg = insn.uve_mod_size();
+auto dispReg = insn.uve_mod_disp();
+
+//unsigned int size = READ_REG(sizeReg);
+int32_t disp = READ_REG(dispReg);
+
+std::visit([&](auto &reg) {
+    reg.addStaticModifier(staticModifier_t(Target::Stride, staticBehaviour::Increment, disp, 0));
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_cfg_vec.h b/riscv/insns/ss_cfg_vec.h
new file mode 100644
index 00000000..f5c61717
--- /dev/null
+++ b/riscv/insns/ss_cfg_vec.h
@@ -0,0 +1,5 @@
+auto &streamReg = P.SU.registers[insn.uve_rd()];
+
+std::visit([&](auto &reg) {
+    reg.configureVecDim();
+}, streamReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_end.h b/riscv/insns/ss_end.h
new file mode 100644
index 00000000..eda0bb91
--- /dev/null
+++ b/riscv/insns/ss_end.h
@@ -0,0 +1,13 @@
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t offset = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+std::visit([&](auto &reg) {
+  reg.addDimension(dimension_t(offset*reg.elementWidth, size, stride));
+  reg.endConfiguration();
+}, destReg);
diff --git a/riscv/insns/ss_end_ind_ofs_sg_add.h b/riscv/insns/ss_end_ind_ofs_sg_add.h
new file mode 100644
index 00000000..00776732
--- /dev/null
+++ b/riscv/insns/ss_end_ind_ofs_sg_add.h
@@ -0,0 +1,9 @@
+// ss.app.ind.sca.ofs.add
+
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addScatterGModifier(scatterGModifier_t(dynamicBehaviour::Add, origin, &(P.SU)));
+    reg.endConfiguration();
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_end_ind_ofs_sg_dec.h b/riscv/insns/ss_end_ind_ofs_sg_dec.h
new file mode 100644
index 00000000..9f932922
--- /dev/null
+++ b/riscv/insns/ss_end_ind_ofs_sg_dec.h
@@ -0,0 +1,9 @@
+// ss.app.ind.sca.ofs.add
+
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addScatterGModifier(scatterGModifier_t(dynamicBehaviour::Decrement, origin, &(P.SU)));
+    reg.endConfiguration();
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_end_ind_ofs_sg_inc.h b/riscv/insns/ss_end_ind_ofs_sg_inc.h
new file mode 100644
index 00000000..865b42ed
--- /dev/null
+++ b/riscv/insns/ss_end_ind_ofs_sg_inc.h
@@ -0,0 +1,9 @@
+// ss.app.ind.sca.ofs.add
+
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addScatterGModifier(scatterGModifier_t(dynamicBehaviour::Increment, origin, &(P.SU)));
+    reg.endConfiguration();
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_end_ind_ofs_sg_set.h b/riscv/insns/ss_end_ind_ofs_sg_set.h
new file mode 100644
index 00000000..b082265e
--- /dev/null
+++ b/riscv/insns/ss_end_ind_ofs_sg_set.h
@@ -0,0 +1,9 @@
+// ss.app.ind.sca.ofs.add
+
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addScatterGModifier(scatterGModifier_t(dynamicBehaviour::Set, origin, &(P.SU)));
+    reg.endConfiguration();
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_end_ind_ofs_sg_sub.h b/riscv/insns/ss_end_ind_ofs_sg_sub.h
new file mode 100644
index 00000000..40d0c275
--- /dev/null
+++ b/riscv/insns/ss_end_ind_ofs_sg_sub.h
@@ -0,0 +1,9 @@
+// ss.app.ind.sca.ofs.add
+
+auto &destReg = P.SU.registers[insn.uve_rd()];
+auto origin = insn.uve_mod_origin();
+
+std::visit([&](auto &reg) {
+    reg.addScatterGModifier(scatterGModifier_t(dynamicBehaviour::Subtract, origin, &(P.SU)));
+    reg.endConfiguration();
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_ld_b.h b/riscv/insns/ss_sta_ld_b.h
new file mode 100644
index 00000000..3876e710
--- /dev/null
+++ b/riscv/insns/ss_sta_ld_b.h
@@ -0,0 +1,17 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+P.SU.makeStreamRegister<std::uint8_t>(streamReg, RegisterConfig::Load);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_ld_b_inds.h b/riscv/insns/ss_sta_ld_b_inds.h
new file mode 100644
index 00000000..3876e710
--- /dev/null
+++ b/riscv/insns/ss_sta_ld_b_inds.h
@@ -0,0 +1,17 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+P.SU.makeStreamRegister<std::uint8_t>(streamReg, RegisterConfig::Load);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_ld_b_v.h b/riscv/insns/ss_sta_ld_b_v.h
new file mode 100644
index 00000000..85c36f07
--- /dev/null
+++ b/riscv/insns/ss_sta_ld_b_v.h
@@ -0,0 +1,18 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+P.SU.makeStreamRegister<std::uint8_t>(streamReg, RegisterConfig::Load);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+    reg.configureVecDim();
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_ld_b_v_1.h b/riscv/insns/ss_sta_ld_b_v_1.h
new file mode 100644
index 00000000..497ecb01
--- /dev/null
+++ b/riscv/insns/ss_sta_ld_b_v_1.h
@@ -0,0 +1,18 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+P.SU.makeStreamRegister<std::uint8_t>(streamReg, RegisterConfig::Load);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+    reg.configureVecDim(0);
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_ld_d.h b/riscv/insns/ss_sta_ld_d.h
new file mode 100644
index 00000000..343038e4
--- /dev/null
+++ b/riscv/insns/ss_sta_ld_d.h
@@ -0,0 +1,19 @@
+#define readRegAS(T, reg) static_cast<T>(READ_REG(reg))
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+P.SU.makeStreamRegister<std::uint64_t>(streamReg, RegisterConfig::Load);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_ld_d_inds.h b/riscv/insns/ss_sta_ld_d_inds.h
new file mode 100644
index 00000000..343038e4
--- /dev/null
+++ b/riscv/insns/ss_sta_ld_d_inds.h
@@ -0,0 +1,19 @@
+#define readRegAS(T, reg) static_cast<T>(READ_REG(reg))
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+P.SU.makeStreamRegister<std::uint64_t>(streamReg, RegisterConfig::Load);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_ld_d_v.h b/riscv/insns/ss_sta_ld_d_v.h
new file mode 100644
index 00000000..5ef0a4f4
--- /dev/null
+++ b/riscv/insns/ss_sta_ld_d_v.h
@@ -0,0 +1,20 @@
+#define readRegAS(T, reg) static_cast<T>(READ_REG(reg))
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+P.SU.makeStreamRegister<std::uint64_t>(streamReg, RegisterConfig::Load);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+    reg.configureVecDim();
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_ld_d_v_1.h b/riscv/insns/ss_sta_ld_d_v_1.h
new file mode 100644
index 00000000..960f9082
--- /dev/null
+++ b/riscv/insns/ss_sta_ld_d_v_1.h
@@ -0,0 +1,20 @@
+#define readRegAS(T, reg) static_cast<T>(READ_REG(reg))
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+P.SU.makeStreamRegister<std::uint64_t>(streamReg, RegisterConfig::Load);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+    reg.configureVecDim(0);
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_ld_h.h b/riscv/insns/ss_sta_ld_h.h
new file mode 100644
index 00000000..40c564a3
--- /dev/null
+++ b/riscv/insns/ss_sta_ld_h.h
@@ -0,0 +1,17 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+P.SU.makeStreamRegister<std::uint16_t>(streamReg, RegisterConfig::Load);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_ld_h_inds.h b/riscv/insns/ss_sta_ld_h_inds.h
new file mode 100644
index 00000000..40c564a3
--- /dev/null
+++ b/riscv/insns/ss_sta_ld_h_inds.h
@@ -0,0 +1,17 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+P.SU.makeStreamRegister<std::uint16_t>(streamReg, RegisterConfig::Load);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_ld_h_v.h b/riscv/insns/ss_sta_ld_h_v.h
new file mode 100644
index 00000000..d2b348d6
--- /dev/null
+++ b/riscv/insns/ss_sta_ld_h_v.h
@@ -0,0 +1,18 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+P.SU.makeStreamRegister<std::uint16_t>(streamReg, RegisterConfig::Load);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+    reg.configureVecDim();
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_ld_h_v_1.h b/riscv/insns/ss_sta_ld_h_v_1.h
new file mode 100644
index 00000000..12754f8a
--- /dev/null
+++ b/riscv/insns/ss_sta_ld_h_v_1.h
@@ -0,0 +1,18 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+P.SU.makeStreamRegister<std::uint16_t>(streamReg, RegisterConfig::Load);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+    reg.configureVecDim(0);
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_ld_w.h b/riscv/insns/ss_sta_ld_w.h
new file mode 100644
index 00000000..a7569499
--- /dev/null
+++ b/riscv/insns/ss_sta_ld_w.h
@@ -0,0 +1,17 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+P.SU.makeStreamRegister<std::uint32_t>(streamReg, RegisterConfig::Load);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_ld_w_inds.h b/riscv/insns/ss_sta_ld_w_inds.h
new file mode 100644
index 00000000..a7569499
--- /dev/null
+++ b/riscv/insns/ss_sta_ld_w_inds.h
@@ -0,0 +1,17 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+P.SU.makeStreamRegister<std::uint32_t>(streamReg, RegisterConfig::Load);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_ld_w_v.h b/riscv/insns/ss_sta_ld_w_v.h
new file mode 100644
index 00000000..dd6a994b
--- /dev/null
+++ b/riscv/insns/ss_sta_ld_w_v.h
@@ -0,0 +1,18 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+P.SU.makeStreamRegister<std::uint32_t>(streamReg, RegisterConfig::Load);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+    reg.configureVecDim();
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_ld_w_v_1.h b/riscv/insns/ss_sta_ld_w_v_1.h
new file mode 100644
index 00000000..97fd8321
--- /dev/null
+++ b/riscv/insns/ss_sta_ld_w_v_1.h
@@ -0,0 +1,18 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+P.SU.makeStreamRegister<std::uint32_t>(streamReg, RegisterConfig::Load);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+    reg.configureVecDim(0);
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_st_b.h b/riscv/insns/ss_sta_st_b.h
new file mode 100644
index 00000000..a7505ce1
--- /dev/null
+++ b/riscv/insns/ss_sta_st_b.h
@@ -0,0 +1,20 @@
+#define readRegAS(T, reg) static_cast<T>( READ_REG(reg) )
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+
+P.SU.makeStreamRegister<std::uint8_t>(streamReg, RegisterConfig::Store);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_st_b_v.h b/riscv/insns/ss_sta_st_b_v.h
new file mode 100644
index 00000000..37b0c509
--- /dev/null
+++ b/riscv/insns/ss_sta_st_b_v.h
@@ -0,0 +1,21 @@
+#define readRegAS(T, reg) static_cast<T>( READ_REG(reg) )
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+
+P.SU.makeStreamRegister<std::uint8_t>(streamReg, RegisterConfig::Store);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+    reg.configureVecDim();
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_st_b_v_1.h b/riscv/insns/ss_sta_st_b_v_1.h
new file mode 100644
index 00000000..4b373928
--- /dev/null
+++ b/riscv/insns/ss_sta_st_b_v_1.h
@@ -0,0 +1,21 @@
+#define readRegAS(T, reg) static_cast<T>( READ_REG(reg) )
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+
+P.SU.makeStreamRegister<std::uint8_t>(streamReg, RegisterConfig::Store);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+    reg.configureVecDim(0);
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_st_d.h b/riscv/insns/ss_sta_st_d.h
new file mode 100644
index 00000000..6695a660
--- /dev/null
+++ b/riscv/insns/ss_sta_st_d.h
@@ -0,0 +1,20 @@
+#define readRegAS(T, reg) static_cast<T>( READ_REG(reg) )
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+
+P.SU.makeStreamRegister<std::uint64_t>(streamReg, RegisterConfig::Store);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_st_d_v.h b/riscv/insns/ss_sta_st_d_v.h
new file mode 100644
index 00000000..59b65ddb
--- /dev/null
+++ b/riscv/insns/ss_sta_st_d_v.h
@@ -0,0 +1,21 @@
+#define readRegAS(T, reg) static_cast<T>( READ_REG(reg) )
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+
+P.SU.makeStreamRegister<std::uint64_t>(streamReg, RegisterConfig::Store);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+    reg.configureVecDim();
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_st_d_v_1.h b/riscv/insns/ss_sta_st_d_v_1.h
new file mode 100644
index 00000000..bbc3752b
--- /dev/null
+++ b/riscv/insns/ss_sta_st_d_v_1.h
@@ -0,0 +1,21 @@
+#define readRegAS(T, reg) static_cast<T>( READ_REG(reg) )
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+
+P.SU.makeStreamRegister<std::uint64_t>(streamReg, RegisterConfig::Store);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+    reg.configureVecDim(0);
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_st_h.h b/riscv/insns/ss_sta_st_h.h
new file mode 100644
index 00000000..2256b7b5
--- /dev/null
+++ b/riscv/insns/ss_sta_st_h.h
@@ -0,0 +1,20 @@
+#define readRegAS(T, reg) static_cast<T>( READ_REG(reg) )
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+
+P.SU.makeStreamRegister<std::uint16_t>(streamReg, RegisterConfig::Store);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_st_h_v.h b/riscv/insns/ss_sta_st_h_v.h
new file mode 100644
index 00000000..d066cd1f
--- /dev/null
+++ b/riscv/insns/ss_sta_st_h_v.h
@@ -0,0 +1,21 @@
+#define readRegAS(T, reg) static_cast<T>( READ_REG(reg) )
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+
+P.SU.makeStreamRegister<std::uint16_t>(streamReg, RegisterConfig::Store);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+    reg.configureVecDim();
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_st_h_v_1.h b/riscv/insns/ss_sta_st_h_v_1.h
new file mode 100644
index 00000000..e5c7267f
--- /dev/null
+++ b/riscv/insns/ss_sta_st_h_v_1.h
@@ -0,0 +1,21 @@
+#define readRegAS(T, reg) static_cast<T>( READ_REG(reg) )
+
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+
+P.SU.makeStreamRegister<std::uint16_t>(streamReg, RegisterConfig::Store);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+    reg.configureVecDim(0);
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_st_w.h b/riscv/insns/ss_sta_st_w.h
new file mode 100644
index 00000000..eb9d01ef
--- /dev/null
+++ b/riscv/insns/ss_sta_st_w.h
@@ -0,0 +1,18 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+
+P.SU.makeStreamRegister<std::uint32_t>(streamReg, RegisterConfig::Store);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_st_w_v.h b/riscv/insns/ss_sta_st_w_v.h
new file mode 100644
index 00000000..dcf97a77
--- /dev/null
+++ b/riscv/insns/ss_sta_st_w_v.h
@@ -0,0 +1,19 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+
+P.SU.makeStreamRegister<std::uint32_t>(streamReg, RegisterConfig::Store);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+    reg.configureVecDim();
+}, destReg);
\ No newline at end of file
diff --git a/riscv/insns/ss_sta_st_w_v_1.h b/riscv/insns/ss_sta_st_w_v_1.h
new file mode 100644
index 00000000..ae353ddc
--- /dev/null
+++ b/riscv/insns/ss_sta_st_w_v_1.h
@@ -0,0 +1,19 @@
+auto streamReg = insn.uve_rd();
+auto &destReg = P.SU.registers[streamReg];
+auto baseReg = insn.uve_conf_base();
+auto sizeReg = insn.uve_conf_size();
+auto strideReg = insn.uve_conf_stride();
+
+uint64_t base = READ_REG(baseReg);
+unsigned int size = READ_REG(sizeReg);
+int stride = READ_REG(strideReg);
+
+
+P.SU.makeStreamRegister<std::uint32_t>(streamReg, RegisterConfig::Store);
+/*operateRegister(P.SU, streamReg, [=](auto& reg) {
+    reg.startConfiguration({ base, size, stride });
+});*/
+std::visit([&](auto& reg){
+    reg.startConfiguration({ base, size, stride });
+    reg.configureVecDim(0);
+}, destReg);
\ No newline at end of file
diff --git a/riscv/processor.cc b/riscv/processor.cc
index 9498b8fe..faf2441a 100644
--- a/riscv/processor.cc
+++ b/riscv/processor.cc
@@ -41,6 +41,7 @@ processor_t::processor_t(const isa_parser_t *isa, const cfg_t *cfg,
   last_pc(1), executions(1), TM(cfg->trigger_count)
 {
   VU.p = this;
+  SU.p = this; // UVE
   TM.proc = this;

 #ifndef HAVE_INT128
diff --git a/riscv/processor.h b/riscv/processor.h
index 14b828cf..8119c6f2 100644
--- a/riscv/processor.h
+++ b/riscv/processor.h
@@ -17,6 +17,9 @@
 #include "triggers.h"
 #include "../fesvr/memif.h"
 #include "vector_unit.h"
+#include "streaming_unit.h" // UVE Implementation
+#include <utility> //uve
+#include <variant> // uve

 #define N_HPMCOUNTERS 29

@@ -425,6 +428,7 @@ public:
   reg_t pmp_tor_mask() { return -(reg_t(1) << (lg_pmp_granularity - PMP_SHIFT)); }

   vectorUnit_t VU;
+  streamingUnit_t SU; // UVE Implementation
   triggers::module_t TM;
 };

diff --git a/riscv/riscv.mk.in b/riscv/riscv.mk.in
index 60723b58..eba768af 100644
--- a/riscv/riscv.mk.in
+++ b/riscv/riscv.mk.in
@@ -44,6 +44,9 @@ riscv_install_hdrs = \
 	trap.h \
 	triggers.h \
 	vector_unit.h \
+	descriptors.h \
+	streaming_unit.h \
+	helpers.h \

 riscv_precompiled_hdrs = \
 	insn_template.h \
@@ -70,6 +73,8 @@ riscv_srcs = \
 	csrs.cc \
 	triggers.cc \
 	vector_unit.cc \
+	descriptors.cc \
+	streaming_unit.cc \
 	socketif.cc \
 	cfg.cc \
 	$(riscv_gen_srcs) \
@@ -1091,6 +1096,169 @@ riscv_insn_ext_zvk = \
 	$(riscv_insn_ext_zvksed) \
 	$(riscv_insn_ext_zvksh) \

+riscv_insn_ext_uve = \
+	so_a_abs_fp \
+	so_a_abs_sg \
+	so_a_add_fp \
+	so_a_add_sg \
+	so_a_add_us \
+	so_a_adde_fp \
+	so_a_adde_sg \
+	so_a_adde_us \
+	so_a_adde_acc_fp \
+	so_a_adde_acc_sg \
+	so_a_adde_acc_us \
+	so_a_adds_fp \
+	so_a_adds_sg \
+	so_a_adds_us \
+	so_a_adds_acc_fp \
+	so_a_adds_acc_sg \
+	so_a_adds_acc_us \
+	so_a_div_fp \
+	so_a_div_sg \
+	so_a_div_us \
+	so_a_dec_fp \
+	so_a_dec_sg \
+	so_a_dec_us \
+	so_a_inc_fp \
+	so_a_inc_sg \
+	so_a_inc_us \
+	so_a_mac_fp \
+	so_a_mac_sg \
+	so_a_mac_us \
+	so_a_max_fp \
+	so_a_max_sg \
+	so_a_max_us \
+	so_a_maxe_fp \
+	so_a_maxe_sg \
+	so_a_maxe_us \
+	so_a_min_fp \
+	so_a_min_sg \
+	so_a_min_us \
+	so_a_mine_fp \
+	so_a_mine_sg \
+	so_a_mine_us \
+	so_a_mul_fp \
+	so_a_mul_sg \
+	so_a_mul_us \
+	so_a_sub_fp \
+	so_a_sub_sg \
+	so_a_sub_us \
+	so_a_and \
+	so_a_nand \
+	so_a_nor \
+	so_a_not \
+	so_a_sll \
+	so_a_slls \
+	so_a_sra \
+	so_a_sras \
+	so_a_srl \
+	so_a_srls \
+	so_a_xor \
+	so_b_c \
+	so_b_dc_1 \
+	so_b_dc_2 \
+	so_b_dc_3 \
+	so_b_dc_4 \
+	so_b_dc_5 \
+	so_b_dc_6 \
+	so_b_dc_7 \
+	so_b_nc \
+	so_b_ndc_1 \
+	so_b_ndc_2 \
+	so_b_ndc_3 \
+	so_b_ndc_4 \
+	so_b_ndc_5 \
+	so_b_ndc_6 \
+	so_b_ndc_7 \
+	so_p_ge_fp \
+	so_p_eq_fp \
+	so_p_lt_fp \
+	so_p_ge_sg \
+	so_p_eq_sg \
+	so_p_lt_sg \
+	so_p_ge_us \
+	so_p_eq_us \
+	so_p_lt_us \
+	so_p_mv \
+	so_p_mvt \
+	so_p_not \
+	so_p_one \
+	so_p_vr \
+	so_p_zero \
+	so_v_dp_b \
+	so_v_dp_d \
+	so_v_dp_h \
+	so_v_dp_w \
+	so_v_mv \
+	so_v_mvt \
+	so_v_mvsv_b \
+	so_v_mvsv_h \
+	so_v_mvsv_w \
+	so_v_mvsv_d \
+	so_v_mvvs \
+	ss_app \
+	ss_end \
+	ss_app_ind_ofs_add_1 \
+	ss_app_ind_ofs_dec_1 \
+	ss_app_ind_ofs_inc_1 \
+	ss_app_ind_ofs_set_1 \
+	ss_app_ind_ofs_sub_1 \
+	ss_app_ind_ofs_sg_add \
+	ss_app_ind_ofs_sg_dec \
+	ss_app_ind_ofs_sg_inc \
+	ss_app_ind_ofs_sg_set \
+	ss_app_ind_ofs_sg_sub \
+	ss_app_ind_siz_add_1 \
+	ss_app_ind_siz_dec_1 \
+	ss_app_ind_siz_inc_1 \
+	ss_app_ind_siz_set_1 \
+	ss_app_ind_siz_sub_1 \
+	ss_app_ind_str_add_1 \
+	ss_app_ind_str_dec_1 \
+	ss_app_ind_str_inc_1 \
+	ss_app_ind_str_set_1 \
+	ss_app_ind_str_sub_1 \
+	ss_app_mod_ofs_dec_1 \
+	ss_app_mod_ofs_inc_1 \
+	ss_app_mod_siz_dec_1 \
+	ss_app_mod_siz_inc_1 \
+	ss_app_mod_str_dec_1 \
+	ss_app_mod_str_inc_1 \
+	ss_end_ind_ofs_sg_add \
+	ss_end_ind_ofs_sg_dec \
+	ss_end_ind_ofs_sg_inc \
+	ss_end_ind_ofs_sg_set \
+	ss_end_ind_ofs_sg_sub \
+	ss_sta_ld_b \
+	ss_sta_ld_d \
+	ss_sta_ld_h \
+	ss_sta_ld_w \
+	ss_sta_ld_b_inds \
+	ss_sta_ld_d_inds \
+	ss_sta_ld_h_inds \
+	ss_sta_ld_w_inds \
+	ss_sta_ld_b_v \
+	ss_sta_ld_d_v \
+	ss_sta_ld_h_v \
+	ss_sta_ld_w_v \
+	ss_sta_ld_b_v_1 \
+	ss_sta_ld_d_v_1 \
+	ss_sta_ld_h_v_1 \
+	ss_sta_ld_w_v_1 \
+	ss_sta_st_b \
+	ss_sta_st_d \
+	ss_sta_st_h \
+	ss_sta_st_w \
+	ss_sta_st_b_v \
+	ss_sta_st_d_v \
+	ss_sta_st_h_v \
+	ss_sta_st_w_v \
+	ss_sta_st_b_v_1 \
+	ss_sta_st_d_v_1 \
+	ss_sta_st_h_v_1 \
+	ss_sta_st_w_v_1 \
+
 riscv_insn_list = \
 	$(riscv_insn_ext_i) \
 	$(riscv_insn_ext_c) \
@@ -1108,6 +1276,7 @@ riscv_insn_list = \
 	$(riscv_insn_ext_k) \
 	$(riscv_insn_ext_q) \
 	$(riscv_insn_ext_q_zfa) \
+	$(riscv_insn_ext_uve) \
 	$(riscv_insn_ext_zacas) \
 	$(riscv_insn_ext_zabha) \
 	$(riscv_insn_ext_zawrs) \
diff --git a/riscv/streaming_unit.cc b/riscv/streaming_unit.cc
new file mode 100644
index 00000000..2137a742
--- /dev/null
+++ b/riscv/streaming_unit.cc
@@ -0,0 +1,533 @@
+#include "streaming_unit.h"
+#include "mmu.h"
+#include "processor.h"
+
+#define gMMU(p) (*(p->get_mmu()))
+
+template <typename T>
+void streamRegister_t<T>::addStaticModifier(staticModifier_t mod) {
+    assert_msg("Cannot append more modifiers as max dimensions were reached", dimensions.size() + 1 < su->maxDimensions);
+    staticModifiers.insert({0, mod});
+    /* print modifiers
+    std::cout << "\nModifiers: ";
+    for (auto &m : modifiers)
+        std::cout << m.first << "  ";
+    std::cout << std::endl;*/
+}
+
+template <typename T>
+void streamRegister_t<T>::addDynamicModifier(dynamicModifier_t mod) {
+    assert_msg("Cannot append more modifiers as max dimensions were reached", dimensions.size() + 1 < su->maxDimensions);
+    dynamicModifiers.insert({0, mod});
+    /* print modifiers
+    std::cout << "\nModifiers: ";
+    for (auto &m : modifiers)
+        std::cout << m.first << "  ";
+    std::cout << std::endl;*/
+}
+
+template <typename T>
+void streamRegister_t<T>::addScatterGModifier(scatterGModifier_t mod) {
+    assert_msg("Cannot append more modifiers as max dimensions were reached", dimensions.size() + 1 < su->maxDimensions);
+    scatterGModifiers.insert({0, mod});
+    /* print modifiers
+    std::cout << "\nModifiers: ";
+    for (auto &m : modifiers)
+        std::cout << m.first << "  ";
+    std::cout << std::endl;*/
+}
+
+template <typename T>
+void streamRegister_t<T>::addDimension(dimension_t dim) {
+    assert_msg("Cannot append more dimensions as the max value was reached", dimensions.size() < su->maxDimensions);
+
+    dimensions.push_front(dim);
+
+    std::unordered_multimap<int, staticModifier_t> updatedModifiers;
+
+    // Increment all static modifiers' indexes
+    for (auto &m : staticModifiers) {
+        updatedModifiers.insert(std::make_pair(m.first + 1, m.second));
+    }
+
+    staticModifiers.swap(updatedModifiers);
+
+    std::unordered_multimap<int, dynamicModifier_t> updatedModifiers1;
+
+    // Increment all dynamic modifiers' indexes
+    for (auto &m : dynamicModifiers) {
+        updatedModifiers1.insert(std::make_pair(m.first + 1, m.second));
+    }
+
+    dynamicModifiers.swap(updatedModifiers1);
+
+    std::unordered_multimap<int, scatterGModifier_t> updatedModifiers2;
+
+    // Increment all scatter-gather modifiers' indexes
+    for (auto &m : scatterGModifiers) {
+        updatedModifiers2.insert(std::make_pair(m.first + 1, m.second));
+    }
+
+    scatterGModifiers.swap(updatedModifiers2);
+
+    /* print2 modifiers
+    std::cout << "Modifiers u" << registerN << ": ";
+    for (auto &m : modifiers)
+        std::cout << m.first << "  ";
+    std::cout << std::endl;*/
+
+    // print dimensions size
+    // std::cout << "Dimensions size: " << dimensions.size() << std::endl;
+}
+
+template <typename T>
+void streamRegister_t<T>::configureVecDim(const int cfgIndex) {
+    mode = RegisterMode::Vector;
+    validElements = vLen;
+    vecCfgDim = cfgIndex;
+}
+
+template <typename T>
+void streamRegister_t<T>::startConfiguration(dimension_t dim) {
+    status = RegisterStatus::NotConfigured;
+    mode = RegisterMode::Scalar;
+    validElements = 1;
+    dimensions.clear();
+    dimensions.push_back(dim);
+}
+
+template <typename T>
+void streamRegister_t<T>::endConfiguration() {
+    status = RegisterStatus::Running;
+
+    //print dimensions and modifiers
+    std::cout << "Dimensions: ";
+    for (auto &d : dimensions)
+        std::cout << d.getSize() << " ";
+    std::cout << std::endl;
+
+    std::cout << "Modifiers: ";
+    for (auto &m : staticModifiers)
+        std::cout << m.first << " ";
+    std::cout << std::endl;
+}
+
+template <typename T>
+std::vector<T> streamRegister_t<T>::getElements(bool causesUpdate) {
+    if (causesUpdate && this->type == RegisterConfig::Load)
+        updateAsLoad();
+
+    std::vector<T> e(elements.begin(), elements.end());
+
+    return e;
+}
+
+template <typename T>
+bool streamRegister_t<T>::getDynModElement(int &value) {
+    mode = RegisterMode::Scalar;
+    validElements = 1;
+    assert_msg("Dynamic modifier source is not correctly configured", this->type == RegisterConfig::Load);
+
+    updateAsLoad();
+
+    value = readAS<int>(elements.at(0));
+
+    // check if any EOD flag is set in EODTable
+    for (auto &eod : su->EODTable.at(registerN)) {
+        if (eod)
+            return 0;
+    }
+
+    return 1;
+}
+
+template <typename T>
+void streamRegister_t<T>::setElements(std::vector<T> e, bool causesUpdate) {
+    assert_msg("Trying to set values to a load stream", type != RegisterConfig::Load);
+
+    elements = e;
+
+    if (causesUpdate && this->type == RegisterConfig::Store)
+        updateAsStore();
+}
+
+template <typename T>
+void streamRegister_t<T>::setValidIndex(const size_t i) {
+    assert_msg("Trying to set valid index to invalid value", i <= vLen);
+
+    validElements = i;
+}
+
+template <typename T>
+void streamRegister_t<T>::setMode(const RegisterMode m) {
+    mode = m;
+    if (m == RegisterMode::Scalar)
+        validElements = 1;
+    else
+        validElements = vLen;
+}
+
+template <typename T>
+bool streamRegister_t<T>::hasStreamFinished() const {
+    return status == RegisterStatus::Finished;
+}
+
+template <typename T>
+bool streamRegister_t<T>::isEndOfDimensionOfDim(size_t i) const {
+    assert_msg("Trying to check EOD of invalid dimension", i < dimensions.size());
+    return dimensions.at(i).isEndOfDimension();
+}
+
+template <typename T>
+size_t streamRegister_t<T>::getElementWidth() const {
+    return elementWidth;
+}
+
+template <typename T>
+size_t streamRegister_t<T>::getVLen() const {
+    return vLen;
+}
+
+template <typename T>
+size_t streamRegister_t<T>::getValidElements() const {
+    return validElements;
+}
+
+template <typename T>
+RegisterStatus streamRegister_t<T>::getStatus() const {
+    return status;
+}
+
+template <typename T>
+RegisterConfig streamRegister_t<T>::getType() const {
+    return type;
+}
+
+template <typename T>
+RegisterMode streamRegister_t<T>::getMode() const {
+    return mode;
+}
+
+/* FOR DEBUGGING*/
+template <typename T>
+void streamRegister_t<T>::printRegN(char *str) {
+    if (registerN >= 0) {
+        if (registerN == 16)
+            fprintf(stdout, "%s\n", str);
+            //fprintf(stderr, ">>> UVE Register u%ld %s <<<\n", registerN, str);
+    } else
+        fprintf(stderr, ">>> Register number not set for debugging. %s<<<", str);
+}
+
+template <typename T>
+size_t streamRegister_t<T>::generateAddress() {
+    /* Result will be the final accumulation of all offsets calculated per dimension */
+    size_t init = 0;
+    int dimN = 0;
+
+    return std::accumulate(dimensions.begin(), dimensions.end(), init, [&](size_t acc, dimension_t &dim) {
+        if (dim.isLastIteration() && isDimensionFullyDone(dimensions.begin(), dimensions.begin() + dimN)) {
+            dim.setEndOfDimension(true);
+        }
+        ++dimN;
+        // std::cout << "Accumulating dimension " << ++dimN << std::endl;
+        return acc + dim.calcAddress(elementWidth);
+    });
+}
+
+template <typename T>
+bool streamRegister_t<T>::isDimensionFullyDone(const std::deque<dimension_t>::const_iterator start, const std::deque<dimension_t>::const_iterator end) const {
+    return std::accumulate(start, end, true, [](bool acc, const dimension_t &dim) {
+        return acc && dim.isEndOfDimension();
+    });
+}
+
+template <typename T>
+bool streamRegister_t<T>::isStreamDone() const {
+    return isDimensionFullyDone(dimensions.begin(), dimensions.end());
+}
+
+template <typename T>
+bool streamRegister_t<T>::tryGenerateAddress(size_t &address) {
+    /* There are two situations that prevent us from generating offsets/iterating a stream:
+    1) We are at the last iteration of the outermost dimension
+    2) We just finished the last iteration of a dimension and there is a configure
+    stream vector modifier at that same dimension. In these cases, the generation can
+    only resume after an exterior call to setEndOfDimension(false) */
+
+    /* The outermost dimension is the last one in the container */
+
+    if (isStreamDone()) {
+        /*if(registerN == 2)
+		    std:: cout << "u" << registerN << "    Stream is done" << std::endl;*/
+        status = RegisterStatus::Finished;
+        type = RegisterConfig::NoStream;
+        return false;
+    }
+
+    for (int i = 0; i < int(dimensions.size()) - 1; i++) {
+        applyDynamicMods(i);
+        if (i == vecCfgDim && isDimensionFullyDone(dimensions.begin(), dimensions.begin() + i + 1)) {
+            /*if(registerN == 2)
+                std::cout << "u" << registerN << "    Stop dimension loading " << i << std::endl;*/
+            return false;
+        }
+    }
+    address = generateAddress();
+    return true;
+}
+
+template <typename T>
+void streamRegister_t<T>::applyDynamicMods(size_t dimN) {
+    auto currentModifierIters = dynamicModifiers.equal_range(dimN);
+    for (auto it = currentModifierIters.first; it != currentModifierIters.second; ++it) {
+        if (!it->second.isApplied()){
+            //std::cout << "u" << registerN << "    Applying dynamic modifier to dim " << dimN << std::endl;
+            it->second.modDimension(dimensions, elementWidth);
+        }
+    }
+    auto currentModifierIters1 = scatterGModifiers.equal_range(dimN);
+    for (auto it = currentModifierIters1.first; it != currentModifierIters1.second; ++it) {
+        if (!it->second.isApplied()){
+            //std::cout << "u" << registerN << "    Applying scatter-gather modifier to dim " << dimN << std::endl;
+            it->second.modDimension(dimensions.at(dimN), elementWidth);
+        }
+    }
+}
+
+template <typename T>
+void streamRegister_t<T>::setDynamicModsNotApplied(size_t dimN) {
+    auto currentModifierIters = dynamicModifiers.equal_range(dimN);
+    for (auto it = currentModifierIters.first; it != currentModifierIters.second; ++it)
+        it->second.setApplied(false);
+}
+
+template <typename T>
+void streamRegister_t<T>::setSGModsNotApplied(size_t dimN) {
+    auto currentModifierIters = scatterGModifiers.equal_range(dimN);
+    for (auto it = currentModifierIters.first; it != currentModifierIters.second; ++it)
+        it->second.setApplied(false);
+}
+
+template <typename T>
+void streamRegister_t<T>::updateIteration() {
+    if (isStreamDone()) {
+        status = RegisterStatus::Finished;
+        type = RegisterConfig::NoStream;
+        return;
+    }
+
+    /* Iteration starts from the innermost dimension and updates the next if the current reaches an overflow */
+    dimensions.at(0).advance();
+
+    // std::cout << "Updating iteration. Dimensions: " << dimensions.size() << std::endl;
+    for (size_t i = 0; i < dimensions.size() - 1; ++i) {
+        auto &currDim = dimensions.at(i);
+        /* The following calculations are only necessary if we ARE in the
+        last iteration of a dimension */
+
+        if (currDim.isEndOfDimension()){
+
+            auto &nextDim = dimensions.at(i + 1);
+
+            // Reset EOD flag of current dimension
+            currDim.setEndOfDimension(false);
+
+            // Unflag dynamic modifiers of current dimension
+            setDynamicModsNotApplied(i);
+
+            // Iterate upper dimension
+            nextDim.advance();
+
+            // Unflag scatter dynamic modifiers of upper  dimension
+            setSGModsNotApplied(i+1);
+
+            // Apply static modifiers associated with upper dimension to target dimensions
+            auto upperModifierIters = staticModifiers.equal_range(i+1);
+            for (auto it = upperModifierIters.first; it != upperModifierIters.second; ++it) {
+                it->second.modDimension(dimensions, elementWidth);
+            }
+
+            // If modifiers exist, the values at targetted dimensions might have been modified.
+            // As such, we need to reset them before next iteration.
+            auto currentModifierIters = staticModifiers.equal_range(i);
+            for (auto it = currentModifierIters.first; it != currentModifierIters.second; ++it) {
+                int target = it->second.getTargetDim();
+                dimensions.at(target).resetIterValues();
+            }
+        }
+    }
+}
+
+template <typename T>
+void streamRegister_t<T>::updateAsLoad() {
+    assert_msg("Trying to update as load a non-load stream", type == RegisterConfig::Load);
+    if (isStreamDone()) { // doesn't try to load if stream has finished
+        status = RegisterStatus::Finished;
+        type = RegisterConfig::NoStream;
+        return;
+    }
+
+    // elements.clear();
+    // elements.reserve(vLen);
+
+    size_t eCount = 0;
+    validElements = 0; // reset valid index
+
+    /*----------------------------------- Loading pipeline -----------------------------------
+    ************************************* THIS IS OUTDATED ***********************************
+    * Iterate stream
+    * Try to load 1 element if not EOD of vector coupled dimension and stream is not finished
+    *      Generate offset
+    *      Push element to register
+    *      Break if:
+    *          EOD if vector coupled
+    *          Register limit reached
+    *      Iterate stream
+    * End
+    *
+    * This iterates the stream before their first load, skipping 1 iteration.
+    *----------------------------------------------------------------------------------------*/
+
+    size_t offset;
+
+    size_t max = mode == RegisterMode::Vector ? vLen : 1;
+
+    while (eCount < max && tryGenerateAddress(offset)) {
+        auto value = [this](auto address) -> ElementsType {
+            if constexpr (std::is_same_v<ElementsType, std::uint8_t>)
+                return readAS<ElementsType>(gMMU(su->p).template load<std::uint8_t>(address));
+            else if constexpr (std::is_same_v<ElementsType, std::uint16_t>)
+                return readAS<ElementsType>(gMMU(su->p).template load<std::uint16_t>(address));
+            else if constexpr (std::is_same_v<ElementsType, std::uint32_t>)
+                return readAS<ElementsType>(gMMU(su->p).template load<std::uint32_t>(address));
+            else
+                return readAS<ElementsType>(gMMU(su->p).template load<std::uint64_t>(address));
+        }(offset);
+
+        // elements.push_back(value);
+        // std::cout << "u"<< registerN << "   Loaded Value: " << readAS<double>(value) << std::endl;
+        elements.at(eCount) = value;
+        /*if (registerN==2)
+            std::cout << "u" << registerN << "    Loaded Value: " << readAS<int>(value) << std::endl;*/
+        ++validElements;
+        for (size_t i = 0; i < dimensions.size() - 1; i++)
+            setSGModsNotApplied(i);
+        if (tryGenerateAddress(offset)) {
+            updateIteration(); // reset EOD flags and iterate stream
+            ++eCount;
+        } else{
+			break;
+		}
+    }
+    su->updateEODTable(registerN); // save current state of the stream so that branches can catch EOD flags
+    // std::cout << "eCount: " << eCount << std::endl;
+    // std::cout << "vLen: " << vLen << std::endl;
+    if (eCount < max) {      // iteration is already updated when register is full
+        updateIteration(); // reset EOD flags and iterate stream
+        /*for (size_t i = 0; i < dimensions.size() - 1; i++)
+            setDynamicModsNotApplied(i, true);*/
+    }
+}
+
+template <typename T>
+void streamRegister_t<T>::updateAsStore() {
+    assert_msg("Trying to update as store a non-store stream", type == RegisterConfig::Store);
+
+    // std::cout << "Updating as store" << std::endl;
+    if (isStreamDone()) {
+        status = RegisterStatus::Finished;
+        type = RegisterConfig::NoStream;
+        return;
+    }
+
+    // std::cout << "Storing " << elements.size() << " elements. eCount=" << vLen << std::endl;
+    size_t offset;
+    size_t eCount = 0;
+
+    /*
+    std::cout << "Storing " << validElements << " elements." << std::endl;
+    // print vecCfg
+    printRegN("\nvecCfg: ");
+    for (auto &v : vecCfg)
+        std::cout << v << " ";
+    std::cout << std::endl;
+    */
+
+    while (eCount < validElements && tryGenerateAddress(offset)) {
+        // auto value = elements.front();
+        // elements.erase(elements.begin());
+        // elements.pop_front(); //-- std::array
+        auto value = elements.at(eCount);
+        // std::cout << "\nStored Values: " << readAS<double>(value) << " ";
+        if constexpr (std::is_same_v<ElementsType, std::uint8_t>)
+            gMMU(su->p).template store<std::uint8_t>(offset, readAS<ElementsType>(value));
+        else if constexpr (std::is_same_v<ElementsType, std::uint16_t>)
+            gMMU(su->p).template store<std::uint16_t>(offset, readAS<ElementsType>(value));
+        else if constexpr (std::is_same_v<ElementsType, std::uint32_t>)
+            gMMU(su->p).template store<std::uint32_t>(offset, readAS<ElementsType>(value));
+        else
+            gMMU(su->p).template store<std::uint64_t>(offset, readAS<ElementsType>(value));
+
+        if (tryGenerateAddress(offset)) {
+            updateIteration(); // reset EOD flags and iterate stream
+            ++eCount;
+        } else
+            break;
+    }
+    // std::cout << std::endl;
+    su->updateEODTable(registerN); // save current state of the stream so that branches can catch EOD flags
+    if (eCount < validElements)       // iteration is already updated when register is full
+        updateIteration();         // reset EOD flags and iterate stream
+    // elements.clear();
+}
+
+std::vector<uint8_t> predRegister_t::getPredicate() const {
+    return elements;
+}
+
+void streamingUnit_t::updateEODTable(const size_t stream) {
+    int r = 0, d = 0;
+    std::visit([&](const auto reg) {
+        int d = 0;
+        for (const auto dim : reg.dimensions) {
+            EODTable.at(stream).at(d) = /*reg.vecCfg.at(d) &&*/ dim.isEndOfDimension();
+            // fprintf(stderr, "EOD of u%d: %d\n", stream, EODTable.at(stream).at(d));
+            ++d;
+        }
+    }, registers.at(stream));
+}
+
+template <typename T>
+void streamingUnit_t::makeStreamRegister(size_t streamRegister, RegisterConfig type) {
+    assert_msg("Tried to use a register index higher than the available registers", streamRegister < registerCount);
+    if constexpr (std::is_same_v<T, std::uint8_t>) {
+        registers.at(streamRegister) = StreamReg8{this, type, streamRegister};
+    } else if constexpr (std::is_same_v<T, std::uint16_t>) {
+        registers.at(streamRegister) = StreamReg16{this, type, streamRegister};
+    } else if constexpr (std::is_same_v<T, std::uint32_t>) {
+        registers.at(streamRegister) = StreamReg32{this, type, streamRegister};
+    } else if constexpr (std::is_same_v<T, std::uint64_t>) {
+        registers.at(streamRegister) = StreamReg64{this, type, streamRegister};
+    } else {
+        static_assert(always_false_v<T>, "Cannot create register with this element width");
+    }
+}
+
+void streamingUnit_t::makePredRegister(std::vector<uint8_t> elements, size_t predRegister) {
+    assert_msg("Tried to alter p0 register, which is hardwired to 1", predRegister);
+    assert_msg("Tried to use a predicate register index higher than the available predicate registers", predRegister < predRegCount);
+    assert_msg("Tried to create predicate with invalid size", elements.size() == predicates.at(predRegister).vLen);
+    for (auto &p : elements)
+        assert_msg("Invalid values for predicate (must be 0 or 1)", !p || p == 1);
+    predicates.at(predRegister).elements = elements;
+}
+
+template class streamRegister_t<uint8_t>;
+template class streamRegister_t<uint16_t>;
+template class streamRegister_t<uint32_t>;
+template class streamRegister_t<uint64_t>;
+template void streamingUnit_t::makeStreamRegister<uint8_t>(size_t streamRegister, RegisterConfig type);
+template void streamingUnit_t::makeStreamRegister<uint16_t>(size_t streamRegister, RegisterConfig type);
+template void streamingUnit_t::makeStreamRegister<uint32_t>(size_t streamRegister, RegisterConfig type);
+template void streamingUnit_t::makeStreamRegister<uint64_t>(size_t streamRegister, RegisterConfig type);
\ No newline at end of file
diff --git a/riscv/streaming_unit.h b/riscv/streaming_unit.h
new file mode 100644
index 00000000..9b1bc7dc
--- /dev/null
+++ b/riscv/streaming_unit.h
@@ -0,0 +1,199 @@
+#ifndef STREAMING_UNIT_HPP
+#define STREAMING_UNIT_HPP
+
+#include "descriptors.h"
+#include "helpers.h"
+
+/* Necessary for using MMU */
+class processor_t;
+class streamingUnit_t;
+
+// extern processor_t *globalProcessor;
+#define gMMU(p) (*(p->get_mmu()))
+
+/* --- Streaming Registers --- */
+
+enum class RegisterConfig { NoStream,
+                            Load,
+                            Store };
+enum class RegisterStatus { NotConfigured,
+                            Running,
+                            Finished };
+enum class RegisterMode { Vector,
+                          Scalar };
+
+/* T is one of std::uint8_t, std::uint16_t, std::uint32_t or std::uint64_t and
+  represents the type of the elements of a stream at a given moment. It is the
+  type configured to store a value at a given time */
+template <typename T>
+struct streamRegister_t {
+    using ElementsType = T;
+    /* The gem5 implementation was made with 64 bytes, so this value mirrors it.
+    It can be changed to another value that is a power of 2, with atleast 8 bytes
+    to support at the 64-bit operations */
+    static constexpr size_t registerLength = 64; // in Bytes
+    //static constexpr size_t registerLength = 16; // in Bytes
+    /* During computations, we test if two streams have the same element width
+    using this property */
+    static constexpr size_t elementWidth = sizeof(ElementsType);
+    /* This property limits how many elements can be manipulated during a
+    computation and also how many can be loaded/stored at a time */
+    static constexpr size_t vLen = registerLength / elementWidth;
+
+    /* In this implementation, the concept of a stream and register are heavily
+    intertwined. As such, stream attributes, such as dimensions, modifiers, EOD flags,
+    status and configuration are associated with the registers holding each stream.
+    In real hardware, they would be independent, with streams being merely associated
+    with a certain register and values being first loaded to a buffer in the
+    Streaming Engine and then loaded to the correspondent register.
+    Because here the stream load and store operations are synchronous to the
+    rest of the execution, such is not necessary and a stream is loaded directly
+    to the register that holds all its information.*/
+    /* Last dimension cannot have a modifier */
+    // static constexpr size_t maxDimensions = 8;
+    // static constexpr size_t maxModifiers = su->maxDimensions - 1;
+
+    /* FOR DEBUGGING */
+    size_t registerN;
+
+    streamRegister_t(streamingUnit_t *su = nullptr, RegisterConfig t = RegisterConfig::NoStream, size_t regN = -1) :
+     registerN(regN), su(su), type(t) {
+        status = RegisterStatus::NotConfigured;
+        mode = RegisterMode::Vector;
+        validElements = vLen;
+        vecCfgDim = -1;
+    }
+
+    void addStaticModifier(staticModifier_t mod);
+    void addDynamicModifier(dynamicModifier_t mod);
+    void addScatterGModifier(scatterGModifier_t mod);
+    void addDimension(dimension_t dim);
+    void configureVecDim(const int = -1);
+    void startConfiguration(dimension_t dim);
+    void endConfiguration();
+    std::vector<ElementsType> getElements(bool causesUpdate = true);
+    bool getDynModElement(int &value);
+    void setElements(std::vector<ElementsType> e, bool causesUpdate = true);
+    void setValidIndex(const size_t i);
+    void setMode(const RegisterMode m);
+    bool hasStreamFinished() const;
+    //void clearEndOfDimensionOfDim(size_t i);
+    bool isEndOfDimensionOfDim(size_t i) const;
+
+    size_t getElementWidth() const;
+    size_t getVLen() const;
+    size_t getValidElements() const;
+    size_t getRegisterLength() const;
+    RegisterConfig getType() const;
+    RegisterStatus getStatus() const;
+    RegisterMode getMode() const;
+
+    /* FOR DEBUGGING*/
+    void printRegN(char *str = "");
+
+    friend class streamingUnit_t;
+
+private:
+    streamingUnit_t *su;
+    std::vector<ElementsType> elements = std::vector<ElementsType>(vLen);
+    size_t validElements;
+    /* Same ordeal as above. Although the amount of dimensions is capped, we can avoid
+    indexing by just calling the size method */
+    std::deque<dimension_t> dimensions;
+    /* Modifiers are different in that they don't have to scale linearly in a stream
+    configuration. As such, it is better to have a container that maps a dimension's
+    index to its modifier. When updating stream the iterators, we can test if a dimension
+    for the given index exists before the calculations */
+    std::unordered_multimap<int, staticModifier_t> staticModifiers;
+    std::unordered_multimap<int, dynamicModifier_t> dynamicModifiers;
+    std::unordered_multimap<int, scatterGModifier_t> scatterGModifiers;
+    RegisterConfig type;
+    RegisterStatus status;
+    RegisterMode mode;
+    /* This structure holds an array of bits indicating whether the corresponding dimension
+    is configured to only load elements while the current dimension is not over or not. It
+    is controlled using the instruction ss_cfg_vec */
+    int vecCfgDim;
+
+    size_t generateAddress();
+    bool isDimensionFullyDone(const std::deque<dimension_t>::const_iterator start, const std::deque<dimension_t>::const_iterator end) const;
+    bool isStreamDone() const;
+    bool tryGenerateAddress(size_t &address);
+    void applyDynamicMods(size_t dimN);
+    void setDynamicModsNotApplied(size_t dimN);
+    void setSGModsNotApplied(size_t dimN);
+    void updateIteration();
+    void updateAsLoad();
+    void updateAsStore();
+};
+
+/* --- Predicate Registers --- */
+
+struct predRegister_t {
+    static constexpr size_t registerLength = 64; // in Bytes
+    static constexpr size_t elementWidth = sizeof(uint8_t);
+    static constexpr size_t vLen = registerLength / elementWidth;
+
+    predRegister_t(std::vector<uint8_t> e = std::vector<uint8_t>(vLen)) {
+        elements = e;
+    }
+
+    std::vector<uint8_t> getPredicate() const;
+
+private:
+    std::vector<uint8_t> elements = std::vector<uint8_t>(vLen);
+
+    friend class streamingUnit_t;
+};
+
+/* --- Streaming Unit --- */
+
+using StreamReg8 = streamRegister_t<std::uint8_t>;
+using StreamReg16 = streamRegister_t<std::uint16_t>;
+using StreamReg32 = streamRegister_t<std::uint32_t>;
+using StreamReg64 = streamRegister_t<std::uint64_t>;
+
+struct streamingUnit_t {
+    processor_t *p = nullptr; // updated by the processor in processor.cc (ln 44)
+    /* UVE specification is to have 32 streaming/vectorial registers */
+    static constexpr size_t registerCount = 32;
+    static constexpr size_t predRegCount = 16;
+    static constexpr size_t maxDimensions = 8;
+    /* There are 2 types at play when implementing the UVE specification. A storage
+    type, which is how values get stored, and a computation type, the type a value
+    should have when doing computations. Using a variant allows us to have almost
+    full type-safety when storing/retriving values, including how many elements can
+    be contained in a register at a given moment. During computations, we might need
+    a raw cast to a signed or floating-point value.  */
+    using RegisterType = std::variant<StreamReg8, StreamReg16, StreamReg32, StreamReg64>;
+
+    std::array<std::array<bool, maxDimensions>, registerCount> EODTable;
+
+    std::array<RegisterType, registerCount> registers;
+    std::array<predRegister_t, predRegCount> predicates;
+
+    streamingUnit_t() {
+        predicates.at(0).elements = std::vector<uint8_t>(predicates.at(0).vLen, 1);
+    }
+
+    template <typename T>
+    void makeStreamRegister(size_t streamRegister = -1, RegisterConfig type = RegisterConfig::NoStream);
+
+    void makePredRegister(std::vector<uint8_t> elements, size_t predRegister = -1);
+
+    void updateEODTable(const size_t stream);
+
+    template <typename Operation>
+    auto operateRegister(size_t streamRegister, Operation &&op) {
+        assert_msg("Tried to use a register index higher than the available registers.", streamRegister < registerCount);
+        return std::visit([op = std::move(op)](auto &reg) { return op(reg); }, registers.at(streamRegister));
+    }
+
+    template <typename Operation>
+    auto operatePredReg(size_t predRegister, Operation &&op) {
+        assert_msg("Tried to use a predicate register index higher than the available predicate registers.", predRegister < predRegCount);
+        return std::visit([op = std::move(op)](auto &reg) { return op(reg); }, predicates.at(predRegister));
+    }
+};
+
+#endif // STREAMING_UNIT_HPP
diff --git a/softfloat/softfloat.h b/softfloat/softfloat.h
index 81d63f3c..78d66e6c 100644
--- a/softfloat/softfloat.h
+++ b/softfloat/softfloat.h
@@ -53,7 +53,11 @@ SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 #if defined(__cplusplus) && !defined(__APPLE__)
 # define THREAD_LOCAL thread_local
 #else
-# define THREAD_LOCAL _Thread_local
+#ifdef __cplusplus
+#define THREAD_LOCAL thread_local
+#else
+#define THREAD_LOCAL _Thread_local
+#endif
 #endif

 #ifdef __cplusplus
